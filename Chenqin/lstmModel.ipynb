{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "part_1 = pd.read_csv(\"../../Data/dc_part_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124293, 147)\n"
     ]
    }
   ],
   "source": [
    "part_1.head()\n",
    "print(part_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124293, 92)\n"
     ]
    }
   ],
   "source": [
    "part_2 = pd.read_csv(\"../../Data/chenqin5%.csv\")\n",
    "print(part_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prgcontct_other_organisation_piv</th>\n",
       "      <th>prgcontct_lwb_worker_piv</th>\n",
       "      <th>prgcontct_both_client_and_carer_piv</th>\n",
       "      <th>prgcontct_department_piv</th>\n",
       "      <th>prgcontct_family_piv</th>\n",
       "      <th>prgcontct_carer_piv</th>\n",
       "      <th>prgcontct_client_piv</th>\n",
       "      <th>prgcontct_meeting_group_of_people_piv_sum_n_days</th>\n",
       "      <th>prgcontct_other_organisation_piv_sum_n_days</th>\n",
       "      <th>prgcontct_educational_institution_piv_sum_n_days</th>\n",
       "      <th>...</th>\n",
       "      <th>progsubjcat_youth_justice_summary_report_piv_days_since</th>\n",
       "      <th>progsubjcat_training_and_development_piv_days_since</th>\n",
       "      <th>progsubjcat_annual_review_piv_days_since</th>\n",
       "      <th>progsubjcat_monthly_report_piv_days_since</th>\n",
       "      <th>progsubjcat_biological_family_carer_piv_days_since</th>\n",
       "      <th>progsubjcat_extra_curricular_activities_piv_days_since</th>\n",
       "      <th>progsubjcat_household_dynamics_piv_days_since</th>\n",
       "      <th>progsubjcat_direct_support_shift_report_piv_days_since</th>\n",
       "      <th>progsubjcat_other_piv_days_since</th>\n",
       "      <th>client_status_active_piv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>3650</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prgcontct_other_organisation_piv  prgcontct_lwb_worker_piv  \\\n",
       "0                                 0                         0   \n",
       "1                                 0                         0   \n",
       "2                                 0                         0   \n",
       "3                                 0                         0   \n",
       "4                                 0                         0   \n",
       "\n",
       "   prgcontct_both_client_and_carer_piv  prgcontct_department_piv  \\\n",
       "0                                    0                         0   \n",
       "1                                    0                         0   \n",
       "2                                    0                         0   \n",
       "3                                    0                         0   \n",
       "4                                    0                         0   \n",
       "\n",
       "   prgcontct_family_piv  prgcontct_carer_piv  prgcontct_client_piv  \\\n",
       "0                     1                    0                     0   \n",
       "1                     0                    0                     0   \n",
       "2                     0                    0                     0   \n",
       "3                     0                    0                     1   \n",
       "4                     0                    0                     2   \n",
       "\n",
       "   prgcontct_meeting_group_of_people_piv_sum_n_days  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   prgcontct_other_organisation_piv_sum_n_days  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   prgcontct_educational_institution_piv_sum_n_days  ...  \\\n",
       "0                                               0.0  ...   \n",
       "1                                               0.0  ...   \n",
       "2                                               0.0  ...   \n",
       "3                                               0.0  ...   \n",
       "4                                               0.0  ...   \n",
       "\n",
       "   progsubjcat_youth_justice_summary_report_piv_days_since  \\\n",
       "0                                               3650         \n",
       "1                                               3650         \n",
       "2                                               3650         \n",
       "3                                               3650         \n",
       "4                                               3650         \n",
       "\n",
       "   progsubjcat_training_and_development_piv_days_since  \\\n",
       "0                                               3650     \n",
       "1                                               3650     \n",
       "2                                               3650     \n",
       "3                                               3650     \n",
       "4                                               3650     \n",
       "\n",
       "   progsubjcat_annual_review_piv_days_since  \\\n",
       "0                                      3650   \n",
       "1                                      3650   \n",
       "2                                      3650   \n",
       "3                                      3650   \n",
       "4                                      3650   \n",
       "\n",
       "   progsubjcat_monthly_report_piv_days_since  \\\n",
       "0                                       3650   \n",
       "1                                       3650   \n",
       "2                                       3650   \n",
       "3                                       3650   \n",
       "4                                       3650   \n",
       "\n",
       "   progsubjcat_biological_family_carer_piv_days_since  \\\n",
       "0                                               3650    \n",
       "1                                               3650    \n",
       "2                                               3650    \n",
       "3                                               3650    \n",
       "4                                               3650    \n",
       "\n",
       "   progsubjcat_extra_curricular_activities_piv_days_since  \\\n",
       "0                                               3650        \n",
       "1                                               3650        \n",
       "2                                               3650        \n",
       "3                                               3650        \n",
       "4                                               3650        \n",
       "\n",
       "   progsubjcat_household_dynamics_piv_days_since  \\\n",
       "0                                           3650   \n",
       "1                                           3650   \n",
       "2                                           3650   \n",
       "3                                           3650   \n",
       "4                                           3650   \n",
       "\n",
       "   progsubjcat_direct_support_shift_report_piv_days_since  \\\n",
       "0                                               3650        \n",
       "1                                               3650        \n",
       "2                                               3650        \n",
       "3                                               3650        \n",
       "4                                               3650        \n",
       "\n",
       "   progsubjcat_other_piv_days_since  client_status_active_piv  \n",
       "0                              3650                        28  \n",
       "1                              3650                        31  \n",
       "2                              3650                        30  \n",
       "3                              3650                        31  \n",
       "4                              3650                        31  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenqinzhang/opt/anaconda3/envs/sem2_2020/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (27,32,38,39,40) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124293, 162)\n"
     ]
    }
   ],
   "source": [
    "part_3 = pd.read_csv(\"../../Data/miaoqin_part.csv\")\n",
    "print(part_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allrows_client_didexistprecirts</th>\n",
       "      <th>allrows_client_isactive</th>\n",
       "      <th>allrows_client_statusreason</th>\n",
       "      <th>allrows_client_gender</th>\n",
       "      <th>allrows_client_dobestimated</th>\n",
       "      <th>allrows_client_maoridescent</th>\n",
       "      <th>allrows_client_cald</th>\n",
       "      <th>allrows_client_interpreterrequired</th>\n",
       "      <th>allrows_client_has_disability_diagnosis_bool</th>\n",
       "      <th>allrows_client_incident_critical_total_count</th>\n",
       "      <th>...</th>\n",
       "      <th>25 to 34</th>\n",
       "      <th>35 to 44</th>\n",
       "      <th>45 to 54</th>\n",
       "      <th>5 and under</th>\n",
       "      <th>55 to 64</th>\n",
       "      <th>6 to 12</th>\n",
       "      <th>65 to 74</th>\n",
       "      <th>75 to 84</th>\n",
       "      <th>85 to 94</th>\n",
       "      <th>95 and over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   allrows_client_didexistprecirts  allrows_client_isactive  \\\n",
       "0                                1                        1   \n",
       "1                                1                        1   \n",
       "2                                1                        1   \n",
       "3                                1                        1   \n",
       "4                                1                        1   \n",
       "\n",
       "   allrows_client_statusreason  allrows_client_gender  \\\n",
       "0                          0.0                      1   \n",
       "1                          0.0                      1   \n",
       "2                          0.0                      1   \n",
       "3                          0.0                      1   \n",
       "4                          0.0                      1   \n",
       "\n",
       "   allrows_client_dobestimated  allrows_client_maoridescent  \\\n",
       "0                            0                            0   \n",
       "1                            0                            0   \n",
       "2                            0                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            0   \n",
       "\n",
       "   allrows_client_cald  allrows_client_interpreterrequired  \\\n",
       "0                    0                                   3   \n",
       "1                    0                                   3   \n",
       "2                    0                                   3   \n",
       "3                    0                                   3   \n",
       "4                    0                                   3   \n",
       "\n",
       "   allrows_client_has_disability_diagnosis_bool  \\\n",
       "0                                           1.0   \n",
       "1                                           1.0   \n",
       "2                                           1.0   \n",
       "3                                           1.0   \n",
       "4                                           1.0   \n",
       "\n",
       "   allrows_client_incident_critical_total_count  ...  25 to 34  35 to 44  \\\n",
       "0                                           0.0  ...         0         0   \n",
       "1                                           0.0  ...         0         0   \n",
       "2                                           0.0  ...         0         0   \n",
       "3                                           0.0  ...         0         0   \n",
       "4                                           0.0  ...         0         0   \n",
       "\n",
       "   45 to 54  5 and under  55 to 64  6 to 12  65 to 74  75 to 84  85 to 94  \\\n",
       "0         0            0         0        0         0         0         0   \n",
       "1         0            0         0        0         0         0         0   \n",
       "2         0            0         0        0         0         0         0   \n",
       "3         0            0         0        0         0         0         0   \n",
       "4         0            0         0        0         0         0         0   \n",
       "\n",
       "   95 and over  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 161 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_3 = part_3.drop([\"Unnamed: 0\"], axis='columns')\n",
    "part_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124293, 74)\n"
     ]
    }
   ],
   "source": [
    "part_4 = pd.read_csv(\"../../Data/yl-data.csv\")\n",
    "print(part_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Incident</th>\n",
       "      <th>rowtype_client_address_addition_piv</th>\n",
       "      <th>rowtype_progress_note_piv</th>\n",
       "      <th>rowtype_diagnosis_piv</th>\n",
       "      <th>rowtype_medictn_start_piv</th>\n",
       "      <th>rowtype_client_plan_start_piv</th>\n",
       "      <th>rowtype_client_plan_end_piv</th>\n",
       "      <th>rowtype_keyworker_change_piv</th>\n",
       "      <th>rowtype_reference_piv</th>\n",
       "      <th>rowtype_plcment_end_piv</th>\n",
       "      <th>...</th>\n",
       "      <th>medc_acqtyp</th>\n",
       "      <th>medc_admintype</th>\n",
       "      <th>medc_levelofindependencetype</th>\n",
       "      <th>medc_adminfreqid</th>\n",
       "      <th>status_placement</th>\n",
       "      <th>status_client_plan</th>\n",
       "      <th>status_rp_mechanical_restraint</th>\n",
       "      <th>status_rp_restricted_access</th>\n",
       "      <th>status_rp_chemical_restraint</th>\n",
       "      <th>status_rp_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>placement_none</td>\n",
       "      <td>client_plan_none</td>\n",
       "      <td>rp_mechanical_restraint_none</td>\n",
       "      <td>rp_restricted_access_none</td>\n",
       "      <td>rp_chemical_restraint_none</td>\n",
       "      <td>rp_other_none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>placement_none</td>\n",
       "      <td>client_plan_none</td>\n",
       "      <td>rp_mechanical_restraint_none</td>\n",
       "      <td>rp_restricted_access_none</td>\n",
       "      <td>rp_chemical_restraint_none</td>\n",
       "      <td>rp_other_none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>placement_none</td>\n",
       "      <td>client_plan_none</td>\n",
       "      <td>rp_mechanical_restraint_none</td>\n",
       "      <td>rp_restricted_access_none</td>\n",
       "      <td>rp_chemical_restraint_none</td>\n",
       "      <td>rp_other_none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>placement_none</td>\n",
       "      <td>client_plan_none</td>\n",
       "      <td>rp_mechanical_restraint_none</td>\n",
       "      <td>rp_restricted_access_none</td>\n",
       "      <td>rp_chemical_restraint_none</td>\n",
       "      <td>rp_other_none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>placement_none</td>\n",
       "      <td>client_plan_none</td>\n",
       "      <td>rp_mechanical_restraint_none</td>\n",
       "      <td>rp_restricted_access_none</td>\n",
       "      <td>rp_chemical_restraint_none</td>\n",
       "      <td>rp_other_none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Incident  rowtype_client_address_addition_piv  rowtype_progress_note_piv  \\\n",
       "0         0                                    0                          1   \n",
       "1         0                                    0                          0   \n",
       "2         0                                    1                          0   \n",
       "3         0                                    0                          1   \n",
       "4         0                                    0                          2   \n",
       "\n",
       "   rowtype_diagnosis_piv  rowtype_medictn_start_piv  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "\n",
       "   rowtype_client_plan_start_piv  rowtype_client_plan_end_piv  \\\n",
       "0                              0                            0   \n",
       "1                              0                            0   \n",
       "2                              0                            0   \n",
       "3                              0                            0   \n",
       "4                              0                            0   \n",
       "\n",
       "   rowtype_keyworker_change_piv  rowtype_reference_piv  \\\n",
       "0                             0                     28   \n",
       "1                             0                     31   \n",
       "2                             0                     30   \n",
       "3                             0                     31   \n",
       "4                             0                     31   \n",
       "\n",
       "   rowtype_plcment_end_piv  ...  medc_acqtyp  medc_admintype  \\\n",
       "0                        0  ...            0               0   \n",
       "1                        0  ...            0               0   \n",
       "2                        0  ...            0               0   \n",
       "3                        0  ...            0               0   \n",
       "4                        0  ...            0               0   \n",
       "\n",
       "   medc_levelofindependencetype  medc_adminfreqid  status_placement  \\\n",
       "0                             0                 0    placement_none   \n",
       "1                             0                 0    placement_none   \n",
       "2                             0                 0    placement_none   \n",
       "3                             0                 0    placement_none   \n",
       "4                             0                 0    placement_none   \n",
       "\n",
       "   status_client_plan  status_rp_mechanical_restraint  \\\n",
       "0    client_plan_none    rp_mechanical_restraint_none   \n",
       "1    client_plan_none    rp_mechanical_restraint_none   \n",
       "2    client_plan_none    rp_mechanical_restraint_none   \n",
       "3    client_plan_none    rp_mechanical_restraint_none   \n",
       "4    client_plan_none    rp_mechanical_restraint_none   \n",
       "\n",
       "   status_rp_restricted_access  status_rp_chemical_restraint  status_rp_other  \n",
       "0    rp_restricted_access_none    rp_chemical_restraint_none    rp_other_none  \n",
       "1    rp_restricted_access_none    rp_chemical_restraint_none    rp_other_none  \n",
       "2    rp_restricted_access_none    rp_chemical_restraint_none    rp_other_none  \n",
       "3    rp_restricted_access_none    rp_chemical_restraint_none    rp_other_none  \n",
       "4    rp_restricted_access_none    rp_chemical_restraint_none    rp_other_none  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_4 = part_4.drop([\"Unnamed: 0\"], axis='columns')\n",
    "part_4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Only use Di Cao's part for now, convate other features later after feature engineer has been done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset to three part: Training, evaluation and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_record = part_1\n",
    "#init_record = pd.concat([part_1, part_2], axis=1, sort=False)\n",
    "init_record['_key_occurreddate_month']=init_record['_key_occurreddate_month'].astype(\"datetime64[ns]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_record = init_record.set_index(['_key_client_id', '_key_occurreddate_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124293, 145)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_record.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.639257663168138"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_record.shape[0]/len(set(init_record.index.get_level_values(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0000D172-EA88-432F-8235-9FAA00D29072', 12)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "count = Counter()\n",
    "for i in init_record.index.get_level_values(0):\n",
    "    count[i] += 1\n",
    "count.most_common(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only keep clients that has at least n records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 12\n",
    "deleteList = []\n",
    "for i in count:\n",
    "    if count[i] < n:\n",
    "        deleteList.append(i)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7007"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deleteList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_record.drop(deleteList, inplace=True, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88560, 145)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_record.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, start to split. Randomly choose 10% of clients as testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "clientList = list(set(init_record.index.get_level_values(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(clientList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(clientList)\n",
    "ratio = int(length*0.1)\n",
    "trainIDs = clientList[ratio:]\n",
    "testIDs = clientList[:ratio]\n",
    "train0 = init_record.drop(testIDs, level=0)\n",
    "test = init_record.drop(trainIDs, level=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79704, 145)\n",
      "(8856, 145)\n"
     ]
    }
   ],
   "source": [
    "print(train0.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = int(len(trainIDs)*0.25)\n",
    "trainRatio = trainIDs[ratio:]\n",
    "evalRatio  = trainIDs[:ratio]\n",
    "train = train0.drop(evalRatio, level=0)\n",
    "evl = train0.drop(trainRatio,level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59784, 145)\n",
      "(19920, 145)\n",
      "(8856, 145)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(evl.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct feature Matrix with length k (k must smaller then n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def construct_feature_label(data,k=6):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    clientList = list(set(data.index.get_level_values(0)))\n",
    "    for client in clientList:\n",
    "        subframe = data.xs(client, level=0)\n",
    "        subtrain = subframe.drop('response_variable',axis='columns')\n",
    "        sublabel = subframe['response_variable']\n",
    "        start = 0\n",
    "        end = k\n",
    "        while end<len(subframe)-1:\n",
    "            x_train.append(subtrain[start:end].values)\n",
    "            y_train.append(sublabel[end+1])\n",
    "            end+=1\n",
    "            start+=1\n",
    "    return x_train, y_train\n",
    "\n",
    "x_train ,y_train = construct_feature_label(train)\n",
    "x_eval, y_eval = construct_feature_label(evl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24910\n",
      "24910\n",
      "6\n",
      "8300\n",
      "8300\n",
      "(6, 144)\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(x_train))\n",
    "print(len(x_train[0]))\n",
    "print(len(y_eval))\n",
    "print(len(x_eval))\n",
    "print(x_eval[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MV_time_CNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, window_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = input_dim, out_channels = output_dim, kernel_size = (4, window_size[0]))\n",
    "        self.conv2 = nn.Conv2d(in_channels = input_dim, out_channels = output_dim, kernel_size = (4, window_size[1]))\n",
    "        self.conv3 = nn.Conv2d(in_channels = input_dim, out_channels = output_dim, kernel_size = (4, window_size[2]))\n",
    "        self.full_connect = nn.Linear(in_features = 699, out_features = 1)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        data = torch.unsqueeze(data, 1)\n",
    "        hidden_layer1 = self.conv1(data)\n",
    "        hidden_layer2 = self.conv2(data)\n",
    "        hidden_layer3 = self.conv3(data)\n",
    "        hidden_layer = torch.cat([hidden_layer1, hidden_layer2, hidden_layer3], dim=3)\n",
    "        hidden_layer = hidden_layer.squeeze(1)\n",
    "        hidden_layer = hidden_layer.squeeze(1)\n",
    "        output = self.full_connect(hidden_layer)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another CNN + Feed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 4x4 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        #self.conv2 = nn.Conv2d(6, 32, 3)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(1704, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "    def forward(self, data):\n",
    "        data = torch.unsqueeze(data, 1)\n",
    "        x = self.conv1(data)\n",
    "        x = F.relu(x)\n",
    "        #x = self.conv2(data)\n",
    "        #x = F.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.batch_size = None\n",
    "        self.hidden = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0, c0 = self.init_hidden(x)\n",
    "        out, (hn, cn) = self.rnn(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        return [t for t in (h0, c0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0245,  0.3222, -2.5998,  2.4115,  1.6522,  0.9915, -1.4971,\n",
       "           0.9450,  0.0633,  0.5878,  0.5842, -0.9860, -1.0189, -1.2539,\n",
       "          -0.5866, -0.5635,  0.8366, -0.1688,  1.9906, -0.9556],\n",
       "         [ 0.3282, -0.9612,  1.4248, -0.6810,  0.7499, -0.4057,  0.1418,\n",
       "          -0.4631,  0.4661, -0.5810,  1.7547,  0.3518,  1.5235,  0.1399,\n",
       "           1.1047,  0.1082,  0.8625, -0.5671,  0.8545,  1.4684],\n",
       "         [-0.6092,  0.2844,  0.5569, -0.0654, -0.4972,  0.0108, -0.5313,\n",
       "           1.6256,  0.1601, -0.9306, -0.5996, -0.1999,  1.7332,  0.6816,\n",
       "          -0.5916,  0.0679,  0.5485,  0.6390,  0.2004,  0.0678]],\n",
       "\n",
       "        [[ 0.3518,  1.1176, -0.9246, -0.8215,  0.5801,  0.0097, -0.5723,\n",
       "           1.1949,  0.8804, -1.7570, -0.9327,  0.6434,  0.8972,  0.9139,\n",
       "           0.2023,  0.2812,  0.1630, -1.3034,  0.5613, -0.2309],\n",
       "         [ 0.1822, -2.3195,  1.5495, -1.3238, -0.6756,  1.2007,  0.7033,\n",
       "          -0.4703, -1.5455,  2.8214,  0.7101,  0.9041, -1.3275,  0.1997,\n",
       "           0.8410,  0.8341,  1.9596, -0.6045, -0.8011, -1.3138],\n",
       "         [-0.0032, -1.0570,  0.4035, -2.0887,  1.6885, -0.6372, -0.9924,\n",
       "           0.3074,  1.2116, -0.8642,  0.7228, -1.0536,  0.4479,  0.1833,\n",
       "          -0.2670,  1.2363,  0.6648,  1.9140, -0.6799,  1.8339]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer data to torch type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "import torch\n",
    "\n",
    "x_train_tensor = torch.Tensor(x_train)\n",
    "y_train_tensor = torch.Tensor(y_train)\n",
    "\n",
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_data_loader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=100)\n",
    "\n",
    "print(len(train_data_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 144])\n"
     ]
    }
   ],
   "source": [
    "print(train_data_loader.dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    }
   ],
   "source": [
    "x_eval_tensor = torch.Tensor(x_eval)\n",
    "y_eval_tensor = torch.Tensor(y_eval)\n",
    "\n",
    "eval_data = TensorDataset(x_eval_tensor, y_eval_tensor)\n",
    "eval_data_loader = DataLoader(eval_data, sampler=RandomSampler(eval_data), batch_size=100)\n",
    "print(len(eval_data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#model = MV_time_CNN(1, 1, [3, 4, 5])\n",
    "input_dim = 144   \n",
    "hidden_dim = 256\n",
    "layer_dim = 6\n",
    "output_dim = 1\n",
    "seq_dim = 6\n",
    "model = LSTMClassifier(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining our loss and porting our model and loss to GPU\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "#model.to(device)\n",
    "#criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(pred, actual_label):\n",
    "    rounded_preds = torch.round(torch.sigmoid(pred))\n",
    "    correct = (rounded_preds == actual_label).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f_score_measure(pred, actual_label):\n",
    "    rounded_preds = torch.round(torch.sigmoid(pred.cpu()))\n",
    "    preds = rounded_preds.data.numpy()\n",
    "    actual_labels = actual_label.cpu().data.numpy()\n",
    "    score = f1_score(preds, actual_labels)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the training method\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_F1_score = 0\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        #input_data = batch[0].to(device)\n",
    "        #labels = batch[1].to(device)\n",
    "        input_data = batch[0]\n",
    "        labels = batch[1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(input_data).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions,labels)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, labels)\n",
    "        f_score = f_score_measure(predictions, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        epoch_F1_score += f_score.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_F1_score / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the validation method\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_F1_score = 0\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            #input_data = batch[0].to(device)\n",
    "            #labels = batch[1].to(device)\n",
    "            input_data = batch[0]\n",
    "            labels = batch[1]\n",
    "\n",
    "            predictions = model(input_data).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, labels)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, labels)\n",
    "            f_score = f_score_measure(predictions, labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_F1_score += f_score.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_F1_score / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the method to calculate epoch time\n",
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 48s\n",
      "\tTrain Loss: 0.236 | Train Acc: 92.74% | Train F1_score: 0.062\n",
      "\t Val. Loss: 0.213 |  Val. Acc: 93.33% | Val. F1_score: 0.414\n",
      "Epoch: 02 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.195 | Train Acc: 93.09% | Train F1_score: 0.242\n",
      "\t Val. Loss: 0.184 |  Val. Acc: 93.67% | Val. F1_score: 0.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenqinzhang/opt/anaconda3/envs/sem2_2020/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1464: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.188 | Train Acc: 93.33% | Train F1_score: 0.290\n",
      "\t Val. Loss: 0.181 |  Val. Acc: 93.69% | Val. F1_score: 0.273\n",
      "Epoch: 04 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.188 | Train Acc: 93.33% | Train F1_score: 0.291\n",
      "\t Val. Loss: 0.179 |  Val. Acc: 93.70% | Val. F1_score: 0.409\n",
      "Epoch: 05 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.187 | Train Acc: 93.32% | Train F1_score: 0.313\n",
      "\t Val. Loss: 0.182 |  Val. Acc: 93.72% | Val. F1_score: 0.341\n",
      "Epoch: 06 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.185 | Train Acc: 93.37% | Train F1_score: 0.306\n",
      "\t Val. Loss: 0.181 |  Val. Acc: 93.64% | Val. F1_score: 0.254\n",
      "Epoch: 07 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.185 | Train Acc: 93.32% | Train F1_score: 0.290\n",
      "\t Val. Loss: 0.186 |  Val. Acc: 93.73% | Val. F1_score: 0.392\n",
      "Epoch: 08 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.185 | Train Acc: 93.28% | Train F1_score: 0.299\n",
      "\t Val. Loss: 0.178 |  Val. Acc: 93.76% | Val. F1_score: 0.390\n",
      "Epoch: 09 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.184 | Train Acc: 93.34% | Train F1_score: 0.291\n",
      "\t Val. Loss: 0.180 |  Val. Acc: 93.71% | Val. F1_score: 0.368\n",
      "Epoch: 10 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.183 | Train Acc: 93.55% | Train F1_score: 0.322\n",
      "\t Val. Loss: 0.185 |  Val. Acc: 93.07% | Val. F1_score: 0.439\n",
      "Epoch: 11 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.182 | Train Acc: 93.46% | Train F1_score: 0.317\n",
      "\t Val. Loss: 0.179 |  Val. Acc: 93.71% | Val. F1_score: 0.334\n",
      "Epoch: 12 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.180 | Train Acc: 93.42% | Train F1_score: 0.308\n",
      "\t Val. Loss: 0.181 |  Val. Acc: 93.41% | Val. F1_score: 0.156\n",
      "Epoch: 13 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.181 | Train Acc: 93.44% | Train F1_score: 0.302\n",
      "\t Val. Loss: 0.183 |  Val. Acc: 93.60% | Val. F1_score: 0.277\n",
      "Epoch: 14 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.180 | Train Acc: 93.57% | Train F1_score: 0.333\n",
      "\t Val. Loss: 0.179 |  Val. Acc: 93.59% | Val. F1_score: 0.239\n",
      "Epoch: 15 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.179 | Train Acc: 93.51% | Train F1_score: 0.315\n",
      "\t Val. Loss: 0.184 |  Val. Acc: 93.46% | Val. F1_score: 0.330\n",
      "Epoch: 16 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.178 | Train Acc: 93.59% | Train F1_score: 0.345\n",
      "\t Val. Loss: 0.179 |  Val. Acc: 93.64% | Val. F1_score: 0.279\n",
      "Epoch: 17 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.177 | Train Acc: 93.64% | Train F1_score: 0.338\n",
      "\t Val. Loss: 0.179 |  Val. Acc: 93.75% | Val. F1_score: 0.256\n",
      "Epoch: 18 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.175 | Train Acc: 93.67% | Train F1_score: 0.355\n",
      "\t Val. Loss: 0.179 |  Val. Acc: 93.54% | Val. F1_score: 0.320\n",
      "Epoch: 19 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.175 | Train Acc: 93.78% | Train F1_score: 0.339\n",
      "\t Val. Loss: 0.181 |  Val. Acc: 93.77% | Val. F1_score: 0.298\n",
      "Epoch: 20 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.175 | Train Acc: 93.82% | Train F1_score: 0.351\n",
      "\t Val. Loss: 0.182 |  Val. Acc: 93.45% | Val. F1_score: 0.271\n",
      "Epoch: 21 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.176 | Train Acc: 93.78% | Train F1_score: 0.344\n",
      "\t Val. Loss: 0.182 |  Val. Acc: 93.53% | Val. F1_score: 0.435\n",
      "Epoch: 22 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.174 | Train Acc: 93.80% | Train F1_score: 0.353\n",
      "\t Val. Loss: 0.179 |  Val. Acc: 93.43% | Val. F1_score: 0.304\n",
      "Epoch: 23 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.173 | Train Acc: 93.90% | Train F1_score: 0.380\n",
      "\t Val. Loss: 0.181 |  Val. Acc: 93.29% | Val. F1_score: 0.284\n",
      "Epoch: 24 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.171 | Train Acc: 93.96% | Train F1_score: 0.386\n",
      "\t Val. Loss: 0.185 |  Val. Acc: 93.39% | Val. F1_score: 0.315\n",
      "Epoch: 25 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.174 | Train Acc: 93.94% | Train F1_score: 0.397\n",
      "\t Val. Loss: 0.184 |  Val. Acc: 93.51% | Val. F1_score: 0.270\n",
      "Epoch: 26 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.171 | Train Acc: 93.86% | Train F1_score: 0.376\n",
      "\t Val. Loss: 0.185 |  Val. Acc: 93.48% | Val. F1_score: 0.334\n",
      "Epoch: 27 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.168 | Train Acc: 94.05% | Train F1_score: 0.373\n",
      "\t Val. Loss: 0.185 |  Val. Acc: 93.41% | Val. F1_score: 0.359\n",
      "Epoch: 28 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.169 | Train Acc: 94.03% | Train F1_score: 0.401\n",
      "\t Val. Loss: 0.184 |  Val. Acc: 93.48% | Val. F1_score: 0.385\n",
      "Epoch: 29 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.166 | Train Acc: 94.27% | Train F1_score: 0.417\n",
      "\t Val. Loss: 0.186 |  Val. Acc: 93.41% | Val. F1_score: 0.253\n",
      "Epoch: 30 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.166 | Train Acc: 94.14% | Train F1_score: 0.403\n",
      "\t Val. Loss: 0.189 |  Val. Acc: 93.23% | Val. F1_score: 0.316\n",
      "Epoch: 31 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.166 | Train Acc: 94.18% | Train F1_score: 0.428\n",
      "\t Val. Loss: 0.190 |  Val. Acc: 93.19% | Val. F1_score: 0.312\n",
      "Epoch: 32 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.165 | Train Acc: 94.25% | Train F1_score: 0.430\n",
      "\t Val. Loss: 0.186 |  Val. Acc: 93.37% | Val. F1_score: 0.297\n",
      "Epoch: 33 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.164 | Train Acc: 94.32% | Train F1_score: 0.429\n",
      "\t Val. Loss: 0.194 |  Val. Acc: 92.81% | Val. F1_score: 0.387\n",
      "Epoch: 34 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.162 | Train Acc: 94.27% | Train F1_score: 0.442\n",
      "\t Val. Loss: 0.197 |  Val. Acc: 92.83% | Val. F1_score: 0.414\n",
      "Epoch: 35 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.165 | Train Acc: 94.27% | Train F1_score: 0.414\n",
      "\t Val. Loss: 0.191 |  Val. Acc: 93.42% | Val. F1_score: 0.257\n",
      "Epoch: 36 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.160 | Train Acc: 94.46% | Train F1_score: 0.454\n",
      "\t Val. Loss: 0.198 |  Val. Acc: 93.24% | Val. F1_score: 0.369\n",
      "Epoch: 37 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.160 | Train Acc: 94.47% | Train F1_score: 0.452\n",
      "\t Val. Loss: 0.193 |  Val. Acc: 93.23% | Val. F1_score: 0.289\n",
      "Epoch: 38 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.160 | Train Acc: 94.48% | Train F1_score: 0.453\n",
      "\t Val. Loss: 0.191 |  Val. Acc: 93.30% | Val. F1_score: 0.275\n",
      "Epoch: 39 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.158 | Train Acc: 94.64% | Train F1_score: 0.460\n",
      "\t Val. Loss: 0.196 |  Val. Acc: 93.43% | Val. F1_score: 0.353\n",
      "Epoch: 40 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.156 | Train Acc: 94.74% | Train F1_score: 0.483\n",
      "\t Val. Loss: 0.201 |  Val. Acc: 93.08% | Val. F1_score: 0.301\n",
      "Epoch: 41 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.156 | Train Acc: 94.77% | Train F1_score: 0.472\n",
      "\t Val. Loss: 0.203 |  Val. Acc: 93.29% | Val. F1_score: 0.381\n",
      "Epoch: 42 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.156 | Train Acc: 94.78% | Train F1_score: 0.510\n",
      "\t Val. Loss: 0.202 |  Val. Acc: 92.80% | Val. F1_score: 0.334\n",
      "Epoch: 43 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.156 | Train Acc: 94.83% | Train F1_score: 0.490\n",
      "\t Val. Loss: 0.206 |  Val. Acc: 93.47% | Val. F1_score: 0.352\n",
      "Epoch: 44 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.153 | Train Acc: 94.84% | Train F1_score: 0.497\n",
      "\t Val. Loss: 0.208 |  Val. Acc: 93.04% | Val. F1_score: 0.352\n",
      "Epoch: 45 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.152 | Train Acc: 94.96% | Train F1_score: 0.508\n",
      "\t Val. Loss: 0.204 |  Val. Acc: 93.33% | Val. F1_score: 0.301\n",
      "Epoch: 46 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.150 | Train Acc: 95.04% | Train F1_score: 0.516\n",
      "\t Val. Loss: 0.210 |  Val. Acc: 92.95% | Val. F1_score: 0.339\n",
      "Epoch: 47 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.148 | Train Acc: 95.14% | Train F1_score: 0.533\n",
      "\t Val. Loss: 0.210 |  Val. Acc: 93.00% | Val. F1_score: 0.293\n",
      "Epoch: 48 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.149 | Train Acc: 95.05% | Train F1_score: 0.519\n",
      "\t Val. Loss: 0.215 |  Val. Acc: 93.10% | Val. F1_score: 0.301\n",
      "Epoch: 49 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.146 | Train Acc: 95.20% | Train F1_score: 0.545\n",
      "\t Val. Loss: 0.216 |  Val. Acc: 93.12% | Val. F1_score: 0.365\n",
      "Epoch: 50 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.146 | Train Acc: 95.15% | Train F1_score: 0.541\n",
      "\t Val. Loss: 0.216 |  Val. Acc: 92.82% | Val. F1_score: 0.374\n",
      "Epoch: 51 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.146 | Train Acc: 95.20% | Train F1_score: 0.554\n",
      "\t Val. Loss: 0.217 |  Val. Acc: 93.05% | Val. F1_score: 0.335\n",
      "Epoch: 52 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.142 | Train Acc: 95.38% | Train F1_score: 0.564\n",
      "\t Val. Loss: 0.222 |  Val. Acc: 93.17% | Val. F1_score: 0.364\n",
      "Epoch: 53 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.144 | Train Acc: 95.41% | Train F1_score: 0.565\n",
      "\t Val. Loss: 0.214 |  Val. Acc: 92.75% | Val. F1_score: 0.343\n",
      "Epoch: 54 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.140 | Train Acc: 95.52% | Train F1_score: 0.585\n",
      "\t Val. Loss: 0.231 |  Val. Acc: 92.94% | Val. F1_score: 0.335\n",
      "Epoch: 55 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.142 | Train Acc: 95.35% | Train F1_score: 0.562\n",
      "\t Val. Loss: 0.220 |  Val. Acc: 93.11% | Val. F1_score: 0.327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.138 | Train Acc: 95.56% | Train F1_score: 0.586\n",
      "\t Val. Loss: 0.222 |  Val. Acc: 93.00% | Val. F1_score: 0.325\n",
      "Epoch: 57 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.137 | Train Acc: 95.58% | Train F1_score: 0.588\n",
      "\t Val. Loss: 0.237 |  Val. Acc: 92.54% | Val. F1_score: 0.360\n",
      "Epoch: 58 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.141 | Train Acc: 95.40% | Train F1_score: 0.572\n",
      "\t Val. Loss: 0.218 |  Val. Acc: 93.13% | Val. F1_score: 0.357\n",
      "Epoch: 59 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.135 | Train Acc: 95.81% | Train F1_score: 0.607\n",
      "\t Val. Loss: 0.223 |  Val. Acc: 93.20% | Val. F1_score: 0.357\n",
      "Epoch: 60 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.132 | Train Acc: 95.84% | Train F1_score: 0.627\n",
      "\t Val. Loss: 0.237 |  Val. Acc: 93.10% | Val. F1_score: 0.335\n",
      "Epoch: 61 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.131 | Train Acc: 95.92% | Train F1_score: 0.615\n",
      "\t Val. Loss: 0.231 |  Val. Acc: 93.10% | Val. F1_score: 0.336\n",
      "Epoch: 62 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.131 | Train Acc: 95.88% | Train F1_score: 0.625\n",
      "\t Val. Loss: 0.238 |  Val. Acc: 93.00% | Val. F1_score: 0.322\n",
      "Epoch: 63 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.129 | Train Acc: 96.03% | Train F1_score: 0.641\n",
      "\t Val. Loss: 0.245 |  Val. Acc: 92.59% | Val. F1_score: 0.363\n",
      "Epoch: 64 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.127 | Train Acc: 96.04% | Train F1_score: 0.636\n",
      "\t Val. Loss: 0.238 |  Val. Acc: 93.08% | Val. F1_score: 0.376\n",
      "Epoch: 65 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.126 | Train Acc: 96.20% | Train F1_score: 0.654\n",
      "\t Val. Loss: 0.244 |  Val. Acc: 92.89% | Val. F1_score: 0.331\n",
      "Epoch: 66 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.126 | Train Acc: 96.11% | Train F1_score: 0.648\n",
      "\t Val. Loss: 0.247 |  Val. Acc: 92.96% | Val. F1_score: 0.333\n",
      "Epoch: 67 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.129 | Train Acc: 96.07% | Train F1_score: 0.642\n",
      "\t Val. Loss: 0.249 |  Val. Acc: 92.87% | Val. F1_score: 0.344\n",
      "Epoch: 68 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.126 | Train Acc: 96.26% | Train F1_score: 0.668\n",
      "\t Val. Loss: 0.249 |  Val. Acc: 92.82% | Val. F1_score: 0.322\n",
      "Epoch: 69 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.127 | Train Acc: 96.06% | Train F1_score: 0.644\n",
      "\t Val. Loss: 0.235 |  Val. Acc: 93.20% | Val. F1_score: 0.368\n",
      "Epoch: 70 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.120 | Train Acc: 96.50% | Train F1_score: 0.683\n",
      "\t Val. Loss: 0.251 |  Val. Acc: 92.61% | Val. F1_score: 0.371\n",
      "Epoch: 71 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.124 | Train Acc: 96.30% | Train F1_score: 0.671\n",
      "\t Val. Loss: 0.259 |  Val. Acc: 92.81% | Val. F1_score: 0.366\n",
      "Epoch: 72 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.119 | Train Acc: 96.43% | Train F1_score: 0.685\n",
      "\t Val. Loss: 0.262 |  Val. Acc: 92.95% | Val. F1_score: 0.341\n",
      "Epoch: 73 | Epoch Time: 0m 47s\n",
      "\tTrain Loss: 0.117 | Train Acc: 96.52% | Train F1_score: 0.669\n",
      "\t Val. Loss: 0.284 |  Val. Acc: 92.86% | Val. F1_score: 0.330\n",
      "Epoch: 74 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.115 | Train Acc: 96.65% | Train F1_score: 0.698\n",
      "\t Val. Loss: 0.273 |  Val. Acc: 92.99% | Val. F1_score: 0.341\n",
      "Epoch: 75 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.120 | Train Acc: 96.44% | Train F1_score: 0.673\n",
      "\t Val. Loss: 0.270 |  Val. Acc: 92.73% | Val. F1_score: 0.361\n",
      "Epoch: 76 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.117 | Train Acc: 96.60% | Train F1_score: 0.692\n",
      "\t Val. Loss: 0.267 |  Val. Acc: 93.00% | Val. F1_score: 0.345\n",
      "Epoch: 77 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.116 | Train Acc: 96.57% | Train F1_score: 0.694\n",
      "\t Val. Loss: 0.288 |  Val. Acc: 92.76% | Val. F1_score: 0.358\n",
      "Epoch: 78 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.112 | Train Acc: 96.72% | Train F1_score: 0.714\n",
      "\t Val. Loss: 0.290 |  Val. Acc: 92.64% | Val. F1_score: 0.343\n",
      "Epoch: 79 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.113 | Train Acc: 96.72% | Train F1_score: 0.706\n",
      "\t Val. Loss: 0.282 |  Val. Acc: 92.81% | Val. F1_score: 0.357\n",
      "Epoch: 80 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.109 | Train Acc: 96.91% | Train F1_score: 0.726\n",
      "\t Val. Loss: 0.298 |  Val. Acc: 92.75% | Val. F1_score: 0.325\n",
      "Epoch: 81 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.110 | Train Acc: 96.78% | Train F1_score: 0.713\n",
      "\t Val. Loss: 0.289 |  Val. Acc: 92.81% | Val. F1_score: 0.360\n",
      "Epoch: 82 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.112 | Train Acc: 96.76% | Train F1_score: 0.711\n",
      "\t Val. Loss: 0.298 |  Val. Acc: 92.29% | Val. F1_score: 0.341\n",
      "Epoch: 83 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.109 | Train Acc: 96.83% | Train F1_score: 0.719\n",
      "\t Val. Loss: 0.302 |  Val. Acc: 92.00% | Val. F1_score: 0.355\n",
      "Epoch: 84 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.106 | Train Acc: 96.99% | Train F1_score: 0.730\n",
      "\t Val. Loss: 0.323 |  Val. Acc: 92.49% | Val. F1_score: 0.356\n",
      "Epoch: 85 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.112 | Train Acc: 96.80% | Train F1_score: 0.717\n",
      "\t Val. Loss: 0.278 |  Val. Acc: 92.75% | Val. F1_score: 0.343\n",
      "Epoch: 86 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.109 | Train Acc: 96.96% | Train F1_score: 0.725\n",
      "\t Val. Loss: 0.294 |  Val. Acc: 92.48% | Val. F1_score: 0.384\n",
      "Epoch: 87 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.105 | Train Acc: 97.03% | Train F1_score: 0.742\n",
      "\t Val. Loss: 0.294 |  Val. Acc: 92.66% | Val. F1_score: 0.323\n",
      "Epoch: 88 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.104 | Train Acc: 97.00% | Train F1_score: 0.733\n",
      "\t Val. Loss: 0.316 |  Val. Acc: 92.83% | Val. F1_score: 0.374\n",
      "Epoch: 89 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.143 | Train Acc: 95.79% | Train F1_score: 0.601\n",
      "\t Val. Loss: 0.282 |  Val. Acc: 92.89% | Val. F1_score: 0.351\n",
      "Epoch: 90 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.104 | Train Acc: 97.13% | Train F1_score: 0.749\n",
      "\t Val. Loss: 0.314 |  Val. Acc: 92.35% | Val. F1_score: 0.366\n",
      "Epoch: 91 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.102 | Train Acc: 97.12% | Train F1_score: 0.750\n",
      "\t Val. Loss: 0.292 |  Val. Acc: 92.67% | Val. F1_score: 0.366\n",
      "Epoch: 92 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.104 | Train Acc: 97.03% | Train F1_score: 0.744\n",
      "\t Val. Loss: 0.324 |  Val. Acc: 92.63% | Val. F1_score: 0.373\n",
      "Epoch: 93 | Epoch Time: 0m 46s\n",
      "\tTrain Loss: 0.099 | Train Acc: 97.28% | Train F1_score: 0.755\n",
      "\t Val. Loss: 0.323 |  Val. Acc: 92.60% | Val. F1_score: 0.340\n",
      "Epoch: 94 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.102 | Train Acc: 97.14% | Train F1_score: 0.741\n",
      "\t Val. Loss: 0.330 |  Val. Acc: 92.36% | Val. F1_score: 0.369\n",
      "Epoch: 95 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.110 | Train Acc: 96.90% | Train F1_score: 0.729\n",
      "\t Val. Loss: 0.309 |  Val. Acc: 92.31% | Val. F1_score: 0.333\n",
      "Epoch: 96 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.102 | Train Acc: 97.11% | Train F1_score: 0.761\n",
      "\t Val. Loss: 0.305 |  Val. Acc: 92.60% | Val. F1_score: 0.378\n",
      "Epoch: 97 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.110 | Train Acc: 96.89% | Train F1_score: 0.733\n",
      "\t Val. Loss: 0.291 |  Val. Acc: 92.31% | Val. F1_score: 0.363\n",
      "Epoch: 98 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.097 | Train Acc: 97.28% | Train F1_score: 0.767\n",
      "\t Val. Loss: 0.314 |  Val. Acc: 92.63% | Val. F1_score: 0.340\n",
      "Epoch: 99 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.097 | Train Acc: 97.23% | Train F1_score: 0.763\n",
      "\t Val. Loss: 0.314 |  Val. Acc: 92.14% | Val. F1_score: 0.337\n",
      "Epoch: 100 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.098 | Train Acc: 97.24% | Train F1_score: 0.765\n",
      "\t Val. Loss: 0.346 |  Val. Acc: 92.19% | Val. F1_score: 0.339\n",
      "Epoch: 101 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.093 | Train Acc: 97.46% | Train F1_score: 0.781\n",
      "\t Val. Loss: 0.330 |  Val. Acc: 92.35% | Val. F1_score: 0.345\n",
      "Epoch: 102 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.095 | Train Acc: 97.44% | Train F1_score: 0.779\n",
      "\t Val. Loss: 0.326 |  Val. Acc: 92.39% | Val. F1_score: 0.332\n",
      "Epoch: 103 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.093 | Train Acc: 97.39% | Train F1_score: 0.769\n",
      "\t Val. Loss: 0.321 |  Val. Acc: 92.67% | Val. F1_score: 0.350\n",
      "Epoch: 104 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.092 | Train Acc: 97.43% | Train F1_score: 0.774\n",
      "\t Val. Loss: 0.349 |  Val. Acc: 92.73% | Val. F1_score: 0.365\n",
      "Epoch: 105 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.099 | Train Acc: 97.18% | Train F1_score: 0.759\n",
      "\t Val. Loss: 0.324 |  Val. Acc: 92.27% | Val. F1_score: 0.351\n",
      "Epoch: 106 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.095 | Train Acc: 97.33% | Train F1_score: 0.774\n",
      "\t Val. Loss: 0.337 |  Val. Acc: 92.76% | Val. F1_score: 0.356\n",
      "Epoch: 107 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.095 | Train Acc: 97.33% | Train F1_score: 0.773\n",
      "\t Val. Loss: 0.337 |  Val. Acc: 92.20% | Val. F1_score: 0.341\n",
      "Epoch: 108 | Epoch Time: 0m 49s\n",
      "\tTrain Loss: 0.091 | Train Acc: 97.50% | Train F1_score: 0.782\n",
      "\t Val. Loss: 0.365 |  Val. Acc: 92.29% | Val. F1_score: 0.329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 109 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.087 | Train Acc: 97.60% | Train F1_score: 0.800\n",
      "\t Val. Loss: 0.364 |  Val. Acc: 92.24% | Val. F1_score: 0.338\n",
      "Epoch: 110 | Epoch Time: 0m 47s\n",
      "\tTrain Loss: 0.092 | Train Acc: 97.46% | Train F1_score: 0.780\n",
      "\t Val. Loss: 0.348 |  Val. Acc: 92.36% | Val. F1_score: 0.338\n",
      "Epoch: 111 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.092 | Train Acc: 97.44% | Train F1_score: 0.774\n",
      "\t Val. Loss: 0.357 |  Val. Acc: 92.49% | Val. F1_score: 0.329\n",
      "Epoch: 112 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.088 | Train Acc: 97.65% | Train F1_score: 0.795\n",
      "\t Val. Loss: 0.362 |  Val. Acc: 92.28% | Val. F1_score: 0.363\n",
      "Epoch: 113 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.091 | Train Acc: 97.47% | Train F1_score: 0.782\n",
      "\t Val. Loss: 0.375 |  Val. Acc: 92.52% | Val. F1_score: 0.349\n",
      "Epoch: 114 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.090 | Train Acc: 97.49% | Train F1_score: 0.783\n",
      "\t Val. Loss: 0.369 |  Val. Acc: 92.36% | Val. F1_score: 0.363\n",
      "Epoch: 115 | Epoch Time: 0m 46s\n",
      "\tTrain Loss: 0.090 | Train Acc: 97.51% | Train F1_score: 0.784\n",
      "\t Val. Loss: 0.390 |  Val. Acc: 92.17% | Val. F1_score: 0.366\n",
      "Epoch: 116 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.086 | Train Acc: 97.68% | Train F1_score: 0.796\n",
      "\t Val. Loss: 0.402 |  Val. Acc: 92.28% | Val. F1_score: 0.348\n",
      "Epoch: 117 | Epoch Time: 0m 46s\n",
      "\tTrain Loss: 0.092 | Train Acc: 97.43% | Train F1_score: 0.784\n",
      "\t Val. Loss: 0.355 |  Val. Acc: 92.22% | Val. F1_score: 0.321\n",
      "Epoch: 118 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.090 | Train Acc: 97.52% | Train F1_score: 0.786\n",
      "\t Val. Loss: 0.373 |  Val. Acc: 92.46% | Val. F1_score: 0.337\n",
      "Epoch: 119 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.085 | Train Acc: 97.75% | Train F1_score: 0.805\n",
      "\t Val. Loss: 0.365 |  Val. Acc: 92.23% | Val. F1_score: 0.327\n",
      "Epoch: 120 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.082 | Train Acc: 97.78% | Train F1_score: 0.814\n",
      "\t Val. Loss: 0.399 |  Val. Acc: 92.02% | Val. F1_score: 0.364\n",
      "Epoch: 121 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.089 | Train Acc: 97.58% | Train F1_score: 0.789\n",
      "\t Val. Loss: 0.356 |  Val. Acc: 92.22% | Val. F1_score: 0.324\n",
      "Epoch: 122 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.089 | Train Acc: 97.55% | Train F1_score: 0.783\n",
      "\t Val. Loss: 0.364 |  Val. Acc: 92.24% | Val. F1_score: 0.359\n",
      "Epoch: 123 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.080 | Train Acc: 97.90% | Train F1_score: 0.817\n",
      "\t Val. Loss: 0.396 |  Val. Acc: 92.12% | Val. F1_score: 0.326\n",
      "Epoch: 124 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.080 | Train Acc: 97.87% | Train F1_score: 0.816\n",
      "\t Val. Loss: 0.400 |  Val. Acc: 91.94% | Val. F1_score: 0.349\n",
      "Epoch: 125 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.078 | Train Acc: 97.99% | Train F1_score: 0.832\n",
      "\t Val. Loss: 0.422 |  Val. Acc: 91.88% | Val. F1_score: 0.323\n",
      "Epoch: 126 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.084 | Train Acc: 97.78% | Train F1_score: 0.810\n",
      "\t Val. Loss: 0.381 |  Val. Acc: 92.20% | Val. F1_score: 0.376\n",
      "Epoch: 127 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.097 | Train Acc: 97.38% | Train F1_score: 0.777\n",
      "\t Val. Loss: 0.321 |  Val. Acc: 92.14% | Val. F1_score: 0.350\n",
      "Epoch: 128 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.083 | Train Acc: 97.76% | Train F1_score: 0.813\n",
      "\t Val. Loss: 0.384 |  Val. Acc: 92.13% | Val. F1_score: 0.332\n",
      "Epoch: 129 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.081 | Train Acc: 97.84% | Train F1_score: 0.819\n",
      "\t Val. Loss: 0.384 |  Val. Acc: 92.17% | Val. F1_score: 0.336\n",
      "Epoch: 130 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.080 | Train Acc: 97.83% | Train F1_score: 0.813\n",
      "\t Val. Loss: 0.400 |  Val. Acc: 92.24% | Val. F1_score: 0.355\n",
      "Epoch: 131 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.076 | Train Acc: 97.96% | Train F1_score: 0.837\n",
      "\t Val. Loss: 0.409 |  Val. Acc: 92.14% | Val. F1_score: 0.342\n",
      "Epoch: 132 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.081 | Train Acc: 97.83% | Train F1_score: 0.815\n",
      "\t Val. Loss: 0.418 |  Val. Acc: 91.88% | Val. F1_score: 0.360\n",
      "Epoch: 133 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.079 | Train Acc: 97.88% | Train F1_score: 0.817\n",
      "\t Val. Loss: 0.365 |  Val. Acc: 92.40% | Val. F1_score: 0.341\n",
      "Epoch: 134 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.083 | Train Acc: 97.70% | Train F1_score: 0.800\n",
      "\t Val. Loss: 0.393 |  Val. Acc: 92.05% | Val. F1_score: 0.334\n",
      "Epoch: 135 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.076 | Train Acc: 98.00% | Train F1_score: 0.827\n",
      "\t Val. Loss: 0.394 |  Val. Acc: 91.94% | Val. F1_score: 0.336\n",
      "Epoch: 136 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.078 | Train Acc: 97.89% | Train F1_score: 0.819\n",
      "\t Val. Loss: 0.394 |  Val. Acc: 92.06% | Val. F1_score: 0.366\n",
      "Epoch: 137 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.075 | Train Acc: 97.98% | Train F1_score: 0.830\n",
      "\t Val. Loss: 0.423 |  Val. Acc: 92.01% | Val. F1_score: 0.341\n",
      "Epoch: 138 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.075 | Train Acc: 97.98% | Train F1_score: 0.829\n",
      "\t Val. Loss: 0.405 |  Val. Acc: 92.45% | Val. F1_score: 0.387\n",
      "Epoch: 139 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.073 | Train Acc: 98.02% | Train F1_score: 0.831\n",
      "\t Val. Loss: 0.430 |  Val. Acc: 91.93% | Val. F1_score: 0.328\n",
      "Epoch: 140 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.072 | Train Acc: 98.12% | Train F1_score: 0.841\n",
      "\t Val. Loss: 0.427 |  Val. Acc: 92.10% | Val. F1_score: 0.339\n",
      "Epoch: 141 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.077 | Train Acc: 97.96% | Train F1_score: 0.819\n",
      "\t Val. Loss: 0.412 |  Val. Acc: 92.20% | Val. F1_score: 0.324\n",
      "Epoch: 142 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.073 | Train Acc: 98.05% | Train F1_score: 0.834\n",
      "\t Val. Loss: 0.396 |  Val. Acc: 92.19% | Val. F1_score: 0.358\n",
      "Epoch: 143 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.072 | Train Acc: 98.00% | Train F1_score: 0.837\n",
      "\t Val. Loss: 0.440 |  Val. Acc: 92.22% | Val. F1_score: 0.336\n",
      "Epoch: 144 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.071 | Train Acc: 98.03% | Train F1_score: 0.834\n",
      "\t Val. Loss: 0.434 |  Val. Acc: 91.93% | Val. F1_score: 0.317\n",
      "Epoch: 145 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.074 | Train Acc: 97.94% | Train F1_score: 0.824\n",
      "\t Val. Loss: 0.409 |  Val. Acc: 92.01% | Val. F1_score: 0.330\n",
      "Epoch: 146 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.072 | Train Acc: 98.08% | Train F1_score: 0.843\n",
      "\t Val. Loss: 0.406 |  Val. Acc: 92.00% | Val. F1_score: 0.345\n",
      "Epoch: 147 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.073 | Train Acc: 97.89% | Train F1_score: 0.830\n",
      "\t Val. Loss: 0.426 |  Val. Acc: 92.14% | Val. F1_score: 0.368\n",
      "Epoch: 148 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.079 | Train Acc: 97.83% | Train F1_score: 0.814\n",
      "\t Val. Loss: 0.367 |  Val. Acc: 92.28% | Val. F1_score: 0.359\n",
      "Epoch: 149 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.068 | Train Acc: 98.14% | Train F1_score: 0.846\n",
      "\t Val. Loss: 0.418 |  Val. Acc: 92.08% | Val. F1_score: 0.327\n",
      "Epoch: 150 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.065 | Train Acc: 98.22% | Train F1_score: 0.849\n",
      "\t Val. Loss: 0.426 |  Val. Acc: 92.01% | Val. F1_score: 0.330\n",
      "Epoch: 151 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.061 | Train Acc: 98.36% | Train F1_score: 0.861\n",
      "\t Val. Loss: 0.465 |  Val. Acc: 91.78% | Val. F1_score: 0.338\n",
      "Epoch: 152 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.069 | Train Acc: 98.06% | Train F1_score: 0.835\n",
      "\t Val. Loss: 0.432 |  Val. Acc: 92.23% | Val. F1_score: 0.370\n",
      "Epoch: 153 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.077 | Train Acc: 97.79% | Train F1_score: 0.821\n",
      "\t Val. Loss: 0.416 |  Val. Acc: 92.19% | Val. F1_score: 0.361\n",
      "Epoch: 154 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.064 | Train Acc: 98.20% | Train F1_score: 0.843\n",
      "\t Val. Loss: 0.432 |  Val. Acc: 91.60% | Val. F1_score: 0.341\n",
      "Epoch: 155 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.061 | Train Acc: 98.29% | Train F1_score: 0.856\n",
      "\t Val. Loss: 0.451 |  Val. Acc: 91.87% | Val. F1_score: 0.346\n",
      "Epoch: 156 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.059 | Train Acc: 98.34% | Train F1_score: 0.853\n",
      "\t Val. Loss: 0.483 |  Val. Acc: 92.01% | Val. F1_score: 0.322\n",
      "Epoch: 157 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.059 | Train Acc: 98.28% | Train F1_score: 0.852\n",
      "\t Val. Loss: 0.453 |  Val. Acc: 92.65% | Val. F1_score: 0.357\n",
      "Epoch: 158 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.069 | Train Acc: 98.02% | Train F1_score: 0.829\n",
      "\t Val. Loss: 0.410 |  Val. Acc: 91.60% | Val. F1_score: 0.354\n",
      "Epoch: 159 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.069 | Train Acc: 97.93% | Train F1_score: 0.825\n",
      "\t Val. Loss: 0.407 |  Val. Acc: 92.24% | Val. F1_score: 0.340\n",
      "Epoch: 160 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.060 | Train Acc: 98.26% | Train F1_score: 0.856\n",
      "\t Val. Loss: 0.428 |  Val. Acc: 92.13% | Val. F1_score: 0.369\n",
      "Epoch: 161 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.055 | Train Acc: 98.39% | Train F1_score: 0.866\n",
      "\t Val. Loss: 0.448 |  Val. Acc: 92.16% | Val. F1_score: 0.324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 162 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.060 | Train Acc: 98.32% | Train F1_score: 0.857\n",
      "\t Val. Loss: 0.424 |  Val. Acc: 92.45% | Val. F1_score: 0.339\n",
      "Epoch: 163 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.062 | Train Acc: 98.24% | Train F1_score: 0.850\n",
      "\t Val. Loss: 0.444 |  Val. Acc: 91.96% | Val. F1_score: 0.357\n",
      "Epoch: 164 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.053 | Train Acc: 98.40% | Train F1_score: 0.867\n",
      "\t Val. Loss: 0.459 |  Val. Acc: 91.89% | Val. F1_score: 0.329\n",
      "Epoch: 165 | Epoch Time: 0m 48s\n",
      "\tTrain Loss: 0.062 | Train Acc: 98.17% | Train F1_score: 0.842\n",
      "\t Val. Loss: 0.467 |  Val. Acc: 91.89% | Val. F1_score: 0.360\n",
      "Epoch: 166 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.052 | Train Acc: 98.44% | Train F1_score: 0.873\n",
      "\t Val. Loss: 0.472 |  Val. Acc: 91.75% | Val. F1_score: 0.348\n",
      "Epoch: 167 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.053 | Train Acc: 98.39% | Train F1_score: 0.872\n",
      "\t Val. Loss: 0.466 |  Val. Acc: 92.16% | Val. F1_score: 0.351\n",
      "Epoch: 168 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.056 | Train Acc: 98.32% | Train F1_score: 0.860\n",
      "\t Val. Loss: 0.458 |  Val. Acc: 91.80% | Val. F1_score: 0.321\n",
      "Epoch: 169 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.060 | Train Acc: 98.14% | Train F1_score: 0.854\n",
      "\t Val. Loss: 0.451 |  Val. Acc: 92.14% | Val. F1_score: 0.346\n",
      "Epoch: 170 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.048 | Train Acc: 98.63% | Train F1_score: 0.886\n",
      "\t Val. Loss: 0.490 |  Val. Acc: 91.69% | Val. F1_score: 0.351\n",
      "Epoch: 171 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.053 | Train Acc: 98.45% | Train F1_score: 0.869\n",
      "\t Val. Loss: 0.464 |  Val. Acc: 91.57% | Val. F1_score: 0.340\n",
      "Epoch: 172 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.047 | Train Acc: 98.59% | Train F1_score: 0.879\n",
      "\t Val. Loss: 0.482 |  Val. Acc: 91.72% | Val. F1_score: 0.365\n",
      "Epoch: 173 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.045 | Train Acc: 98.66% | Train F1_score: 0.899\n",
      "\t Val. Loss: 0.498 |  Val. Acc: 91.93% | Val. F1_score: 0.334\n",
      "Epoch: 174 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.050 | Train Acc: 98.49% | Train F1_score: 0.871\n",
      "\t Val. Loss: 0.488 |  Val. Acc: 91.87% | Val. F1_score: 0.352\n",
      "Epoch: 175 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.050 | Train Acc: 98.49% | Train F1_score: 0.882\n",
      "\t Val. Loss: 0.473 |  Val. Acc: 91.95% | Val. F1_score: 0.349\n",
      "Epoch: 176 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.044 | Train Acc: 98.68% | Train F1_score: 0.899\n",
      "\t Val. Loss: 0.496 |  Val. Acc: 91.49% | Val. F1_score: 0.344\n",
      "Epoch: 177 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.048 | Train Acc: 98.58% | Train F1_score: 0.881\n",
      "\t Val. Loss: 0.484 |  Val. Acc: 91.72% | Val. F1_score: 0.357\n",
      "Epoch: 178 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.043 | Train Acc: 98.69% | Train F1_score: 0.894\n",
      "\t Val. Loss: 0.474 |  Val. Acc: 91.72% | Val. F1_score: 0.349\n",
      "Epoch: 179 | Epoch Time: 0m 47s\n",
      "\tTrain Loss: 0.072 | Train Acc: 97.81% | Train F1_score: 0.828\n",
      "\t Val. Loss: 0.410 |  Val. Acc: 91.99% | Val. F1_score: 0.347\n",
      "Epoch: 180 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.055 | Train Acc: 98.38% | Train F1_score: 0.871\n",
      "\t Val. Loss: 0.405 |  Val. Acc: 91.76% | Val. F1_score: 0.327\n",
      "Epoch: 181 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.040 | Train Acc: 98.82% | Train F1_score: 0.911\n",
      "\t Val. Loss: 0.464 |  Val. Acc: 91.89% | Val. F1_score: 0.363\n",
      "Epoch: 182 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.041 | Train Acc: 98.84% | Train F1_score: 0.907\n",
      "\t Val. Loss: 0.467 |  Val. Acc: 92.16% | Val. F1_score: 0.364\n",
      "Epoch: 183 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.041 | Train Acc: 98.80% | Train F1_score: 0.892\n",
      "\t Val. Loss: 0.488 |  Val. Acc: 91.78% | Val. F1_score: 0.331\n",
      "Epoch: 184 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.036 | Train Acc: 98.90% | Train F1_score: 0.908\n",
      "\t Val. Loss: 0.493 |  Val. Acc: 91.80% | Val. F1_score: 0.345\n",
      "Epoch: 185 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.039 | Train Acc: 98.81% | Train F1_score: 0.904\n",
      "\t Val. Loss: 0.514 |  Val. Acc: 91.81% | Val. F1_score: 0.340\n",
      "Epoch: 186 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.044 | Train Acc: 98.64% | Train F1_score: 0.889\n",
      "\t Val. Loss: 0.467 |  Val. Acc: 91.80% | Val. F1_score: 0.329\n",
      "Epoch: 187 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.046 | Train Acc: 98.63% | Train F1_score: 0.888\n",
      "\t Val. Loss: 0.471 |  Val. Acc: 91.69% | Val. F1_score: 0.357\n",
      "Epoch: 188 | Epoch Time: 0m 46s\n",
      "\tTrain Loss: 0.034 | Train Acc: 99.01% | Train F1_score: 0.921\n",
      "\t Val. Loss: 0.455 |  Val. Acc: 91.69% | Val. F1_score: 0.335\n",
      "Epoch: 189 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.038 | Train Acc: 98.89% | Train F1_score: 0.909\n",
      "\t Val. Loss: 0.478 |  Val. Acc: 91.35% | Val. F1_score: 0.351\n",
      "Epoch: 190 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.036 | Train Acc: 98.91% | Train F1_score: 0.913\n",
      "\t Val. Loss: 0.497 |  Val. Acc: 91.87% | Val. F1_score: 0.377\n",
      "Epoch: 191 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.038 | Train Acc: 98.83% | Train F1_score: 0.909\n",
      "\t Val. Loss: 0.488 |  Val. Acc: 91.53% | Val. F1_score: 0.355\n",
      "Epoch: 192 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.042 | Train Acc: 98.73% | Train F1_score: 0.897\n",
      "\t Val. Loss: 0.454 |  Val. Acc: 91.28% | Val. F1_score: 0.328\n",
      "Epoch: 193 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.040 | Train Acc: 98.82% | Train F1_score: 0.909\n",
      "\t Val. Loss: 0.484 |  Val. Acc: 91.71% | Val. F1_score: 0.358\n",
      "Epoch: 194 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.045 | Train Acc: 98.64% | Train F1_score: 0.892\n",
      "\t Val. Loss: 0.457 |  Val. Acc: 92.10% | Val. F1_score: 0.370\n",
      "Epoch: 195 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.039 | Train Acc: 98.76% | Train F1_score: 0.905\n",
      "\t Val. Loss: 0.476 |  Val. Acc: 91.84% | Val. F1_score: 0.333\n",
      "Epoch: 196 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.035 | Train Acc: 98.95% | Train F1_score: 0.910\n",
      "\t Val. Loss: 0.466 |  Val. Acc: 91.70% | Val. F1_score: 0.354\n",
      "Epoch: 197 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.041 | Train Acc: 98.80% | Train F1_score: 0.908\n",
      "\t Val. Loss: 0.448 |  Val. Acc: 92.18% | Val. F1_score: 0.366\n",
      "Epoch: 198 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.038 | Train Acc: 98.86% | Train F1_score: 0.909\n",
      "\t Val. Loss: 0.469 |  Val. Acc: 92.19% | Val. F1_score: 0.380\n",
      "Epoch: 199 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.033 | Train Acc: 99.08% | Train F1_score: 0.925\n",
      "\t Val. Loss: 0.477 |  Val. Acc: 91.84% | Val. F1_score: 0.358\n",
      "Epoch: 200 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.031 | Train Acc: 99.05% | Train F1_score: 0.919\n",
      "\t Val. Loss: 0.508 |  Val. Acc: 92.01% | Val. F1_score: 0.364\n"
     ]
    }
   ],
   "source": [
    "#TRAINING!\n",
    "N_EPOCHS = 200\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc, train_f_score = train(model, train_data_loader, optimizer, criterion)\n",
    "    valid_loss, valid_acc, valid_f_score = evaluate(model, eval_data_loader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'lstm_version-4.0.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train F1_score: {train_f_score:.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% | Val. F1_score: {valid_f_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(10, 20, num_layers=2)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.LSTM(10, 20, 2)\n",
    "rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1347, -1.5577,  0.6494, -1.0098,  1.7483,  0.2658,  0.2991,\n",
       "           0.0336,  0.3152, -0.5713],\n",
       "         [-0.6693, -0.3471,  0.8272,  0.0490,  0.7425, -1.4127, -0.7675,\n",
       "          -0.8499,  0.7907,  0.6289],\n",
       "         [ 0.6289,  0.6942,  0.8110,  0.1560,  0.4390, -0.9293, -1.7457,\n",
       "           1.1537, -1.9180, -1.2843]],\n",
       "\n",
       "        [[ 1.1862,  0.7990,  0.0356,  1.0290,  0.9737,  0.1894,  1.2703,\n",
       "          -0.1135, -0.6481,  0.4043],\n",
       "         [ 0.1784,  0.0405, -0.9773, -2.0575,  1.2846,  0.3438,  0.3358,\n",
       "          -1.0450,  0.1550,  0.8151],\n",
       "         [ 0.1318,  1.8710, -0.8423, -0.1986,  0.5868,  1.0136,  0.2237,\n",
       "           0.8186,  1.7981, -0.2298]],\n",
       "\n",
       "        [[ 0.6371,  0.9076,  1.6369, -0.5735, -0.1101, -0.1481,  0.5099,\n",
       "           0.3916, -0.6552,  1.5432],\n",
       "         [-0.8548,  0.9731, -0.3098, -0.9160, -0.0370,  1.8049,  0.6302,\n",
       "           0.7893,  0.5934,  0.4143],\n",
       "         [-0.3266, -1.0510, -1.5049,  0.5987,  0.5945, -0.0469, -0.1752,\n",
       "          -1.4014, -1.2407, -0.5458]],\n",
       "\n",
       "        [[-0.7859, -0.2570, -0.8651, -1.4756,  2.2897, -0.1295, -1.9912,\n",
       "          -0.7877, -0.1139, -0.5788],\n",
       "         [-1.0541, -1.4359, -1.0268, -1.2546, -0.8356,  0.0102, -0.4811,\n",
       "          -0.1202,  0.3458, -1.7744],\n",
       "         [ 0.2558, -2.2613,  0.1061,  0.5187,  0.6879,  1.0600, -0.0059,\n",
       "          -0.3336,  1.2639,  0.5610]],\n",
       "\n",
       "        [[-0.4667,  1.7586, -1.3760,  1.6841,  1.2924, -0.2324, -0.2084,\n",
       "           0.5315,  0.1988,  0.2920],\n",
       "         [ 1.4669, -0.0137,  0.1663, -1.5033,  0.8824,  0.5897,  0.5319,\n",
       "          -0.0557,  0.8793,  0.2068],\n",
       "         [-0.7439, -1.2473, -0.3910, -0.2127, -1.2580, -0.1110, -1.0256,\n",
       "           0.4217,  1.3830,  0.7965]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(5, 3, 10)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6320, -1.3230, -0.1048, -1.0491,  0.2811, -0.1304,  1.1368,\n",
       "           0.2260,  0.0196, -0.6081, -0.4820, -0.1535, -1.1211,  1.6573,\n",
       "          -1.3806, -0.6483,  0.3105,  1.8602,  2.3665, -1.9099],\n",
       "         [-0.9171,  1.7928, -1.0056, -0.3919, -0.6205, -1.1237, -0.3242,\n",
       "           0.8012,  1.1795, -1.1276,  0.1794,  0.3691,  0.7555,  0.1353,\n",
       "           0.1291,  0.3518, -0.0308,  0.5966, -0.5567,  1.2217],\n",
       "         [-0.2085,  1.5343, -0.0105,  0.5676, -0.1690,  0.0255, -0.7709,\n",
       "           0.5966,  0.2893,  1.4010, -0.4583, -1.9280, -0.3356, -0.2181,\n",
       "          -0.2710, -0.8887,  1.1676,  1.3073, -0.1747,  0.3372]],\n",
       "\n",
       "        [[-1.1013,  2.6724, -0.8474, -0.6863,  1.3936,  0.0934, -0.2287,\n",
       "           0.6535,  0.0348,  1.0603,  0.7382, -0.5521, -1.2984, -1.7420,\n",
       "           0.1296, -0.6031, -0.7196,  1.0153, -0.4114, -0.3086],\n",
       "         [-0.6933, -0.9621,  1.0742, -0.0543, -0.2513,  1.1321,  0.9281,\n",
       "           0.3317, -0.1270, -0.3376, -0.4320,  1.1565,  0.8985,  0.7913,\n",
       "          -0.9962,  2.6254, -0.6323,  0.3609,  1.6113, -1.1966],\n",
       "         [ 0.0616,  0.0039,  0.3417, -0.2622,  0.1317, -0.3929, -0.2691,\n",
       "          -0.8804, -1.8110,  1.4803,  0.1393,  1.0633,  1.2204,  0.7676,\n",
       "           1.8507, -1.2605, -0.0097,  0.5183, -0.5213,  1.2242]]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = torch.randn(2, 3, 20)\n",
    "h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = torch.randn(2, 3, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
