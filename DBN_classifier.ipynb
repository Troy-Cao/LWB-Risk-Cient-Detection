{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DBN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHPsm8PtQsvo"
      },
      "source": [
        "Loading the package & Configure the Environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhF4jCA49ZYt"
      },
      "source": [
        "! kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MVUg2f8QqCq",
        "outputId": "06ca425c-2d67-40fb-f78a-5f67319765bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "from tqdm import tqdm\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7411 sha256=1c42ea2cf91ca3701f548fa1e5122e4aee055b57f06a328b4a76e2db68043d32\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.8 GB  | Proc size: 112.5 MB\n",
            "GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total 15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQwrauKNQ2gw",
        "outputId": "dc1f6d5f-2507-45e9-b626-4cd9913d8eec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"There are {} GPUs available.\".format(torch.cuda.device_count()))\n",
        "    print(\"We will use GPU {}\".format(torch.cuda.get_device_name(0)))\n",
        "else:\n",
        "    print(\"There is no GPU available, using the CPU instead!\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPUs available.\n",
            "We will use GPU Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NAGKU0WQ6PK"
      },
      "source": [
        "Now Loading the Data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juJ_hb_rQ-fG"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "part_1 = pd.read_csv(\"dc_part_v3.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNhKTxqDRAVH",
        "outputId": "67cf31fc-bab7-43c6-e9d8-1d6dd7ed8e42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "part_1.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(124293, 147)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66b1gkdeRCgU"
      },
      "source": [
        "init_record = part_1 \n",
        "init_record = init_record.set_index(['_key_client_id', '_key_occurreddate_month'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjEitrsPRE0H",
        "outputId": "0aab7ca3-5933-4d21-c8cf-3d9f9499692d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "init_record.head(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>incident_catgry_care_concern_piv</th>\n",
              "      <th>incident_catgry_medication_piv</th>\n",
              "      <th>incident_catgry_medical_piv</th>\n",
              "      <th>incident_catgry__piv</th>\n",
              "      <th>incident_catgry_death_piv</th>\n",
              "      <th>incident_catgry_property_and_vehicles_piv</th>\n",
              "      <th>incident_catgry_physical_and_sexual_assault_piv</th>\n",
              "      <th>incident_catgry_client_missing_piv</th>\n",
              "      <th>incident_catgry_standard_of_care_soc_piv</th>\n",
              "      <th>incident_catgry_absconding_minor_significant_qld_jurisdi_piv</th>\n",
              "      <th>incident_catgry_emergency_situation_piv</th>\n",
              "      <th>incident_catgry_restrictive_practices_piv</th>\n",
              "      <th>incident_catgry_media_piv</th>\n",
              "      <th>incident_catgry_drugs_alcohol_piv</th>\n",
              "      <th>incident_catgry_behaviour_piv</th>\n",
              "      <th>incident_catgry_client_wellbeing_piv</th>\n",
              "      <th>minor_event_total</th>\n",
              "      <th>significant_event_total</th>\n",
              "      <th>critical_event_total</th>\n",
              "      <th>Total_incident_count</th>\n",
              "      <th>response_variable</th>\n",
              "      <th>incident_subcatgry_verbal_abuse____nsw__piv</th>\n",
              "      <th>incident_subcatgry_breach_of_legislatio_piv</th>\n",
              "      <th>incident_subcatgry_ill_treatment_piv</th>\n",
              "      <th>incident_subcatgry_public_health_risk_piv</th>\n",
              "      <th>incident_subcatgry_prn_administered_piv</th>\n",
              "      <th>incident_subcatgry_family_and_domestic__piv</th>\n",
              "      <th>incident_subcatgry_reaction_to_medicati_piv</th>\n",
              "      <th>incident_subcatgry_behaviour_of_concern_piv</th>\n",
              "      <th>incident_subcatgry_possession_of_weapon_piv</th>\n",
              "      <th>incident_subcatgry_unknown_piv</th>\n",
              "      <th>incident_subcatgry_restricted_practice_piv</th>\n",
              "      <th>incident_subcatgry_physical_aggression_piv</th>\n",
              "      <th>incident_subcatgry_visitor_refused_acce_piv</th>\n",
              "      <th>incident_subcatgry_restrictive_practice_piv</th>\n",
              "      <th>incident_subcatgry_adverse_piv</th>\n",
              "      <th>incident_subcatgry_client_piv</th>\n",
              "      <th>incident_subcatgry_personal_finances_piv</th>\n",
              "      <th>incident_subcatgry_sexual_exploitation_piv</th>\n",
              "      <th>incident_subcatgry_negative_experience__piv</th>\n",
              "      <th>...</th>\n",
              "      <th>diagnosiscat_medical_condition_ongoing_piv</th>\n",
              "      <th>diagnosiscat_personality_disorder_piv</th>\n",
              "      <th>diagnosiscat_childhood_disorder_piv</th>\n",
              "      <th>diagnosiscat_adjustment_disorder_piv</th>\n",
              "      <th>diagnosiscat_tuberous_sclerosis_piv</th>\n",
              "      <th>diagnosiscat_infectious_disease_piv</th>\n",
              "      <th>diagnosiscat_autism_spectrum_disorder_piv</th>\n",
              "      <th>diagnosiscat_fragile_x_syndrome_piv</th>\n",
              "      <th>diagnosiscat_hearing_sensory_piv</th>\n",
              "      <th>diagnosiscat_psychotic_disorder_piv</th>\n",
              "      <th>diagnosiscat_down_syndrome_piv</th>\n",
              "      <th>diagnosiscat_multiple_sclerosis_piv</th>\n",
              "      <th>diagnosiscat_substance_related_disorder_piv</th>\n",
              "      <th>diagnosiscat_scoliosis_piv</th>\n",
              "      <th>diagnosiscat_anxiety_disorder_piv</th>\n",
              "      <th>diagnosiscat_vision_sensory_piv</th>\n",
              "      <th>diagnosiscat_foetal_alcohol_syndrome_piv</th>\n",
              "      <th>diagnosiscat_muscular_dystrophy_piv</th>\n",
              "      <th>diagnosiscat_intellectual_disability_piv</th>\n",
              "      <th>diagnosiscat_medical_condition_temporary_piv</th>\n",
              "      <th>diagnosiscat_developmental_delay_0_5_years_only_piv</th>\n",
              "      <th>diagnosiscat_specific_learning_difficulties_other_than_intellectual_piv</th>\n",
              "      <th>diagnosiscat_pervasive_developmental_delay_piv</th>\n",
              "      <th>diagnosiscat_attention_deficit_hyperactivity_disorder_piv</th>\n",
              "      <th>diagnosiscat_high_risk_clinical_needs_piv</th>\n",
              "      <th>diagnosiscat_deafblind_dual_sensory_piv</th>\n",
              "      <th>diagnosiscat_mood_disorder_piv</th>\n",
              "      <th>diagnosiscat_speech_impairment_piv</th>\n",
              "      <th>diagnosiscat_para_quadri_tetra_hemiplegia_piv</th>\n",
              "      <th>diagnosiscat_motor_neurone_disease_piv</th>\n",
              "      <th>diagnosiscat_acquired_brain_injury_piv</th>\n",
              "      <th>diagnosiscat_spina_bifida_piv</th>\n",
              "      <th>diagnosiscat_psychiatric_disability_piv</th>\n",
              "      <th>diagnosiscat_other_physical_piv</th>\n",
              "      <th>diagnosiscat_other_neurological_piv</th>\n",
              "      <th>diagnosiscat_cerebral_palsy_piv</th>\n",
              "      <th>diagnosiscat_rett_syndrome_piv</th>\n",
              "      <th>diagnosiscat_prader_willi_syndrome_piv</th>\n",
              "      <th>diagnosiscat_other_piv</th>\n",
              "      <th>diagnosiscat_dementia_piv</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>_key_client_id</th>\n",
              "      <th>_key_occurreddate_month</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">0000D172-EA88-432F-8235-9FAA00D29072</th>\n",
              "      <th>2019-04-01T00:00:00.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-05-01T00:00:00.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-06-01T00:00:00.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-01T00:00:00.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-01T00:00:00.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09-01T00:00:00.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-01T00:00:00.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-11-01T00:00:00.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-01T00:00:00.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-01T00:00:00.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 145 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                              incident_catgry_care_concern_piv  ...  diagnosiscat_dementia_piv\n",
              "_key_client_id                       _key_occurreddate_month                                    ...                           \n",
              "0000D172-EA88-432F-8235-9FAA00D29072 2019-04-01T00:00:00.0                                   0  ...                          0\n",
              "                                     2019-05-01T00:00:00.0                                   0  ...                          0\n",
              "                                     2019-06-01T00:00:00.0                                   0  ...                          0\n",
              "                                     2019-07-01T00:00:00.0                                   0  ...                          0\n",
              "                                     2019-08-01T00:00:00.0                                   0  ...                          0\n",
              "                                     2019-09-01T00:00:00.0                                   0  ...                          0\n",
              "                                     2019-10-01T00:00:00.0                                   0  ...                          0\n",
              "                                     2019-11-01T00:00:00.0                                   0  ...                          0\n",
              "                                     2019-12-01T00:00:00.0                                   0  ...                          0\n",
              "                                     2020-01-01T00:00:00.0                                   0  ...                          0\n",
              "\n",
              "[10 rows x 145 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqEQTMo4RGpX",
        "outputId": "c3154e43-a24e-47c0-97a8-813c8393a197",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"The Length of Loading Data is {}\".format(len(init_record)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Length of Loading Data is 124293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoS1618hRQNc",
        "outputId": "f176e6ff-c5d3-4f15-aaf0-87974da3791e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# summarize the total number of clients (year)\n",
        "index_dict = {}\n",
        "for ind in init_record.index:\n",
        "    if ind[0] not in index_dict:\n",
        "        index_dict[ind[0]] = []\n",
        "        index_dict[ind[0]].append(ind[1])\n",
        "    else:\n",
        "        index_dict[ind[0]].append(ind[1])\n",
        "\n",
        "print(len(index_dict))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE49XcZZRS1E",
        "outputId": "8e2b0eb5-b76f-4a31-91da-3f94d7d6e77b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Plot the distribution of record number\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "record_num = defaultdict(list)\n",
        "record_list = []\n",
        "\n",
        "for id, value in tqdm(index_dict.items()):\n",
        "    record_num[len(value)].append(id)\n",
        "    record_list.append(len(value))\n",
        "\n",
        "print('\\nThe Length of the record number dictionary is {}'.format(len(record_num)))\n",
        "print(len(record_list))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14387/14387 [00:00<00:00, 843917.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The Length of the record number dictionary is 12\n",
            "14387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPZKdKrER3AR",
        "outputId": "f8b9e1d7-c49e-494f-bbac-5d23b7f22ebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title('Distribution of Record Length',fontsize=20)\n",
        "plt.xlabel(u'Record Length',fontsize=14)\n",
        "plt.ylabel(u'Frenquency',fontsize=14)\n",
        "plt.hist(record_list, edgecolor='k', alpha=0.35)\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxchc1kqSZ28",
        "outputId": "fdabee6a-0629-458b-bec7-203e46fa4f9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Store the full-record client record in initial_data\n",
        "initial_data = {}\n",
        "for inde in index_dict.keys():\n",
        "    if len(index_dict[inde]) == 12:\n",
        "        initial_data[inde] = init_record.loc[inde]\n",
        "print(len(initial_data))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7380\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of1_GSc7SwFz",
        "outputId": "a2fc2328-81d6-410c-a481-a951d72d7b0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Build the train dataset\n",
        "\n",
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "for key in tqdm(initial_data.keys()):\n",
        "    all_labels.append(initial_data[key]['response_variable'])\n",
        "    temp_sample = initial_data[key].drop(['response_variable'], axis=1)\n",
        "    all_features.append(temp_sample)\n",
        "\n",
        "print('\\nThe length of All the feature is {}'.format(len(all_features)))\n",
        "print('\\nThe length of All labels is {}'.format(len(all_labels)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7380/7380 [00:05<00:00, 1382.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The length of All the feature is 7380\n",
            "\n",
            "The length of All labels is 7380\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqWoN2VNS07o",
        "outputId": "c57d2766-a892-47e6-9ae9-b8d46c12d9a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "feature_sample = []\n",
        "label_sample = []\n",
        "\n",
        "\n",
        "## k is the window size\n",
        "def split_df(feature_data, label_data, k):\n",
        "    \n",
        "    df_list = []\n",
        "    label_list = []\n",
        "    i = 0\n",
        "    while i+k < feature_data.shape[0]:\n",
        "        temp = feature_data[i: i+k, :]\n",
        "        df_list.append(temp)\n",
        "        label_list.append(label_data[i+k])\n",
        "        i += 1\n",
        "    return df_list, label_list\n",
        "\n",
        "for i in tqdm(range(len(all_features))):\n",
        "    feature_temp_list, label_temp_list = split_df(all_features[i].values, all_labels[i].values, 4)\n",
        "    for feature in feature_temp_list:\n",
        "        feature_sample.append(feature)\n",
        "    # feature_sample.append(feature_temp_list) \n",
        "    for label in label_temp_list:\n",
        "        label_sample.append(label) ## When the sample size to 7380, should be 59040\n",
        "    # label_sample.append(label_temp_list[-1]) ## Should be 5000\n",
        "print(len(feature_sample))\n",
        "print(len(label_sample))  ## the length should be 59040"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7380/7380 [00:00<00:00, 65298.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "59040\n",
            "59040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nyv_Bcy3TM3e"
      },
      "source": [
        "Now Construct the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOtKXd8Ju7EM"
      },
      "source": [
        "from DBN import DBN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "import numpy as np"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlAo-e9HZ-EL"
      },
      "source": [
        "class DBNmodel(nn.Module):\n",
        "    def __init__(self, visible_unit, hidden_unit, k, learning_rate, learning_rate_decay, xvaier_init, use_gpu, \n",
        "                 num_epochs, batch_size, input_dim, class_num):\n",
        "        super().__init__()\n",
        "        self.dbn = DBN(visible_unit= visible_unit,\n",
        "                hidden_unit=hidden_unit,\n",
        "                k = k,\n",
        "                learning_rate = learning_rate_decay,\n",
        "                learning_rate_decay = learning_rate_decay,\n",
        "                xavier_init = xvaier_init,\n",
        "                use_gpu = use_gpu)\n",
        "        self.linear = nn.Linear(in_features = input_dim, out_features = class_num)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    def forward(self, data, label):\n",
        "        dbn_output = self.dbn.train_stat(data, label, num_epochs, batch_size)\n",
        "        output = self.linear(self.dropout(dbn_output))\n",
        "        return output\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YkJ2_xVtwWJ"
      },
      "source": [
        "Split Training and Testing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqkjQ7eot0sn"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(feature_sample, label_sample, test_size=0.3)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEwT855x5RYK",
        "outputId": "e9f544cd-ca79-4107-a31e-f35e808cd11c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "x_train_tensor = torch.Tensor(x_train)\n",
        "y_train_tensor = torch.Tensor(y_train)\n",
        "\n",
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "train_data_loader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=100)\n",
        "\n",
        "print('The Length of Train Dataloader is {}'.format(len(train_data_loader)))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Length of Train Dataloader is 414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uNZqNMrt71u",
        "outputId": "614c746d-5755-4cfb-8e93-81124cc384ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_test_tensor = torch.Tensor(x_test)\n",
        "y_test_tensor = torch.Tensor(y_test)\n",
        "\n",
        "test_data = TensorDataset(x_test_tensor, y_test_tensor)\n",
        "test_data_loader = DataLoader(test_data, sampler=RandomSampler(test_data), batch_size=100)\n",
        "\n",
        "print('The Length of Test Dataloader is {}'.format(len(test_data_loader)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Length of Test Dataloader is 178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuyYPapTTMmE"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "visible_unit = 4 * 144\n",
        "hidden_unit = [144, 100]\n",
        "k = 10\n",
        "learing_rate = 0.05\n",
        "learning_rate_decay = True\n",
        "xvaier_init = True\n",
        "use_gpu = True\n",
        "num_epochs = 20\n",
        "batch_size = 100\n",
        "input_dim = 100\n",
        "class_num = 1\n",
        "\n",
        "\n",
        "\n",
        "model = DBNmodel(visible_unit, hidden_unit, k, learing_rate, learning_rate_decay,\n",
        "                 xvaier_init, use_gpu, num_epochs, batch_size, input_dim, class_num)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvit0RaCyTvh",
        "outputId": "f288566a-2208-4041-a057-855065fd90b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#defining our loss and porting our model and loss to GPU\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model.to(device)\n",
        "criterion.to(device)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtbbOLTIyXTX"
      },
      "source": [
        "def binary_accuracy(pred, actual_label):\n",
        "    rounded_preds = torch.round(torch.sigmoid(pred))\n",
        "    correct = (rounded_preds == actual_label).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsObvayqyb85"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f_score_measure(pred, actual_label):\n",
        "    rounded_preds = torch.round(torch.sigmoid(pred.cpu()))\n",
        "    preds = rounded_preds.data.numpy()\n",
        "    actual_labels = actual_label.cpu().data.numpy()\n",
        "    score = f1_score(preds, actual_labels)\n",
        "\n",
        "    return score"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCNjSeRgyhgp"
      },
      "source": [
        "#defining the training method\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_F1_score = 0\n",
        "\n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        input_data = batch[0].to(device)\n",
        "        labels = batch[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(input_data, labels).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions,labels)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, labels)\n",
        "        f_score = f_score_measure(predictions, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        epoch_F1_score += f_score.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_F1_score / len(iterator)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IZUtEGcyq_T"
      },
      "source": [
        "#defining the validation method\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_F1_score = 0\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "            input_data = batch[0].to(device)\n",
        "            labels = batch[1].to(device)\n",
        "\n",
        "            predictions = model(input_data, labels).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, labels)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, labels)\n",
        "            f_score = f_score_measure(predictions, labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            epoch_F1_score += f_score.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_F1_score / len(iterator)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrI4uE2jy9UI"
      },
      "source": [
        "#defining the method to calculate epoch time\n",
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgTiR9PYzDb9",
        "outputId": "072ab976-0980-4659-c992-70240e65dc5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "#TRAINING!\n",
        "N_EPOCHS = 50\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc, train_f_score = train(model, train_data_loader, optimizer, criterion)\n",
        "    valid_loss, valid_acc, valid_f_score = evaluate(model, test_data_loader, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'dbn_version 1.0.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train F1_score: {train_f_score:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% | Val. F1_score: {valid_f_score:.3f}')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 17s\n",
            "\tTrain Loss: 0.301 | Train Acc: 91.10% | Train F1_score: 0.002\n",
            "\t Val. Loss: 0.289 |  Val. Acc: 91.60% | Val. F1_score: 0.000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-bb55e5b60c61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_f_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-0e5d01fe879e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-015105bd1d0a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, label)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mdbn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_stat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdbn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DBN.py\u001b[0m in \u001b[0;36mtrain_stat\u001b[0;34m(self, train_data, train_labels, num_epoch, batch_size)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0m_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrbm_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/RBM.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataloader, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mcost_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;31m# print(\"Epoch:{} finished, avg_cost = {}, std_cost = {}, avg_grad = {}, std_grad = {}\".format(num_epochs,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m#                                                                                         torch.mean(cost_),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/RBM.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, input_data, epoch)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrastive_divergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_gibbs_sampling_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/RBM.py\u001b[0m in \u001b[0;36mcontrastive_divergence\u001b[0;34m(self, input_data, training, n_gibbs_sampling_steps, lr)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mhidden_activations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_gibbs_sampling_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mvisible_probabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_activations\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# v_dim * v_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mhidden_probabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisible_probabilities\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# v_dim * h_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/RBM.py\u001b[0m in \u001b[0;36mto_visible\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# reconstruct data from hidden layer also does sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mX_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mX_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mX_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6ueuIIn5UEz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
