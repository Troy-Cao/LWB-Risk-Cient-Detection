{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "LSTM_Anomaly_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE32-2_1q9QC"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1q3GKyFq9QG",
        "outputId": "074e43be-6fb9-420c-bb89-14d296d0000b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df_1 = pd.read_csv('dc_part.csv')\n",
        "df_2 = pd.read_csv('chenqin5%.csv')\n",
        "df_3 = pd.read_csv('miaoqin_part.csv')\n",
        "df_4 = pd.read_csv('yunDataN.csv')\n",
        "print(df_1.shape,df_2.shape,df_3.shape,df_4.shape)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(124293, 147) (124293, 92) (124293, 162) (124293, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-fDmQXidApD"
      },
      "source": [
        "# Mergeing the 4 parts of the datasets with the zero-rate less than 95%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m6MHarYYWEU"
      },
      "source": [
        "data_parts=[df_1,df_2,df_3,df_4]\n",
        "useful=[] # the column names for each parts that have less than 95% zeros\n",
        "for ele in data_parts:\n",
        "  useful_sub=[]\n",
        "  for col in ele.columns:\n",
        "    if ele[col].isin([0]).sum()/ele.shape[0]<0.95:\n",
        "      useful_sub.append(col)\n",
        "  useful.append(useful_sub)\n",
        "useful[2]=useful[2][1:]  # drop unuseful column_name in the 4th parts"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5ZNKlpHNrhA"
      },
      "source": [
        "df_1 = df_1.loc[:,useful[0]]\n",
        "df_2 = df_2.loc[:,useful[1]]\n",
        "df_3 = df_3.loc[:,useful[2]]\n",
        "df_4 = df_4.loc[:,useful[3]]"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucd5-0LZlEvW"
      },
      "source": [
        "result = pd.concat([df_1,df_2,df_3,df_4], axis=1, sort=False) # combine the dateset"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glIvV3rinX1N",
        "outputId": "c8f5581c-0bc8-40dc-f7c6-079517f921e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        }
      },
      "source": [
        "result.head()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_key_client_id</th>\n",
              "      <th>_key_occurreddate_month</th>\n",
              "      <th>Total_incident_count</th>\n",
              "      <th>response_variable</th>\n",
              "      <th>incident_subcatgry_unknown_piv</th>\n",
              "      <th>prgcontct_other_organisation_piv</th>\n",
              "      <th>prgcontct_lwb_worker_piv</th>\n",
              "      <th>prgcontct_both_client_and_carer_piv</th>\n",
              "      <th>prgcontct_department_piv</th>\n",
              "      <th>prgcontct_family_piv</th>\n",
              "      <th>prgcontct_carer_piv</th>\n",
              "      <th>prgcontct_client_piv</th>\n",
              "      <th>prgcontct_meeting_group_of_people_piv_sum_n_days</th>\n",
              "      <th>prgcontct_other_organisation_piv_sum_n_days</th>\n",
              "      <th>prgcontct_educational_institution_piv_sum_n_days</th>\n",
              "      <th>prgcontct_lwb_worker_piv_sum_n_days</th>\n",
              "      <th>prgcontct_both_client_and_carer_piv_sum_n_days</th>\n",
              "      <th>prgcontct_health_professional_piv_sum_n_days</th>\n",
              "      <th>prgcontct_department_piv_sum_n_days</th>\n",
              "      <th>prgcontct_other_stakeholder_piv_sum_n_days</th>\n",
              "      <th>prgcontct_family_piv_sum_n_days</th>\n",
              "      <th>prgcontct_carer_piv_sum_n_days</th>\n",
              "      <th>prgcontct_client_piv_sum_n_days</th>\n",
              "      <th>prgcontct_meeting_group_of_people_piv_days_since</th>\n",
              "      <th>prgcontct_other_organisation_piv_days_since</th>\n",
              "      <th>prgcontct_meeting_lwb_internal_only_piv_days_since</th>\n",
              "      <th>prgcontct_educational_institution_piv_days_since</th>\n",
              "      <th>prgcontct_employer_piv_days_since</th>\n",
              "      <th>prgcontct_lwb_worker_piv_days_since</th>\n",
              "      <th>prgcontct_police_piv_days_since</th>\n",
              "      <th>prgcontct_both_client_and_carer_piv_days_since</th>\n",
              "      <th>prgcontct_health_professional_piv_days_since</th>\n",
              "      <th>prgcontct_department_piv_days_since</th>\n",
              "      <th>prgcontct_other_stakeholder_piv_days_since</th>\n",
              "      <th>prgcontct_family_piv_days_since</th>\n",
              "      <th>prgcontct_carer_piv_days_since</th>\n",
              "      <th>prgcontct_client_piv_days_since</th>\n",
              "      <th>progsubjcat_information_provided_piv</th>\n",
              "      <th>progsubjcat_case_discussion_planning_piv</th>\n",
              "      <th>progsubjcat_i_sight_client_incident_system_generated_piv</th>\n",
              "      <th>...</th>\n",
              "      <th>rowtype_reference_piv_avg_n_days</th>\n",
              "      <th>rowtype_client_address_addition_piv_days_since</th>\n",
              "      <th>rowtype_rp_end_piv_days_since</th>\n",
              "      <th>rowtype_rp_start_piv_days_since</th>\n",
              "      <th>rowtype_progress_note_piv_days_since</th>\n",
              "      <th>rowtype_diagnosis_piv_days_since</th>\n",
              "      <th>rowtype_medictn_start_piv_days_since</th>\n",
              "      <th>rowtype_client_plan_start_piv_days_since</th>\n",
              "      <th>rowtype_client_plan_end_piv_days_since</th>\n",
              "      <th>rowtype_keyworker_change_piv_days_since</th>\n",
              "      <th>rowtype_reference_piv_days_since</th>\n",
              "      <th>rowtype_medictn_end_piv_days_since</th>\n",
              "      <th>rowtype_plcment_end_piv_days_since</th>\n",
              "      <th>rowtype_incident_piv_days_since</th>\n",
              "      <th>rowtype_plcment_start_piv_days_since</th>\n",
              "      <th>rowtype_program_primary_service_type_start_piv_days_since</th>\n",
              "      <th>rowtype_client_alert_start_piv_days_since</th>\n",
              "      <th>rowtype_client_address_addition_piv_lag01</th>\n",
              "      <th>rowtype_rp_end_piv_lag01</th>\n",
              "      <th>rowtype_rp_start_piv_lag01</th>\n",
              "      <th>rowtype_progress_note_piv_lag01</th>\n",
              "      <th>rowtype_diagnosis_piv_lag01</th>\n",
              "      <th>rowtype_medictn_start_piv_lag01</th>\n",
              "      <th>rowtype_client_plan_start_piv_lag01</th>\n",
              "      <th>rowtype_client_plan_end_piv_lag01</th>\n",
              "      <th>rowtype_keyworker_change_piv_lag01</th>\n",
              "      <th>rowtype_reference_piv_lag01</th>\n",
              "      <th>rowtype_medictn_end_piv_lag01</th>\n",
              "      <th>rowtype_plcment_end_piv_lag01</th>\n",
              "      <th>rowtype_incident_piv_lag01</th>\n",
              "      <th>rowtype_plcment_start_piv_lag01</th>\n",
              "      <th>rowtype_program_primary_service_type_start_piv_lag01</th>\n",
              "      <th>rowtype_client_alert_start_piv_lag01</th>\n",
              "      <th>status_placement</th>\n",
              "      <th>status_client_plan</th>\n",
              "      <th>status_rp_mechanical_restraint</th>\n",
              "      <th>status_rp_restricted_access</th>\n",
              "      <th>status_rp_chemical_restraint</th>\n",
              "      <th>status_rp_other</th>\n",
              "      <th>Incident</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000D172-EA88-432F-8235-9FAA00D29072</td>\n",
              "      <td>2019-04-01T00:00:00.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>2868</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>603</td>\n",
              "      <td>355</td>\n",
              "      <td>376</td>\n",
              "      <td>890</td>\n",
              "      <td>515</td>\n",
              "      <td>492</td>\n",
              "      <td>761</td>\n",
              "      <td>555</td>\n",
              "      <td>345</td>\n",
              "      <td>2</td>\n",
              "      <td>425</td>\n",
              "      <td>469</td>\n",
              "      <td>703</td>\n",
              "      <td>527</td>\n",
              "      <td>577</td>\n",
              "      <td>488</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000D172-EA88-432F-8235-9FAA00D29072</td>\n",
              "      <td>2019-05-01T00:00:00.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>22</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>603</td>\n",
              "      <td>355</td>\n",
              "      <td>376</td>\n",
              "      <td>21</td>\n",
              "      <td>515</td>\n",
              "      <td>492</td>\n",
              "      <td>761</td>\n",
              "      <td>555</td>\n",
              "      <td>345</td>\n",
              "      <td>0</td>\n",
              "      <td>425</td>\n",
              "      <td>469</td>\n",
              "      <td>703</td>\n",
              "      <td>527</td>\n",
              "      <td>577</td>\n",
              "      <td>488</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000D172-EA88-432F-8235-9FAA00D29072</td>\n",
              "      <td>2019-06-01T00:00:00.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>52</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>559</td>\n",
              "      <td>355</td>\n",
              "      <td>376</td>\n",
              "      <td>51</td>\n",
              "      <td>515</td>\n",
              "      <td>492</td>\n",
              "      <td>761</td>\n",
              "      <td>555</td>\n",
              "      <td>345</td>\n",
              "      <td>0</td>\n",
              "      <td>425</td>\n",
              "      <td>469</td>\n",
              "      <td>703</td>\n",
              "      <td>527</td>\n",
              "      <td>577</td>\n",
              "      <td>488</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000D172-EA88-432F-8235-9FAA00D29072</td>\n",
              "      <td>2019-07-01T00:00:00.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>83</td>\n",
              "      <td>3650</td>\n",
              "      <td>483</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>355</td>\n",
              "      <td>376</td>\n",
              "      <td>20</td>\n",
              "      <td>515</td>\n",
              "      <td>492</td>\n",
              "      <td>761</td>\n",
              "      <td>555</td>\n",
              "      <td>345</td>\n",
              "      <td>0</td>\n",
              "      <td>425</td>\n",
              "      <td>469</td>\n",
              "      <td>703</td>\n",
              "      <td>527</td>\n",
              "      <td>577</td>\n",
              "      <td>488</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000D172-EA88-432F-8235-9FAA00D29072</td>\n",
              "      <td>2019-08-01T00:00:00.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>114</td>\n",
              "      <td>3650</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>355</td>\n",
              "      <td>376</td>\n",
              "      <td>7</td>\n",
              "      <td>515</td>\n",
              "      <td>492</td>\n",
              "      <td>761</td>\n",
              "      <td>555</td>\n",
              "      <td>345</td>\n",
              "      <td>0</td>\n",
              "      <td>425</td>\n",
              "      <td>469</td>\n",
              "      <td>703</td>\n",
              "      <td>527</td>\n",
              "      <td>577</td>\n",
              "      <td>488</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 212 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         _key_client_id  ... Incident\n",
              "0  0000D172-EA88-432F-8235-9FAA00D29072  ...        0\n",
              "1  0000D172-EA88-432F-8235-9FAA00D29072  ...        0\n",
              "2  0000D172-EA88-432F-8235-9FAA00D29072  ...        0\n",
              "3  0000D172-EA88-432F-8235-9FAA00D29072  ...        0\n",
              "4  0000D172-EA88-432F-8235-9FAA00D29072  ...        0\n",
              "\n",
              "[5 rows x 212 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfjmd39toDbO"
      },
      "source": [
        "### Parse 'Dates' and indexs it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI6eJ4P5bOR5"
      },
      "source": [
        "result.to_csv('Dataconcate.csv')"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-a32wgnbOKa"
      },
      "source": [
        "Dataset=pd.read_csv('Dataconcate.csv',parse_dates=['_key_occurreddate_month'],index_col=['_key_client_id','_key_occurreddate_month'])"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLRU4RuNuPgd",
        "outputId": "4ca989eb-f407-44e2-d72d-4f6392769896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "Dataset.drop(['Unnamed: 0','response_variable'],axis=1).head()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Total_incident_count</th>\n",
              "      <th>incident_subcatgry_unknown_piv</th>\n",
              "      <th>prgcontct_other_organisation_piv</th>\n",
              "      <th>prgcontct_lwb_worker_piv</th>\n",
              "      <th>prgcontct_both_client_and_carer_piv</th>\n",
              "      <th>prgcontct_department_piv</th>\n",
              "      <th>prgcontct_family_piv</th>\n",
              "      <th>prgcontct_carer_piv</th>\n",
              "      <th>prgcontct_client_piv</th>\n",
              "      <th>prgcontct_meeting_group_of_people_piv_sum_n_days</th>\n",
              "      <th>prgcontct_other_organisation_piv_sum_n_days</th>\n",
              "      <th>prgcontct_educational_institution_piv_sum_n_days</th>\n",
              "      <th>prgcontct_lwb_worker_piv_sum_n_days</th>\n",
              "      <th>prgcontct_both_client_and_carer_piv_sum_n_days</th>\n",
              "      <th>prgcontct_health_professional_piv_sum_n_days</th>\n",
              "      <th>prgcontct_department_piv_sum_n_days</th>\n",
              "      <th>prgcontct_other_stakeholder_piv_sum_n_days</th>\n",
              "      <th>prgcontct_family_piv_sum_n_days</th>\n",
              "      <th>prgcontct_carer_piv_sum_n_days</th>\n",
              "      <th>prgcontct_client_piv_sum_n_days</th>\n",
              "      <th>prgcontct_meeting_group_of_people_piv_days_since</th>\n",
              "      <th>prgcontct_other_organisation_piv_days_since</th>\n",
              "      <th>prgcontct_meeting_lwb_internal_only_piv_days_since</th>\n",
              "      <th>prgcontct_educational_institution_piv_days_since</th>\n",
              "      <th>prgcontct_employer_piv_days_since</th>\n",
              "      <th>prgcontct_lwb_worker_piv_days_since</th>\n",
              "      <th>prgcontct_police_piv_days_since</th>\n",
              "      <th>prgcontct_both_client_and_carer_piv_days_since</th>\n",
              "      <th>prgcontct_health_professional_piv_days_since</th>\n",
              "      <th>prgcontct_department_piv_days_since</th>\n",
              "      <th>prgcontct_other_stakeholder_piv_days_since</th>\n",
              "      <th>prgcontct_family_piv_days_since</th>\n",
              "      <th>prgcontct_carer_piv_days_since</th>\n",
              "      <th>prgcontct_client_piv_days_since</th>\n",
              "      <th>progsubjcat_information_provided_piv</th>\n",
              "      <th>progsubjcat_case_discussion_planning_piv</th>\n",
              "      <th>progsubjcat_i_sight_client_incident_system_generated_piv</th>\n",
              "      <th>progsubjcat_home_visit_piv</th>\n",
              "      <th>progsubjcat_health_and_wellbeing_piv</th>\n",
              "      <th>progsubjcat_monthly_report_piv</th>\n",
              "      <th>...</th>\n",
              "      <th>rowtype_reference_piv_avg_n_days</th>\n",
              "      <th>rowtype_client_address_addition_piv_days_since</th>\n",
              "      <th>rowtype_rp_end_piv_days_since</th>\n",
              "      <th>rowtype_rp_start_piv_days_since</th>\n",
              "      <th>rowtype_progress_note_piv_days_since</th>\n",
              "      <th>rowtype_diagnosis_piv_days_since</th>\n",
              "      <th>rowtype_medictn_start_piv_days_since</th>\n",
              "      <th>rowtype_client_plan_start_piv_days_since</th>\n",
              "      <th>rowtype_client_plan_end_piv_days_since</th>\n",
              "      <th>rowtype_keyworker_change_piv_days_since</th>\n",
              "      <th>rowtype_reference_piv_days_since</th>\n",
              "      <th>rowtype_medictn_end_piv_days_since</th>\n",
              "      <th>rowtype_plcment_end_piv_days_since</th>\n",
              "      <th>rowtype_incident_piv_days_since</th>\n",
              "      <th>rowtype_plcment_start_piv_days_since</th>\n",
              "      <th>rowtype_program_primary_service_type_start_piv_days_since</th>\n",
              "      <th>rowtype_client_alert_start_piv_days_since</th>\n",
              "      <th>rowtype_client_address_addition_piv_lag01</th>\n",
              "      <th>rowtype_rp_end_piv_lag01</th>\n",
              "      <th>rowtype_rp_start_piv_lag01</th>\n",
              "      <th>rowtype_progress_note_piv_lag01</th>\n",
              "      <th>rowtype_diagnosis_piv_lag01</th>\n",
              "      <th>rowtype_medictn_start_piv_lag01</th>\n",
              "      <th>rowtype_client_plan_start_piv_lag01</th>\n",
              "      <th>rowtype_client_plan_end_piv_lag01</th>\n",
              "      <th>rowtype_keyworker_change_piv_lag01</th>\n",
              "      <th>rowtype_reference_piv_lag01</th>\n",
              "      <th>rowtype_medictn_end_piv_lag01</th>\n",
              "      <th>rowtype_plcment_end_piv_lag01</th>\n",
              "      <th>rowtype_incident_piv_lag01</th>\n",
              "      <th>rowtype_plcment_start_piv_lag01</th>\n",
              "      <th>rowtype_program_primary_service_type_start_piv_lag01</th>\n",
              "      <th>rowtype_client_alert_start_piv_lag01</th>\n",
              "      <th>status_placement</th>\n",
              "      <th>status_client_plan</th>\n",
              "      <th>status_rp_mechanical_restraint</th>\n",
              "      <th>status_rp_restricted_access</th>\n",
              "      <th>status_rp_chemical_restraint</th>\n",
              "      <th>status_rp_other</th>\n",
              "      <th>Incident</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>_key_client_id</th>\n",
              "      <th>_key_occurreddate_month</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">0000D172-EA88-432F-8235-9FAA00D29072</th>\n",
              "      <th>2019-04-01</th>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>2868</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>603</td>\n",
              "      <td>355</td>\n",
              "      <td>376</td>\n",
              "      <td>890</td>\n",
              "      <td>515</td>\n",
              "      <td>492</td>\n",
              "      <td>761</td>\n",
              "      <td>555</td>\n",
              "      <td>345</td>\n",
              "      <td>2</td>\n",
              "      <td>425</td>\n",
              "      <td>469</td>\n",
              "      <td>703</td>\n",
              "      <td>527</td>\n",
              "      <td>577</td>\n",
              "      <td>488</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-05-01</th>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>22</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>603</td>\n",
              "      <td>355</td>\n",
              "      <td>376</td>\n",
              "      <td>21</td>\n",
              "      <td>515</td>\n",
              "      <td>492</td>\n",
              "      <td>761</td>\n",
              "      <td>555</td>\n",
              "      <td>345</td>\n",
              "      <td>0</td>\n",
              "      <td>425</td>\n",
              "      <td>469</td>\n",
              "      <td>703</td>\n",
              "      <td>527</td>\n",
              "      <td>577</td>\n",
              "      <td>488</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-06-01</th>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>52</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>559</td>\n",
              "      <td>355</td>\n",
              "      <td>376</td>\n",
              "      <td>51</td>\n",
              "      <td>515</td>\n",
              "      <td>492</td>\n",
              "      <td>761</td>\n",
              "      <td>555</td>\n",
              "      <td>345</td>\n",
              "      <td>0</td>\n",
              "      <td>425</td>\n",
              "      <td>469</td>\n",
              "      <td>703</td>\n",
              "      <td>527</td>\n",
              "      <td>577</td>\n",
              "      <td>488</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-01</th>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>83</td>\n",
              "      <td>3650</td>\n",
              "      <td>483</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>355</td>\n",
              "      <td>376</td>\n",
              "      <td>20</td>\n",
              "      <td>515</td>\n",
              "      <td>492</td>\n",
              "      <td>761</td>\n",
              "      <td>555</td>\n",
              "      <td>345</td>\n",
              "      <td>0</td>\n",
              "      <td>425</td>\n",
              "      <td>469</td>\n",
              "      <td>703</td>\n",
              "      <td>527</td>\n",
              "      <td>577</td>\n",
              "      <td>488</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-01</th>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>3650</td>\n",
              "      <td>114</td>\n",
              "      <td>3650</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>355</td>\n",
              "      <td>376</td>\n",
              "      <td>7</td>\n",
              "      <td>515</td>\n",
              "      <td>492</td>\n",
              "      <td>761</td>\n",
              "      <td>555</td>\n",
              "      <td>345</td>\n",
              "      <td>0</td>\n",
              "      <td>425</td>\n",
              "      <td>469</td>\n",
              "      <td>703</td>\n",
              "      <td>527</td>\n",
              "      <td>577</td>\n",
              "      <td>488</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 209 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                              Total_incident_count  ...  Incident\n",
              "_key_client_id                       _key_occurreddate_month                        ...          \n",
              "0000D172-EA88-432F-8235-9FAA00D29072 2019-04-01                                  0  ...         0\n",
              "                                     2019-05-01                                  0  ...         0\n",
              "                                     2019-06-01                                  0  ...         0\n",
              "                                     2019-07-01                                  0  ...         0\n",
              "                                     2019-08-01                                  0  ...         0\n",
              "\n",
              "[5 rows x 209 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IA3ZX1Q3J0j"
      },
      "source": [
        "client_id=list(Dataset.index.get_level_values(0)) # the value of '_key_client_id' indexe"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OuahIt2UWF2"
      },
      "source": [
        "### Remove the Useless records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvzX1ELmMAfw"
      },
      "source": [
        "from collections import Counter\n",
        "occurrences = Counter(client_id)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZxg9_39N7FR"
      },
      "source": [
        "used_id=[]\n",
        "usedless_id=[]\n",
        "for key, value in occurrences.items():\n",
        "  if value==12:  # number can be changed\n",
        "    used_id.append(key)\n",
        "  else:\n",
        "    usedless_id.append(key)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74FXgqe1lzb_",
        "outputId": "a8265ea6-f8f1-4a74-c3b6-dce9f9098fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(f'Useful client:  {len(used_id):d}\\nUseless client: {len(usedless_id):d}')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Useful client:  7380\n",
            "Useless client: 7007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIqnQ5eWQ8Oy",
        "outputId": "9e56df52-2630-45cc-f58a-7004c48d98c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# remove the rows that the record of client is less than 12 month \n",
        "Dataset=Dataset.drop(usedless_id,level=0) \n",
        "Dataset.shape"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88560, 211)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d38tzpQ6UBkf"
      },
      "source": [
        "\n",
        "Dataset.drop(['Unnamed: 0','response_variable'],axis=1,inplace=True)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obJNduOArMIa"
      },
      "source": [
        "## Perparing Dateset for Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6T0_1bqg3J-"
      },
      "source": [
        "### Spliting to Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDdZl8hahLXe",
        "outputId": "6e76e2f1-b7bd-43d6-c2ca-d32fea924a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "split=int(0.9*len(used_id))\n",
        "train_index=used_id[:split] # the clients who will in trainset\n",
        "test_index=used_id[split:] # the clients who will in testset\n",
        "\n",
        "# Train dataset\n",
        "train=Dataset.loc[train_index]\n",
        "train_x = train.drop('Incident',axis=1)\n",
        "train_y = train.Incident\n",
        "\n",
        "# Test Dataset\n",
        "test=Dataset.loc[test_index]\n",
        "test_x = test.drop('Incident',axis=1)\n",
        "test_y = test.Incident\n",
        "\n",
        "print(train.shape,test.shape)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(79704, 209) (8856, 209)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVBhIWD6oqke"
      },
      "source": [
        "### Normalize the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjwqksZ3oJVi"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler()\n",
        "\n",
        "train_x = scaler.fit_transform(train_x)\n",
        "\n",
        "test_x = scaler.transform(test_x)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aim_l66xgSI"
      },
      "source": [
        "###Serializing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOhbC83Kq9QL"
      },
      "source": [
        "# 4D output\n",
        "import numpy as np\n",
        "\n",
        "def create_dataset(X, y, time_steps, window, number):\n",
        "  xs, ys,channel = [],[],0\n",
        "  while channel < number: # Ensure all client data have changed to time series type\n",
        "    xs_sub, ys_sub =[],[]\n",
        "    for i in range(window - time_steps):\n",
        "      shifft= window * channel\n",
        "      v = X[i+shifft:(i + shifft + time_steps)]\n",
        "      xs_sub.append(v)\n",
        "      ys_sub.append(y[i + shifft + time_steps])\n",
        "\n",
        "    channel+=1\n",
        "    xs.append(xs_sub)\n",
        "    ys.append(ys_sub)\n",
        "\n",
        "  return np.array(xs),np.array(ys)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ9H29Sdq9QO"
      },
      "source": [
        "TIME_STEPS = 4\n",
        "WINDOW = 12 # control client change\n",
        "NUM_TRAIN = len(train_index)\n",
        "NUM_TEST = len(test_index)\n",
        "\n",
        "X_train, y_train = create_dataset(train_x,train_y, TIME_STEPS, WINDOW, NUM_TRAIN)\n",
        "X_test, y_test = create_dataset(test_x, test_y, TIME_STEPS, WINDOW,NUM_TEST)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_1HVVXRq9QQ",
        "outputId": "c3c3cb36-5121-4965-cf4c-a37e5263b935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# [n_samples, (n_sub_sequence),TIME_STEPS, n_features]\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6642, 8, 4, 208) (6642, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nonWCISJrpa7"
      },
      "source": [
        "## LSTM AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx4xhtWAkXXW"
      },
      "source": [
        "# https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/\n",
        "''' 4D input [n_samples, n_sub_sequence,TIME_STEPS, n_features]'''\n",
        "def ConvLSMT_autoencoder(X):\n",
        "  model = Sequential()\n",
        "  model.add(layers.TimeDistributed(layers.Conv1D(filters=16, kernel_size=1, activation='relu'), input_shape=(None, X.shape[2], X.shape[3])))\n",
        "  model.add(layers.TimeDistributed(layers.MaxPooling1D(pool_size=2)))\n",
        "  model.add(layers.TimeDistributed(layers.Flatten()))\n",
        "  model.add(layers.LSTM(32, activation='relu'))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.RepeatVector(X.shape[2]))\n",
        "  model.add(layers.LSTM(4, activation='relu', return_sequences=True))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(X.shape[1],activation='sigmoid'))\n",
        "  return model"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OluqSOE2fRNx",
        "outputId": "26181ed1-bd81-4a28-edee-87862aee9fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "model = ConvLSMT_autoencoder(X_train)\n",
        "model.summary()"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed_3 (TimeDist (None, None, 4, 16)       3344      \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, None, 2, 16)       0         \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, None, 32)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 4, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 4, 4)              592       \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 136       \n",
            "=================================================================\n",
            "Total params: 12,392\n",
            "Trainable params: 12,392\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVvbWAb4dXUu"
      },
      "source": [
        "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "              optimizer=keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgSPpteoeOLD",
        "outputId": "f5d0396d-5279-414f-d09b-cdd76281cb29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(\n",
        "    X_train,y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 48,\n",
        "    validation_split = 0.1,\n",
        "    shuffle = False)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.6906 - accuracy: 0.0408 - val_loss: 0.6855 - val_accuracy: 0.0436\n",
            "Epoch 2/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.6500 - accuracy: 0.0427 - val_loss: 0.5504 - val_accuracy: 0.0466\n",
            "Epoch 3/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.5539 - accuracy: 0.0417 - val_loss: 0.4775 - val_accuracy: 0.0466\n",
            "Epoch 4/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.4967 - accuracy: 0.0420 - val_loss: 0.4226 - val_accuracy: 0.0466\n",
            "Epoch 5/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.4455 - accuracy: 0.0410 - val_loss: 0.3437 - val_accuracy: 0.0451\n",
            "Epoch 6/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3718 - accuracy: 0.0428 - val_loss: 0.2538 - val_accuracy: 0.0481\n",
            "Epoch 7/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3143 - accuracy: 0.0507 - val_loss: 0.2189 - val_accuracy: 0.0541\n",
            "Epoch 8/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2747 - accuracy: 0.0582 - val_loss: 0.1976 - val_accuracy: 0.0632\n",
            "Epoch 9/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2567 - accuracy: 0.0607 - val_loss: 0.1918 - val_accuracy: 0.0752\n",
            "Epoch 10/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2397 - accuracy: 0.0673 - val_loss: 0.1876 - val_accuracy: 0.0767\n",
            "Epoch 11/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2250 - accuracy: 0.0785 - val_loss: 0.1850 - val_accuracy: 0.0767\n",
            "Epoch 12/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2177 - accuracy: 0.0798 - val_loss: 0.1830 - val_accuracy: 0.0812\n",
            "Epoch 13/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2075 - accuracy: 0.0870 - val_loss: 0.1813 - val_accuracy: 0.0752\n",
            "Epoch 14/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2042 - accuracy: 0.0932 - val_loss: 0.1794 - val_accuracy: 0.0872\n",
            "Epoch 15/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2000 - accuracy: 0.0915 - val_loss: 0.1785 - val_accuracy: 0.0797\n",
            "Epoch 16/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1941 - accuracy: 0.0984 - val_loss: 0.1769 - val_accuracy: 0.1023\n",
            "Epoch 17/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1921 - accuracy: 0.1049 - val_loss: 0.1756 - val_accuracy: 0.1173\n",
            "Epoch 18/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1898 - accuracy: 0.1031 - val_loss: 0.1743 - val_accuracy: 0.1218\n",
            "Epoch 19/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1852 - accuracy: 0.1129 - val_loss: 0.1734 - val_accuracy: 0.1248\n",
            "Epoch 20/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1828 - accuracy: 0.1069 - val_loss: 0.1724 - val_accuracy: 0.1293\n",
            "Epoch 21/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1811 - accuracy: 0.1074 - val_loss: 0.1714 - val_accuracy: 0.1233\n",
            "Epoch 22/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1794 - accuracy: 0.1114 - val_loss: 0.1700 - val_accuracy: 0.1504\n",
            "Epoch 23/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1766 - accuracy: 0.1198 - val_loss: 0.1692 - val_accuracy: 0.1489\n",
            "Epoch 24/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1744 - accuracy: 0.1151 - val_loss: 0.1679 - val_accuracy: 0.1504\n",
            "Epoch 25/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1724 - accuracy: 0.1186 - val_loss: 0.1669 - val_accuracy: 0.1669\n",
            "Epoch 26/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1707 - accuracy: 0.1183 - val_loss: 0.1656 - val_accuracy: 0.1669\n",
            "Epoch 27/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1680 - accuracy: 0.1302 - val_loss: 0.1647 - val_accuracy: 0.1729\n",
            "Epoch 28/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1669 - accuracy: 0.1317 - val_loss: 0.1640 - val_accuracy: 0.1639\n",
            "Epoch 29/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1671 - accuracy: 0.1211 - val_loss: 0.1625 - val_accuracy: 0.1729\n",
            "Epoch 30/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1659 - accuracy: 0.1354 - val_loss: 0.1624 - val_accuracy: 0.1699\n",
            "Epoch 31/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1639 - accuracy: 0.1395 - val_loss: 0.1626 - val_accuracy: 0.1699\n",
            "Epoch 32/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1647 - accuracy: 0.1367 - val_loss: 0.1618 - val_accuracy: 0.1594\n",
            "Epoch 33/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1636 - accuracy: 0.1360 - val_loss: 0.1618 - val_accuracy: 0.1774\n",
            "Epoch 34/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1625 - accuracy: 0.1497 - val_loss: 0.1607 - val_accuracy: 0.1759\n",
            "Epoch 35/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1608 - accuracy: 0.1534 - val_loss: 0.1594 - val_accuracy: 0.1805\n",
            "Epoch 36/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1598 - accuracy: 0.1606 - val_loss: 0.1592 - val_accuracy: 0.1759\n",
            "Epoch 37/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1597 - accuracy: 0.1539 - val_loss: 0.1595 - val_accuracy: 0.1895\n",
            "Epoch 38/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1585 - accuracy: 0.1620 - val_loss: 0.1592 - val_accuracy: 0.1865\n",
            "Epoch 39/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1591 - accuracy: 0.1578 - val_loss: 0.1582 - val_accuracy: 0.1880\n",
            "Epoch 40/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1572 - accuracy: 0.1523 - val_loss: 0.1582 - val_accuracy: 0.1729\n",
            "Epoch 41/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1574 - accuracy: 0.1519 - val_loss: 0.1577 - val_accuracy: 0.1895\n",
            "Epoch 42/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1566 - accuracy: 0.1691 - val_loss: 0.1586 - val_accuracy: 0.1910\n",
            "Epoch 43/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1564 - accuracy: 0.1616 - val_loss: 0.1566 - val_accuracy: 0.1669\n",
            "Epoch 44/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1554 - accuracy: 0.1387 - val_loss: 0.1578 - val_accuracy: 0.1654\n",
            "Epoch 45/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1546 - accuracy: 0.1477 - val_loss: 0.1570 - val_accuracy: 0.1684\n",
            "Epoch 46/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1547 - accuracy: 0.1512 - val_loss: 0.1561 - val_accuracy: 0.1654\n",
            "Epoch 47/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1545 - accuracy: 0.1476 - val_loss: 0.1564 - val_accuracy: 0.1669\n",
            "Epoch 48/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1521 - accuracy: 0.1486 - val_loss: 0.1561 - val_accuracy: 0.1654\n",
            "Epoch 49/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1536 - accuracy: 0.1467 - val_loss: 0.1563 - val_accuracy: 0.1684\n",
            "Epoch 50/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1532 - accuracy: 0.1405 - val_loss: 0.1549 - val_accuracy: 0.1654\n",
            "Epoch 51/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1523 - accuracy: 0.1405 - val_loss: 0.1549 - val_accuracy: 0.1684\n",
            "Epoch 52/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1512 - accuracy: 0.1449 - val_loss: 0.1555 - val_accuracy: 0.1714\n",
            "Epoch 53/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1503 - accuracy: 0.1457 - val_loss: 0.1558 - val_accuracy: 0.1729\n",
            "Epoch 54/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1510 - accuracy: 0.1528 - val_loss: 0.1543 - val_accuracy: 0.1729\n",
            "Epoch 55/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1508 - accuracy: 0.1539 - val_loss: 0.1542 - val_accuracy: 0.1789\n",
            "Epoch 56/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1498 - accuracy: 0.1551 - val_loss: 0.1541 - val_accuracy: 0.1774\n",
            "Epoch 57/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1491 - accuracy: 0.1514 - val_loss: 0.1520 - val_accuracy: 0.1774\n",
            "Epoch 58/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1504 - accuracy: 0.1456 - val_loss: 0.1530 - val_accuracy: 0.1820\n",
            "Epoch 59/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1490 - accuracy: 0.1477 - val_loss: 0.1529 - val_accuracy: 0.1835\n",
            "Epoch 60/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1482 - accuracy: 0.1461 - val_loss: 0.1521 - val_accuracy: 0.1865\n",
            "Epoch 61/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1478 - accuracy: 0.1446 - val_loss: 0.1507 - val_accuracy: 0.1880\n",
            "Epoch 62/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1481 - accuracy: 0.1439 - val_loss: 0.1501 - val_accuracy: 0.1865\n",
            "Epoch 63/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1469 - accuracy: 0.1466 - val_loss: 0.1494 - val_accuracy: 0.1895\n",
            "Epoch 64/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1464 - accuracy: 0.1494 - val_loss: 0.1512 - val_accuracy: 0.1865\n",
            "Epoch 65/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1464 - accuracy: 0.1494 - val_loss: 0.1491 - val_accuracy: 0.1880\n",
            "Epoch 66/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1450 - accuracy: 0.1444 - val_loss: 0.1495 - val_accuracy: 0.1880\n",
            "Epoch 67/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1452 - accuracy: 0.1471 - val_loss: 0.1490 - val_accuracy: 0.1850\n",
            "Epoch 68/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1447 - accuracy: 0.1425 - val_loss: 0.1485 - val_accuracy: 0.1880\n",
            "Epoch 69/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1442 - accuracy: 0.1499 - val_loss: 0.1503 - val_accuracy: 0.1925\n",
            "Epoch 70/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1443 - accuracy: 0.1523 - val_loss: 0.1477 - val_accuracy: 0.1850\n",
            "Epoch 71/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1436 - accuracy: 0.1553 - val_loss: 0.1460 - val_accuracy: 0.1865\n",
            "Epoch 72/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1427 - accuracy: 0.1549 - val_loss: 0.1466 - val_accuracy: 0.1910\n",
            "Epoch 73/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1430 - accuracy: 0.1516 - val_loss: 0.1465 - val_accuracy: 0.1880\n",
            "Epoch 74/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1410 - accuracy: 0.1561 - val_loss: 0.1448 - val_accuracy: 0.1910\n",
            "Epoch 75/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1407 - accuracy: 0.1477 - val_loss: 0.1459 - val_accuracy: 0.1910\n",
            "Epoch 76/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1414 - accuracy: 0.1524 - val_loss: 0.1443 - val_accuracy: 0.1955\n",
            "Epoch 77/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1411 - accuracy: 0.1553 - val_loss: 0.1435 - val_accuracy: 0.1970\n",
            "Epoch 78/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1400 - accuracy: 0.1613 - val_loss: 0.1428 - val_accuracy: 0.1940\n",
            "Epoch 79/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1403 - accuracy: 0.1591 - val_loss: 0.1420 - val_accuracy: 0.2015\n",
            "Epoch 80/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1387 - accuracy: 0.1643 - val_loss: 0.1418 - val_accuracy: 0.2015\n",
            "Epoch 81/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1400 - accuracy: 0.1596 - val_loss: 0.1411 - val_accuracy: 0.1970\n",
            "Epoch 82/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1383 - accuracy: 0.1645 - val_loss: 0.1413 - val_accuracy: 0.1985\n",
            "Epoch 83/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1381 - accuracy: 0.1579 - val_loss: 0.1403 - val_accuracy: 0.2045\n",
            "Epoch 84/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1373 - accuracy: 0.1551 - val_loss: 0.1405 - val_accuracy: 0.1970\n",
            "Epoch 85/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1367 - accuracy: 0.1568 - val_loss: 0.1386 - val_accuracy: 0.1985\n",
            "Epoch 86/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1370 - accuracy: 0.1574 - val_loss: 0.1394 - val_accuracy: 0.1970\n",
            "Epoch 87/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1357 - accuracy: 0.1606 - val_loss: 0.1391 - val_accuracy: 0.1955\n",
            "Epoch 88/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1356 - accuracy: 0.1599 - val_loss: 0.1375 - val_accuracy: 0.1940\n",
            "Epoch 89/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1360 - accuracy: 0.1472 - val_loss: 0.1375 - val_accuracy: 0.1940\n",
            "Epoch 90/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1351 - accuracy: 0.1556 - val_loss: 0.1365 - val_accuracy: 0.1925\n",
            "Epoch 91/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1351 - accuracy: 0.1528 - val_loss: 0.1376 - val_accuracy: 0.1955\n",
            "Epoch 92/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1335 - accuracy: 0.1574 - val_loss: 0.1361 - val_accuracy: 0.1970\n",
            "Epoch 93/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1349 - accuracy: 0.1558 - val_loss: 0.1361 - val_accuracy: 0.1985\n",
            "Epoch 94/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1336 - accuracy: 0.1661 - val_loss: 0.1344 - val_accuracy: 0.1880\n",
            "Epoch 95/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1341 - accuracy: 0.1512 - val_loss: 0.1356 - val_accuracy: 0.1970\n",
            "Epoch 96/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1325 - accuracy: 0.1598 - val_loss: 0.1347 - val_accuracy: 0.1925\n",
            "Epoch 97/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1329 - accuracy: 0.1528 - val_loss: 0.1342 - val_accuracy: 0.1820\n",
            "Epoch 98/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1323 - accuracy: 0.1519 - val_loss: 0.1342 - val_accuracy: 0.1850\n",
            "Epoch 99/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1320 - accuracy: 0.1616 - val_loss: 0.1331 - val_accuracy: 0.1805\n",
            "Epoch 100/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1317 - accuracy: 0.1543 - val_loss: 0.1340 - val_accuracy: 0.1805\n",
            "Epoch 101/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1308 - accuracy: 0.1573 - val_loss: 0.1327 - val_accuracy: 0.1835\n",
            "Epoch 102/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1308 - accuracy: 0.1559 - val_loss: 0.1327 - val_accuracy: 0.1805\n",
            "Epoch 103/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1314 - accuracy: 0.1499 - val_loss: 0.1327 - val_accuracy: 0.1759\n",
            "Epoch 104/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1301 - accuracy: 0.1514 - val_loss: 0.1310 - val_accuracy: 0.1789\n",
            "Epoch 105/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1298 - accuracy: 0.1502 - val_loss: 0.1312 - val_accuracy: 0.1774\n",
            "Epoch 106/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1294 - accuracy: 0.1556 - val_loss: 0.1322 - val_accuracy: 0.1729\n",
            "Epoch 107/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1293 - accuracy: 0.1507 - val_loss: 0.1310 - val_accuracy: 0.1729\n",
            "Epoch 108/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1288 - accuracy: 0.1588 - val_loss: 0.1309 - val_accuracy: 0.1774\n",
            "Epoch 109/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1282 - accuracy: 0.1524 - val_loss: 0.1304 - val_accuracy: 0.1669\n",
            "Epoch 110/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1271 - accuracy: 0.1546 - val_loss: 0.1308 - val_accuracy: 0.1714\n",
            "Epoch 111/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1286 - accuracy: 0.1444 - val_loss: 0.1279 - val_accuracy: 0.1684\n",
            "Epoch 112/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1276 - accuracy: 0.1623 - val_loss: 0.1291 - val_accuracy: 0.1684\n",
            "Epoch 113/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1273 - accuracy: 0.1543 - val_loss: 0.1291 - val_accuracy: 0.1774\n",
            "Epoch 114/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1272 - accuracy: 0.1646 - val_loss: 0.1281 - val_accuracy: 0.1714\n",
            "Epoch 115/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1265 - accuracy: 0.1573 - val_loss: 0.1290 - val_accuracy: 0.1699\n",
            "Epoch 116/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1261 - accuracy: 0.1549 - val_loss: 0.1283 - val_accuracy: 0.1699\n",
            "Epoch 117/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1258 - accuracy: 0.1631 - val_loss: 0.1267 - val_accuracy: 0.1684\n",
            "Epoch 118/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1263 - accuracy: 0.1604 - val_loss: 0.1268 - val_accuracy: 0.1699\n",
            "Epoch 119/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1263 - accuracy: 0.1594 - val_loss: 0.1264 - val_accuracy: 0.1699\n",
            "Epoch 120/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1248 - accuracy: 0.1596 - val_loss: 0.1273 - val_accuracy: 0.1699\n",
            "Epoch 121/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1250 - accuracy: 0.1625 - val_loss: 0.1271 - val_accuracy: 0.1744\n",
            "Epoch 122/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1246 - accuracy: 0.1559 - val_loss: 0.1258 - val_accuracy: 0.1699\n",
            "Epoch 123/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1239 - accuracy: 0.1676 - val_loss: 0.1256 - val_accuracy: 0.1714\n",
            "Epoch 124/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1238 - accuracy: 0.1738 - val_loss: 0.1253 - val_accuracy: 0.1699\n",
            "Epoch 125/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1235 - accuracy: 0.1666 - val_loss: 0.1251 - val_accuracy: 0.1744\n",
            "Epoch 126/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1238 - accuracy: 0.1686 - val_loss: 0.1251 - val_accuracy: 0.1789\n",
            "Epoch 127/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1233 - accuracy: 0.1775 - val_loss: 0.1234 - val_accuracy: 0.1774\n",
            "Epoch 128/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1223 - accuracy: 0.1745 - val_loss: 0.1240 - val_accuracy: 0.1744\n",
            "Epoch 129/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1216 - accuracy: 0.1812 - val_loss: 0.1234 - val_accuracy: 0.1759\n",
            "Epoch 130/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1222 - accuracy: 0.1852 - val_loss: 0.1223 - val_accuracy: 0.1744\n",
            "Epoch 131/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1215 - accuracy: 0.1827 - val_loss: 0.1223 - val_accuracy: 0.1759\n",
            "Epoch 132/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1217 - accuracy: 0.1804 - val_loss: 0.1229 - val_accuracy: 0.1774\n",
            "Epoch 133/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1210 - accuracy: 0.1800 - val_loss: 0.1228 - val_accuracy: 0.1774\n",
            "Epoch 134/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1209 - accuracy: 0.1884 - val_loss: 0.1221 - val_accuracy: 0.1774\n",
            "Epoch 135/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1208 - accuracy: 0.1891 - val_loss: 0.1213 - val_accuracy: 0.1714\n",
            "Epoch 136/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1205 - accuracy: 0.1892 - val_loss: 0.1219 - val_accuracy: 0.1759\n",
            "Epoch 137/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1199 - accuracy: 0.1795 - val_loss: 0.1209 - val_accuracy: 0.1714\n",
            "Epoch 138/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1196 - accuracy: 0.1964 - val_loss: 0.1208 - val_accuracy: 0.1684\n",
            "Epoch 139/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1195 - accuracy: 0.1887 - val_loss: 0.1222 - val_accuracy: 0.1699\n",
            "Epoch 140/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1196 - accuracy: 0.1954 - val_loss: 0.1199 - val_accuracy: 0.1789\n",
            "Epoch 141/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1182 - accuracy: 0.1974 - val_loss: 0.1194 - val_accuracy: 0.1744\n",
            "Epoch 142/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1180 - accuracy: 0.2068 - val_loss: 0.1197 - val_accuracy: 0.1774\n",
            "Epoch 143/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1180 - accuracy: 0.2036 - val_loss: 0.1194 - val_accuracy: 0.1774\n",
            "Epoch 144/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1169 - accuracy: 0.2068 - val_loss: 0.1187 - val_accuracy: 0.1714\n",
            "Epoch 145/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1185 - accuracy: 0.1921 - val_loss: 0.1193 - val_accuracy: 0.1805\n",
            "Epoch 146/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1171 - accuracy: 0.2285 - val_loss: 0.1191 - val_accuracy: 0.1850\n",
            "Epoch 147/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1177 - accuracy: 0.2046 - val_loss: 0.1186 - val_accuracy: 0.1789\n",
            "Epoch 148/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1168 - accuracy: 0.2224 - val_loss: 0.1192 - val_accuracy: 0.1850\n",
            "Epoch 149/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1164 - accuracy: 0.2254 - val_loss: 0.1193 - val_accuracy: 0.1835\n",
            "Epoch 150/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1162 - accuracy: 0.2096 - val_loss: 0.1180 - val_accuracy: 0.1699\n",
            "Epoch 151/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1164 - accuracy: 0.2170 - val_loss: 0.1173 - val_accuracy: 0.1789\n",
            "Epoch 152/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1161 - accuracy: 0.2277 - val_loss: 0.1180 - val_accuracy: 0.1699\n",
            "Epoch 153/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1154 - accuracy: 0.2322 - val_loss: 0.1177 - val_accuracy: 0.1744\n",
            "Epoch 154/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1154 - accuracy: 0.2208 - val_loss: 0.1168 - val_accuracy: 0.1820\n",
            "Epoch 155/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1150 - accuracy: 0.2344 - val_loss: 0.1183 - val_accuracy: 0.1805\n",
            "Epoch 156/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1153 - accuracy: 0.2481 - val_loss: 0.1165 - val_accuracy: 0.1789\n",
            "Epoch 157/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1142 - accuracy: 0.2386 - val_loss: 0.1157 - val_accuracy: 0.1714\n",
            "Epoch 158/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1141 - accuracy: 0.2361 - val_loss: 0.1163 - val_accuracy: 0.1714\n",
            "Epoch 159/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1142 - accuracy: 0.2356 - val_loss: 0.1153 - val_accuracy: 0.1970\n",
            "Epoch 160/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1141 - accuracy: 0.2339 - val_loss: 0.1171 - val_accuracy: 0.1940\n",
            "Epoch 161/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1133 - accuracy: 0.2480 - val_loss: 0.1157 - val_accuracy: 0.1835\n",
            "Epoch 162/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1139 - accuracy: 0.2466 - val_loss: 0.1150 - val_accuracy: 0.1805\n",
            "Epoch 163/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1131 - accuracy: 0.2438 - val_loss: 0.1141 - val_accuracy: 0.1789\n",
            "Epoch 164/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1131 - accuracy: 0.2377 - val_loss: 0.1145 - val_accuracy: 0.1835\n",
            "Epoch 165/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1129 - accuracy: 0.2501 - val_loss: 0.1147 - val_accuracy: 0.1820\n",
            "Epoch 166/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1129 - accuracy: 0.2625 - val_loss: 0.1146 - val_accuracy: 0.1805\n",
            "Epoch 167/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1128 - accuracy: 0.2459 - val_loss: 0.1138 - val_accuracy: 0.1880\n",
            "Epoch 168/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1124 - accuracy: 0.2481 - val_loss: 0.1131 - val_accuracy: 0.1865\n",
            "Epoch 169/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1121 - accuracy: 0.2483 - val_loss: 0.1137 - val_accuracy: 0.1729\n",
            "Epoch 170/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1119 - accuracy: 0.2687 - val_loss: 0.1123 - val_accuracy: 0.1835\n",
            "Epoch 171/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1117 - accuracy: 0.2642 - val_loss: 0.1130 - val_accuracy: 0.1940\n",
            "Epoch 172/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1118 - accuracy: 0.2759 - val_loss: 0.1133 - val_accuracy: 0.1940\n",
            "Epoch 173/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1112 - accuracy: 0.2720 - val_loss: 0.1121 - val_accuracy: 0.1895\n",
            "Epoch 174/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1109 - accuracy: 0.2796 - val_loss: 0.1122 - val_accuracy: 0.1955\n",
            "Epoch 175/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1105 - accuracy: 0.2746 - val_loss: 0.1111 - val_accuracy: 0.1865\n",
            "Epoch 176/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1110 - accuracy: 0.2660 - val_loss: 0.1125 - val_accuracy: 0.1774\n",
            "Epoch 177/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1097 - accuracy: 0.2742 - val_loss: 0.1103 - val_accuracy: 0.1865\n",
            "Epoch 178/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1096 - accuracy: 0.2533 - val_loss: 0.1108 - val_accuracy: 0.1895\n",
            "Epoch 179/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1095 - accuracy: 0.2746 - val_loss: 0.1110 - val_accuracy: 0.1820\n",
            "Epoch 180/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1090 - accuracy: 0.2741 - val_loss: 0.1097 - val_accuracy: 0.1820\n",
            "Epoch 181/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1097 - accuracy: 0.2694 - val_loss: 0.1100 - val_accuracy: 0.1880\n",
            "Epoch 182/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1088 - accuracy: 0.2535 - val_loss: 0.1101 - val_accuracy: 0.1820\n",
            "Epoch 183/500\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.1091 - accuracy: 0.2704 - val_loss: 0.1102 - val_accuracy: 0.1789\n",
            "Epoch 184/500\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.1090 - accuracy: 0.2720 - val_loss: 0.1100 - val_accuracy: 0.1865\n",
            "Epoch 185/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1074 - accuracy: 0.2583 - val_loss: 0.1097 - val_accuracy: 0.1774\n",
            "Epoch 186/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1085 - accuracy: 0.2637 - val_loss: 0.1101 - val_accuracy: 0.1850\n",
            "Epoch 187/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1075 - accuracy: 0.2500 - val_loss: 0.1120 - val_accuracy: 0.1805\n",
            "Epoch 188/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1077 - accuracy: 0.2638 - val_loss: 0.1085 - val_accuracy: 0.1835\n",
            "Epoch 189/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1085 - accuracy: 0.2551 - val_loss: 0.1090 - val_accuracy: 0.1789\n",
            "Epoch 190/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1074 - accuracy: 0.2645 - val_loss: 0.1096 - val_accuracy: 0.1805\n",
            "Epoch 191/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1063 - accuracy: 0.2635 - val_loss: 0.1080 - val_accuracy: 0.1774\n",
            "Epoch 192/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1067 - accuracy: 0.2620 - val_loss: 0.1080 - val_accuracy: 0.1744\n",
            "Epoch 193/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1066 - accuracy: 0.2543 - val_loss: 0.1092 - val_accuracy: 0.1865\n",
            "Epoch 194/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1070 - accuracy: 0.2608 - val_loss: 0.1069 - val_accuracy: 0.1865\n",
            "Epoch 195/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1057 - accuracy: 0.2682 - val_loss: 0.1076 - val_accuracy: 0.1789\n",
            "Epoch 196/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1061 - accuracy: 0.2607 - val_loss: 0.1081 - val_accuracy: 0.1774\n",
            "Epoch 197/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1065 - accuracy: 0.2637 - val_loss: 0.1069 - val_accuracy: 0.1820\n",
            "Epoch 198/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1058 - accuracy: 0.2680 - val_loss: 0.1075 - val_accuracy: 0.1805\n",
            "Epoch 199/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1062 - accuracy: 0.2595 - val_loss: 0.1064 - val_accuracy: 0.1759\n",
            "Epoch 200/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1049 - accuracy: 0.2550 - val_loss: 0.1076 - val_accuracy: 0.1805\n",
            "Epoch 201/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1053 - accuracy: 0.2597 - val_loss: 0.1081 - val_accuracy: 0.1820\n",
            "Epoch 202/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1048 - accuracy: 0.2665 - val_loss: 0.1060 - val_accuracy: 0.1835\n",
            "Epoch 203/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1050 - accuracy: 0.2744 - val_loss: 0.1057 - val_accuracy: 0.1729\n",
            "Epoch 204/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1057 - accuracy: 0.2558 - val_loss: 0.1063 - val_accuracy: 0.1759\n",
            "Epoch 205/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1039 - accuracy: 0.2520 - val_loss: 0.1057 - val_accuracy: 0.1744\n",
            "Epoch 206/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1041 - accuracy: 0.2583 - val_loss: 0.1060 - val_accuracy: 0.1865\n",
            "Epoch 207/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1043 - accuracy: 0.2712 - val_loss: 0.1050 - val_accuracy: 0.1850\n",
            "Epoch 208/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1040 - accuracy: 0.2469 - val_loss: 0.1055 - val_accuracy: 0.1789\n",
            "Epoch 209/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1044 - accuracy: 0.2521 - val_loss: 0.1041 - val_accuracy: 0.1789\n",
            "Epoch 210/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1048 - accuracy: 0.2240 - val_loss: 0.1046 - val_accuracy: 0.1759\n",
            "Epoch 211/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1035 - accuracy: 0.2515 - val_loss: 0.1046 - val_accuracy: 0.1714\n",
            "Epoch 212/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1029 - accuracy: 0.2585 - val_loss: 0.1073 - val_accuracy: 0.1789\n",
            "Epoch 213/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1030 - accuracy: 0.2518 - val_loss: 0.1047 - val_accuracy: 0.1759\n",
            "Epoch 214/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1028 - accuracy: 0.2520 - val_loss: 0.1054 - val_accuracy: 0.1744\n",
            "Epoch 215/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1031 - accuracy: 0.2404 - val_loss: 0.1045 - val_accuracy: 0.1820\n",
            "Epoch 216/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1024 - accuracy: 0.2503 - val_loss: 0.1046 - val_accuracy: 0.1729\n",
            "Epoch 217/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1021 - accuracy: 0.2416 - val_loss: 0.1027 - val_accuracy: 0.1835\n",
            "Epoch 218/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1008 - accuracy: 0.2533 - val_loss: 0.1051 - val_accuracy: 0.1774\n",
            "Epoch 219/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1018 - accuracy: 0.2530 - val_loss: 0.1047 - val_accuracy: 0.1774\n",
            "Epoch 220/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1019 - accuracy: 0.2478 - val_loss: 0.1033 - val_accuracy: 0.1759\n",
            "Epoch 221/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1013 - accuracy: 0.2421 - val_loss: 0.1041 - val_accuracy: 0.1744\n",
            "Epoch 222/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1010 - accuracy: 0.2419 - val_loss: 0.1032 - val_accuracy: 0.1789\n",
            "Epoch 223/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1013 - accuracy: 0.2362 - val_loss: 0.1062 - val_accuracy: 0.1774\n",
            "Epoch 224/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1013 - accuracy: 0.2396 - val_loss: 0.1020 - val_accuracy: 0.1774\n",
            "Epoch 225/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1009 - accuracy: 0.2387 - val_loss: 0.1043 - val_accuracy: 0.1805\n",
            "Epoch 226/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1009 - accuracy: 0.2361 - val_loss: 0.1034 - val_accuracy: 0.1744\n",
            "Epoch 227/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1012 - accuracy: 0.2336 - val_loss: 0.1035 - val_accuracy: 0.1729\n",
            "Epoch 228/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1012 - accuracy: 0.2386 - val_loss: 0.1018 - val_accuracy: 0.1744\n",
            "Epoch 229/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1000 - accuracy: 0.2530 - val_loss: 0.1041 - val_accuracy: 0.1759\n",
            "Epoch 230/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1009 - accuracy: 0.2352 - val_loss: 0.1012 - val_accuracy: 0.1805\n",
            "Epoch 231/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0997 - accuracy: 0.2409 - val_loss: 0.1030 - val_accuracy: 0.1774\n",
            "Epoch 232/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1004 - accuracy: 0.2474 - val_loss: 0.1028 - val_accuracy: 0.1759\n",
            "Epoch 233/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1004 - accuracy: 0.2446 - val_loss: 0.1022 - val_accuracy: 0.1744\n",
            "Epoch 234/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0996 - accuracy: 0.2339 - val_loss: 0.1013 - val_accuracy: 0.1744\n",
            "Epoch 235/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0996 - accuracy: 0.2262 - val_loss: 0.1023 - val_accuracy: 0.1759\n",
            "Epoch 236/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0992 - accuracy: 0.2391 - val_loss: 0.1024 - val_accuracy: 0.1774\n",
            "Epoch 237/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0992 - accuracy: 0.2275 - val_loss: 0.1006 - val_accuracy: 0.1789\n",
            "Epoch 238/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1000 - accuracy: 0.2210 - val_loss: 0.1005 - val_accuracy: 0.1759\n",
            "Epoch 239/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0991 - accuracy: 0.2215 - val_loss: 0.1001 - val_accuracy: 0.1759\n",
            "Epoch 240/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0987 - accuracy: 0.2163 - val_loss: 0.1008 - val_accuracy: 0.1805\n",
            "Epoch 241/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0987 - accuracy: 0.2284 - val_loss: 0.1027 - val_accuracy: 0.1789\n",
            "Epoch 242/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0984 - accuracy: 0.2203 - val_loss: 0.0998 - val_accuracy: 0.1805\n",
            "Epoch 243/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0971 - accuracy: 0.2239 - val_loss: 0.1028 - val_accuracy: 0.1850\n",
            "Epoch 244/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0976 - accuracy: 0.2262 - val_loss: 0.0995 - val_accuracy: 0.1805\n",
            "Epoch 245/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0971 - accuracy: 0.2235 - val_loss: 0.1002 - val_accuracy: 0.1850\n",
            "Epoch 246/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0980 - accuracy: 0.2168 - val_loss: 0.1025 - val_accuracy: 0.1805\n",
            "Epoch 247/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0972 - accuracy: 0.2193 - val_loss: 0.0997 - val_accuracy: 0.1759\n",
            "Epoch 248/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0973 - accuracy: 0.2192 - val_loss: 0.1018 - val_accuracy: 0.1820\n",
            "Epoch 249/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0982 - accuracy: 0.2225 - val_loss: 0.1001 - val_accuracy: 0.1820\n",
            "Epoch 250/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0971 - accuracy: 0.2073 - val_loss: 0.0998 - val_accuracy: 0.1835\n",
            "Epoch 251/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0967 - accuracy: 0.2198 - val_loss: 0.0996 - val_accuracy: 0.1820\n",
            "Epoch 252/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0971 - accuracy: 0.2060 - val_loss: 0.0994 - val_accuracy: 0.1789\n",
            "Epoch 253/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0975 - accuracy: 0.2041 - val_loss: 0.1003 - val_accuracy: 0.1820\n",
            "Epoch 254/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0966 - accuracy: 0.2056 - val_loss: 0.0990 - val_accuracy: 0.1789\n",
            "Epoch 255/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0960 - accuracy: 0.2043 - val_loss: 0.0997 - val_accuracy: 0.1805\n",
            "Epoch 256/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0970 - accuracy: 0.2090 - val_loss: 0.0988 - val_accuracy: 0.1774\n",
            "Epoch 257/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0963 - accuracy: 0.2121 - val_loss: 0.0998 - val_accuracy: 0.1850\n",
            "Epoch 258/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0962 - accuracy: 0.2121 - val_loss: 0.0991 - val_accuracy: 0.1805\n",
            "Epoch 259/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0956 - accuracy: 0.2093 - val_loss: 0.0999 - val_accuracy: 0.1850\n",
            "Epoch 260/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0956 - accuracy: 0.2126 - val_loss: 0.1005 - val_accuracy: 0.1850\n",
            "Epoch 261/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0965 - accuracy: 0.2128 - val_loss: 0.0985 - val_accuracy: 0.1805\n",
            "Epoch 262/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0960 - accuracy: 0.2031 - val_loss: 0.0989 - val_accuracy: 0.1835\n",
            "Epoch 263/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0952 - accuracy: 0.2086 - val_loss: 0.0983 - val_accuracy: 0.1850\n",
            "Epoch 264/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0955 - accuracy: 0.2078 - val_loss: 0.0980 - val_accuracy: 0.1805\n",
            "Epoch 265/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0956 - accuracy: 0.2115 - val_loss: 0.0996 - val_accuracy: 0.1850\n",
            "Epoch 266/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0954 - accuracy: 0.2105 - val_loss: 0.0982 - val_accuracy: 0.1820\n",
            "Epoch 267/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0949 - accuracy: 0.2055 - val_loss: 0.0998 - val_accuracy: 0.1835\n",
            "Epoch 268/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0952 - accuracy: 0.2011 - val_loss: 0.0987 - val_accuracy: 0.1820\n",
            "Epoch 269/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0938 - accuracy: 0.2083 - val_loss: 0.1002 - val_accuracy: 0.1865\n",
            "Epoch 270/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0946 - accuracy: 0.2138 - val_loss: 0.0981 - val_accuracy: 0.1789\n",
            "Epoch 271/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0946 - accuracy: 0.2045 - val_loss: 0.1004 - val_accuracy: 0.1835\n",
            "Epoch 272/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0948 - accuracy: 0.2051 - val_loss: 0.0978 - val_accuracy: 0.1850\n",
            "Epoch 273/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0949 - accuracy: 0.2093 - val_loss: 0.0981 - val_accuracy: 0.1880\n",
            "Epoch 274/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0945 - accuracy: 0.2108 - val_loss: 0.0991 - val_accuracy: 0.1865\n",
            "Epoch 275/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0936 - accuracy: 0.2073 - val_loss: 0.0971 - val_accuracy: 0.1820\n",
            "Epoch 276/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0932 - accuracy: 0.2033 - val_loss: 0.0992 - val_accuracy: 0.1895\n",
            "Epoch 277/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0946 - accuracy: 0.2066 - val_loss: 0.0986 - val_accuracy: 0.1880\n",
            "Epoch 278/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0936 - accuracy: 0.1974 - val_loss: 0.0977 - val_accuracy: 0.1895\n",
            "Epoch 279/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0932 - accuracy: 0.2006 - val_loss: 0.0983 - val_accuracy: 0.1925\n",
            "Epoch 280/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0942 - accuracy: 0.2016 - val_loss: 0.0975 - val_accuracy: 0.1925\n",
            "Epoch 281/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0929 - accuracy: 0.2029 - val_loss: 0.0980 - val_accuracy: 0.1925\n",
            "Epoch 282/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0931 - accuracy: 0.2021 - val_loss: 0.1001 - val_accuracy: 0.1880\n",
            "Epoch 283/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0936 - accuracy: 0.1993 - val_loss: 0.0975 - val_accuracy: 0.1910\n",
            "Epoch 284/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0930 - accuracy: 0.1986 - val_loss: 0.0974 - val_accuracy: 0.1850\n",
            "Epoch 285/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0927 - accuracy: 0.2008 - val_loss: 0.0973 - val_accuracy: 0.1910\n",
            "Epoch 286/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0938 - accuracy: 0.1916 - val_loss: 0.0961 - val_accuracy: 0.1865\n",
            "Epoch 287/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0922 - accuracy: 0.2004 - val_loss: 0.0962 - val_accuracy: 0.1865\n",
            "Epoch 288/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0930 - accuracy: 0.1917 - val_loss: 0.0985 - val_accuracy: 0.1895\n",
            "Epoch 289/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0930 - accuracy: 0.2024 - val_loss: 0.0958 - val_accuracy: 0.1880\n",
            "Epoch 290/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0925 - accuracy: 0.1981 - val_loss: 0.0961 - val_accuracy: 0.1865\n",
            "Epoch 291/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0919 - accuracy: 0.1989 - val_loss: 0.0967 - val_accuracy: 0.1880\n",
            "Epoch 292/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0920 - accuracy: 0.1944 - val_loss: 0.0986 - val_accuracy: 0.1910\n",
            "Epoch 293/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0929 - accuracy: 0.1993 - val_loss: 0.0965 - val_accuracy: 0.1910\n",
            "Epoch 294/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0915 - accuracy: 0.1968 - val_loss: 0.0961 - val_accuracy: 0.1925\n",
            "Epoch 295/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0919 - accuracy: 0.1994 - val_loss: 0.0953 - val_accuracy: 0.1910\n",
            "Epoch 296/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0909 - accuracy: 0.1946 - val_loss: 0.0973 - val_accuracy: 0.1910\n",
            "Epoch 297/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0921 - accuracy: 0.2004 - val_loss: 0.0966 - val_accuracy: 0.1940\n",
            "Epoch 298/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0913 - accuracy: 0.1979 - val_loss: 0.0965 - val_accuracy: 0.1910\n",
            "Epoch 299/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0927 - accuracy: 0.2105 - val_loss: 0.0959 - val_accuracy: 0.1940\n",
            "Epoch 300/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0917 - accuracy: 0.2056 - val_loss: 0.0960 - val_accuracy: 0.1910\n",
            "Epoch 301/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0915 - accuracy: 0.1956 - val_loss: 0.0958 - val_accuracy: 0.1925\n",
            "Epoch 302/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0910 - accuracy: 0.1969 - val_loss: 0.0960 - val_accuracy: 0.1925\n",
            "Epoch 303/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0919 - accuracy: 0.1994 - val_loss: 0.0952 - val_accuracy: 0.1940\n",
            "Epoch 304/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0902 - accuracy: 0.2076 - val_loss: 0.0958 - val_accuracy: 0.1925\n",
            "Epoch 305/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0901 - accuracy: 0.1946 - val_loss: 0.0959 - val_accuracy: 0.1940\n",
            "Epoch 306/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0902 - accuracy: 0.1949 - val_loss: 0.0951 - val_accuracy: 0.1940\n",
            "Epoch 307/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0907 - accuracy: 0.1996 - val_loss: 0.0949 - val_accuracy: 0.1910\n",
            "Epoch 308/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0900 - accuracy: 0.1927 - val_loss: 0.0944 - val_accuracy: 0.1940\n",
            "Epoch 309/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0908 - accuracy: 0.2006 - val_loss: 0.0968 - val_accuracy: 0.1895\n",
            "Epoch 310/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0901 - accuracy: 0.1952 - val_loss: 0.0984 - val_accuracy: 0.1910\n",
            "Epoch 311/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0895 - accuracy: 0.1986 - val_loss: 0.0952 - val_accuracy: 0.1910\n",
            "Epoch 312/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0905 - accuracy: 0.1939 - val_loss: 0.0946 - val_accuracy: 0.1880\n",
            "Epoch 313/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0911 - accuracy: 0.1845 - val_loss: 0.0951 - val_accuracy: 0.1910\n",
            "Epoch 314/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0908 - accuracy: 0.1909 - val_loss: 0.0975 - val_accuracy: 0.1925\n",
            "Epoch 315/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0900 - accuracy: 0.2003 - val_loss: 0.0966 - val_accuracy: 0.1925\n",
            "Epoch 316/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0897 - accuracy: 0.2024 - val_loss: 0.0967 - val_accuracy: 0.1895\n",
            "Epoch 317/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0890 - accuracy: 0.2008 - val_loss: 0.0983 - val_accuracy: 0.1940\n",
            "Epoch 318/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0893 - accuracy: 0.2071 - val_loss: 0.0942 - val_accuracy: 0.1970\n",
            "Epoch 319/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0896 - accuracy: 0.2033 - val_loss: 0.0960 - val_accuracy: 0.2000\n",
            "Epoch 320/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0887 - accuracy: 0.2045 - val_loss: 0.0953 - val_accuracy: 0.1940\n",
            "Epoch 321/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0885 - accuracy: 0.2016 - val_loss: 0.0954 - val_accuracy: 0.1985\n",
            "Epoch 322/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0895 - accuracy: 0.2031 - val_loss: 0.0962 - val_accuracy: 0.1985\n",
            "Epoch 323/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0892 - accuracy: 0.1911 - val_loss: 0.0945 - val_accuracy: 0.1970\n",
            "Epoch 324/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0890 - accuracy: 0.1956 - val_loss: 0.0964 - val_accuracy: 0.1970\n",
            "Epoch 325/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0901 - accuracy: 0.1963 - val_loss: 0.0972 - val_accuracy: 0.1925\n",
            "Epoch 326/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0900 - accuracy: 0.1897 - val_loss: 0.0951 - val_accuracy: 0.1940\n",
            "Epoch 327/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0884 - accuracy: 0.1974 - val_loss: 0.0968 - val_accuracy: 0.1925\n",
            "Epoch 328/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0895 - accuracy: 0.1989 - val_loss: 0.0950 - val_accuracy: 0.1970\n",
            "Epoch 329/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0901 - accuracy: 0.1991 - val_loss: 0.0956 - val_accuracy: 0.1985\n",
            "Epoch 330/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0883 - accuracy: 0.1947 - val_loss: 0.0957 - val_accuracy: 0.1940\n",
            "Epoch 331/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0885 - accuracy: 0.1944 - val_loss: 0.0969 - val_accuracy: 0.1940\n",
            "Epoch 332/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0881 - accuracy: 0.1976 - val_loss: 0.0949 - val_accuracy: 0.1970\n",
            "Epoch 333/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0880 - accuracy: 0.2034 - val_loss: 0.0979 - val_accuracy: 0.1985\n",
            "Epoch 334/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0883 - accuracy: 0.1936 - val_loss: 0.0963 - val_accuracy: 0.1940\n",
            "Epoch 335/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0891 - accuracy: 0.2006 - val_loss: 0.0958 - val_accuracy: 0.2000\n",
            "Epoch 336/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0872 - accuracy: 0.1998 - val_loss: 0.0979 - val_accuracy: 0.1985\n",
            "Epoch 337/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0878 - accuracy: 0.1988 - val_loss: 0.0953 - val_accuracy: 0.1985\n",
            "Epoch 338/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0872 - accuracy: 0.1911 - val_loss: 0.0987 - val_accuracy: 0.1955\n",
            "Epoch 339/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0879 - accuracy: 0.2014 - val_loss: 0.0964 - val_accuracy: 0.1955\n",
            "Epoch 340/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0875 - accuracy: 0.2004 - val_loss: 0.0978 - val_accuracy: 0.1940\n",
            "Epoch 341/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0879 - accuracy: 0.1994 - val_loss: 0.0986 - val_accuracy: 0.1955\n",
            "Epoch 342/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0882 - accuracy: 0.1947 - val_loss: 0.0957 - val_accuracy: 0.1970\n",
            "Epoch 343/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0880 - accuracy: 0.1922 - val_loss: 0.0965 - val_accuracy: 0.1955\n",
            "Epoch 344/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0872 - accuracy: 0.1966 - val_loss: 0.0945 - val_accuracy: 0.1925\n",
            "Epoch 345/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0876 - accuracy: 0.1927 - val_loss: 0.0963 - val_accuracy: 0.1925\n",
            "Epoch 346/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0878 - accuracy: 0.1934 - val_loss: 0.0966 - val_accuracy: 0.1940\n",
            "Epoch 347/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0869 - accuracy: 0.1924 - val_loss: 0.0954 - val_accuracy: 0.1940\n",
            "Epoch 348/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0874 - accuracy: 0.1968 - val_loss: 0.0959 - val_accuracy: 0.1970\n",
            "Epoch 349/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0871 - accuracy: 0.1994 - val_loss: 0.0959 - val_accuracy: 0.1955\n",
            "Epoch 350/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0868 - accuracy: 0.2001 - val_loss: 0.0945 - val_accuracy: 0.1955\n",
            "Epoch 351/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0873 - accuracy: 0.1951 - val_loss: 0.0941 - val_accuracy: 0.2045\n",
            "Epoch 352/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0869 - accuracy: 0.1994 - val_loss: 0.0952 - val_accuracy: 0.1985\n",
            "Epoch 353/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0866 - accuracy: 0.1976 - val_loss: 0.0957 - val_accuracy: 0.2000\n",
            "Epoch 354/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0862 - accuracy: 0.1994 - val_loss: 0.0945 - val_accuracy: 0.2000\n",
            "Epoch 355/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0864 - accuracy: 0.1973 - val_loss: 0.0960 - val_accuracy: 0.1985\n",
            "Epoch 356/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0867 - accuracy: 0.1996 - val_loss: 0.0968 - val_accuracy: 0.2000\n",
            "Epoch 357/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0865 - accuracy: 0.1993 - val_loss: 0.0939 - val_accuracy: 0.2015\n",
            "Epoch 358/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0865 - accuracy: 0.1998 - val_loss: 0.0929 - val_accuracy: 0.2000\n",
            "Epoch 359/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0861 - accuracy: 0.1919 - val_loss: 0.0973 - val_accuracy: 0.1970\n",
            "Epoch 360/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0873 - accuracy: 0.1921 - val_loss: 0.0939 - val_accuracy: 0.2075\n",
            "Epoch 361/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0875 - accuracy: 0.2121 - val_loss: 0.0955 - val_accuracy: 0.2030\n",
            "Epoch 362/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0863 - accuracy: 0.2046 - val_loss: 0.0947 - val_accuracy: 0.2090\n",
            "Epoch 363/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0853 - accuracy: 0.2065 - val_loss: 0.0933 - val_accuracy: 0.2030\n",
            "Epoch 364/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0858 - accuracy: 0.2036 - val_loss: 0.0952 - val_accuracy: 0.2045\n",
            "Epoch 365/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0853 - accuracy: 0.2023 - val_loss: 0.0939 - val_accuracy: 0.2045\n",
            "Epoch 366/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0856 - accuracy: 0.2053 - val_loss: 0.0936 - val_accuracy: 0.2045\n",
            "Epoch 367/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0858 - accuracy: 0.2101 - val_loss: 0.0963 - val_accuracy: 0.2075\n",
            "Epoch 368/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0862 - accuracy: 0.2071 - val_loss: 0.0925 - val_accuracy: 0.2045\n",
            "Epoch 369/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0861 - accuracy: 0.2045 - val_loss: 0.0951 - val_accuracy: 0.2030\n",
            "Epoch 370/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0847 - accuracy: 0.2039 - val_loss: 0.0969 - val_accuracy: 0.2030\n",
            "Epoch 371/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0856 - accuracy: 0.2043 - val_loss: 0.0943 - val_accuracy: 0.2090\n",
            "Epoch 372/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0860 - accuracy: 0.2046 - val_loss: 0.0930 - val_accuracy: 0.2075\n",
            "Epoch 373/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0847 - accuracy: 0.2043 - val_loss: 0.0946 - val_accuracy: 0.2030\n",
            "Epoch 374/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0849 - accuracy: 0.2043 - val_loss: 0.0966 - val_accuracy: 0.2090\n",
            "Epoch 375/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0840 - accuracy: 0.2029 - val_loss: 0.0947 - val_accuracy: 0.2030\n",
            "Epoch 376/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0855 - accuracy: 0.2051 - val_loss: 0.0927 - val_accuracy: 0.2075\n",
            "Epoch 377/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0856 - accuracy: 0.2070 - val_loss: 0.0926 - val_accuracy: 0.2090\n",
            "Epoch 378/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0851 - accuracy: 0.2093 - val_loss: 0.0937 - val_accuracy: 0.2105\n",
            "Epoch 379/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0849 - accuracy: 0.2073 - val_loss: 0.0932 - val_accuracy: 0.2030\n",
            "Epoch 380/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0852 - accuracy: 0.2093 - val_loss: 0.0923 - val_accuracy: 0.2060\n",
            "Epoch 381/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0843 - accuracy: 0.2033 - val_loss: 0.0916 - val_accuracy: 0.2120\n",
            "Epoch 382/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0839 - accuracy: 0.2085 - val_loss: 0.0945 - val_accuracy: 0.2030\n",
            "Epoch 383/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0846 - accuracy: 0.2051 - val_loss: 0.0915 - val_accuracy: 0.2090\n",
            "Epoch 384/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0846 - accuracy: 0.2050 - val_loss: 0.0922 - val_accuracy: 0.2075\n",
            "Epoch 385/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0841 - accuracy: 0.2083 - val_loss: 0.0954 - val_accuracy: 0.2075\n",
            "Epoch 386/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0851 - accuracy: 0.2063 - val_loss: 0.0945 - val_accuracy: 0.2075\n",
            "Epoch 387/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0841 - accuracy: 0.2068 - val_loss: 0.0931 - val_accuracy: 0.2060\n",
            "Epoch 388/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0852 - accuracy: 0.2021 - val_loss: 0.0942 - val_accuracy: 0.2015\n",
            "Epoch 389/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0844 - accuracy: 0.2028 - val_loss: 0.0943 - val_accuracy: 0.2120\n",
            "Epoch 390/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0837 - accuracy: 0.2053 - val_loss: 0.0937 - val_accuracy: 0.2045\n",
            "Epoch 391/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0832 - accuracy: 0.2085 - val_loss: 0.0934 - val_accuracy: 0.2075\n",
            "Epoch 392/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0835 - accuracy: 0.2028 - val_loss: 0.0931 - val_accuracy: 0.2060\n",
            "Epoch 393/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0837 - accuracy: 0.2075 - val_loss: 0.0936 - val_accuracy: 0.2060\n",
            "Epoch 394/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0837 - accuracy: 0.2033 - val_loss: 0.0931 - val_accuracy: 0.2045\n",
            "Epoch 395/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0835 - accuracy: 0.2018 - val_loss: 0.0957 - val_accuracy: 0.2045\n",
            "Epoch 396/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0832 - accuracy: 0.2058 - val_loss: 0.0939 - val_accuracy: 0.2120\n",
            "Epoch 397/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0843 - accuracy: 0.2033 - val_loss: 0.0937 - val_accuracy: 0.2105\n",
            "Epoch 398/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0826 - accuracy: 0.2014 - val_loss: 0.0936 - val_accuracy: 0.2075\n",
            "Epoch 399/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0838 - accuracy: 0.2070 - val_loss: 0.0967 - val_accuracy: 0.2075\n",
            "Epoch 400/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0831 - accuracy: 0.2081 - val_loss: 0.0906 - val_accuracy: 0.2090\n",
            "Epoch 401/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0834 - accuracy: 0.2085 - val_loss: 0.0966 - val_accuracy: 0.2090\n",
            "Epoch 402/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0828 - accuracy: 0.2051 - val_loss: 0.0955 - val_accuracy: 0.2090\n",
            "Epoch 403/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0832 - accuracy: 0.2048 - val_loss: 0.0932 - val_accuracy: 0.2075\n",
            "Epoch 404/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0834 - accuracy: 0.2051 - val_loss: 0.0937 - val_accuracy: 0.2045\n",
            "Epoch 405/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0825 - accuracy: 0.2080 - val_loss: 0.0921 - val_accuracy: 0.2060\n",
            "Epoch 406/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0833 - accuracy: 0.2058 - val_loss: 0.0932 - val_accuracy: 0.2060\n",
            "Epoch 407/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0829 - accuracy: 0.2091 - val_loss: 0.0939 - val_accuracy: 0.2030\n",
            "Epoch 408/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0834 - accuracy: 0.2048 - val_loss: 0.0928 - val_accuracy: 0.2105\n",
            "Epoch 409/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0846 - accuracy: 0.2046 - val_loss: 0.0926 - val_accuracy: 0.2105\n",
            "Epoch 410/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0835 - accuracy: 0.2071 - val_loss: 0.0969 - val_accuracy: 0.2105\n",
            "Epoch 411/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0828 - accuracy: 0.2028 - val_loss: 0.0947 - val_accuracy: 0.2090\n",
            "Epoch 412/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0825 - accuracy: 0.2078 - val_loss: 0.0945 - val_accuracy: 0.2090\n",
            "Epoch 413/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0825 - accuracy: 0.2019 - val_loss: 0.0938 - val_accuracy: 0.2120\n",
            "Epoch 414/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0814 - accuracy: 0.2031 - val_loss: 0.0954 - val_accuracy: 0.2120\n",
            "Epoch 415/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0818 - accuracy: 0.2026 - val_loss: 0.0953 - val_accuracy: 0.2120\n",
            "Epoch 416/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0826 - accuracy: 0.2021 - val_loss: 0.0929 - val_accuracy: 0.2045\n",
            "Epoch 417/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0830 - accuracy: 0.2019 - val_loss: 0.0924 - val_accuracy: 0.2060\n",
            "Epoch 418/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0819 - accuracy: 0.2034 - val_loss: 0.0957 - val_accuracy: 0.2105\n",
            "Epoch 419/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0826 - accuracy: 0.2056 - val_loss: 0.0900 - val_accuracy: 0.2090\n",
            "Epoch 420/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0827 - accuracy: 0.2066 - val_loss: 0.0928 - val_accuracy: 0.2075\n",
            "Epoch 421/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0823 - accuracy: 0.2076 - val_loss: 0.0942 - val_accuracy: 0.2090\n",
            "Epoch 422/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0818 - accuracy: 0.2055 - val_loss: 0.0943 - val_accuracy: 0.2060\n",
            "Epoch 423/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0829 - accuracy: 0.2029 - val_loss: 0.0989 - val_accuracy: 0.2075\n",
            "Epoch 424/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0820 - accuracy: 0.2068 - val_loss: 0.0962 - val_accuracy: 0.2045\n",
            "Epoch 425/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0810 - accuracy: 0.2014 - val_loss: 0.0957 - val_accuracy: 0.2105\n",
            "Epoch 426/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0816 - accuracy: 0.2053 - val_loss: 0.0934 - val_accuracy: 0.2105\n",
            "Epoch 427/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0822 - accuracy: 0.2085 - val_loss: 0.0942 - val_accuracy: 0.2135\n",
            "Epoch 428/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0812 - accuracy: 0.2076 - val_loss: 0.0943 - val_accuracy: 0.2135\n",
            "Epoch 429/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0825 - accuracy: 0.2006 - val_loss: 0.0951 - val_accuracy: 0.2120\n",
            "Epoch 430/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0820 - accuracy: 0.2053 - val_loss: 0.0962 - val_accuracy: 0.2105\n",
            "Epoch 431/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0816 - accuracy: 0.2061 - val_loss: 0.0951 - val_accuracy: 0.2120\n",
            "Epoch 432/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0809 - accuracy: 0.2070 - val_loss: 0.0980 - val_accuracy: 0.2060\n",
            "Epoch 433/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0810 - accuracy: 0.2063 - val_loss: 0.0930 - val_accuracy: 0.2090\n",
            "Epoch 434/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0808 - accuracy: 0.2071 - val_loss: 0.0941 - val_accuracy: 0.2075\n",
            "Epoch 435/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0816 - accuracy: 0.2065 - val_loss: 0.0911 - val_accuracy: 0.2120\n",
            "Epoch 436/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0821 - accuracy: 0.2034 - val_loss: 0.0932 - val_accuracy: 0.2105\n",
            "Epoch 437/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0812 - accuracy: 0.2045 - val_loss: 0.0947 - val_accuracy: 0.2135\n",
            "Epoch 438/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0816 - accuracy: 0.2055 - val_loss: 0.0932 - val_accuracy: 0.2135\n",
            "Epoch 439/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0812 - accuracy: 0.2048 - val_loss: 0.0964 - val_accuracy: 0.2150\n",
            "Epoch 440/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0807 - accuracy: 0.2086 - val_loss: 0.0966 - val_accuracy: 0.2120\n",
            "Epoch 441/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0804 - accuracy: 0.2043 - val_loss: 0.0969 - val_accuracy: 0.2120\n",
            "Epoch 442/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0814 - accuracy: 0.2033 - val_loss: 0.0911 - val_accuracy: 0.2090\n",
            "Epoch 443/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0815 - accuracy: 0.2023 - val_loss: 0.0937 - val_accuracy: 0.2120\n",
            "Epoch 444/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0802 - accuracy: 0.2036 - val_loss: 0.0941 - val_accuracy: 0.2105\n",
            "Epoch 445/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0809 - accuracy: 0.2001 - val_loss: 0.0903 - val_accuracy: 0.2150\n",
            "Epoch 446/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0809 - accuracy: 0.2038 - val_loss: 0.0928 - val_accuracy: 0.2135\n",
            "Epoch 447/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0808 - accuracy: 0.2038 - val_loss: 0.0976 - val_accuracy: 0.2060\n",
            "Epoch 448/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0808 - accuracy: 0.2029 - val_loss: 0.0931 - val_accuracy: 0.2120\n",
            "Epoch 449/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0801 - accuracy: 0.2063 - val_loss: 0.0943 - val_accuracy: 0.2090\n",
            "Epoch 450/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0806 - accuracy: 0.2041 - val_loss: 0.0955 - val_accuracy: 0.2090\n",
            "Epoch 451/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0799 - accuracy: 0.2063 - val_loss: 0.0937 - val_accuracy: 0.2075\n",
            "Epoch 452/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0796 - accuracy: 0.2056 - val_loss: 0.0959 - val_accuracy: 0.2120\n",
            "Epoch 453/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0806 - accuracy: 0.2055 - val_loss: 0.0952 - val_accuracy: 0.2150\n",
            "Epoch 454/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0801 - accuracy: 0.2001 - val_loss: 0.0956 - val_accuracy: 0.2150\n",
            "Epoch 455/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0798 - accuracy: 0.2013 - val_loss: 0.0949 - val_accuracy: 0.2150\n",
            "Epoch 456/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0796 - accuracy: 0.2061 - val_loss: 0.0928 - val_accuracy: 0.2105\n",
            "Epoch 457/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0803 - accuracy: 0.2009 - val_loss: 0.0983 - val_accuracy: 0.2120\n",
            "Epoch 458/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0800 - accuracy: 0.2016 - val_loss: 0.0939 - val_accuracy: 0.2135\n",
            "Epoch 459/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0794 - accuracy: 0.2039 - val_loss: 0.0939 - val_accuracy: 0.2120\n",
            "Epoch 460/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0804 - accuracy: 0.2053 - val_loss: 0.0937 - val_accuracy: 0.2090\n",
            "Epoch 461/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0811 - accuracy: 0.2041 - val_loss: 0.0930 - val_accuracy: 0.2120\n",
            "Epoch 462/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0798 - accuracy: 0.2034 - val_loss: 0.0918 - val_accuracy: 0.2150\n",
            "Epoch 463/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0793 - accuracy: 0.2046 - val_loss: 0.0933 - val_accuracy: 0.2135\n",
            "Epoch 464/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0788 - accuracy: 0.2031 - val_loss: 0.0916 - val_accuracy: 0.2165\n",
            "Epoch 465/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0794 - accuracy: 0.2004 - val_loss: 0.0924 - val_accuracy: 0.2120\n",
            "Epoch 466/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0787 - accuracy: 0.2058 - val_loss: 0.0926 - val_accuracy: 0.2135\n",
            "Epoch 467/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0797 - accuracy: 0.2018 - val_loss: 0.0945 - val_accuracy: 0.2135\n",
            "Epoch 468/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0804 - accuracy: 0.1991 - val_loss: 0.0922 - val_accuracy: 0.2165\n",
            "Epoch 469/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0804 - accuracy: 0.2051 - val_loss: 0.0937 - val_accuracy: 0.2075\n",
            "Epoch 470/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0784 - accuracy: 0.2065 - val_loss: 0.0944 - val_accuracy: 0.2105\n",
            "Epoch 471/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0795 - accuracy: 0.2039 - val_loss: 0.0948 - val_accuracy: 0.2150\n",
            "Epoch 472/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0791 - accuracy: 0.2071 - val_loss: 0.0925 - val_accuracy: 0.2120\n",
            "Epoch 473/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0791 - accuracy: 0.2045 - val_loss: 0.0968 - val_accuracy: 0.2135\n",
            "Epoch 474/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0797 - accuracy: 0.2019 - val_loss: 0.0937 - val_accuracy: 0.2150\n",
            "Epoch 475/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0786 - accuracy: 0.2076 - val_loss: 0.0962 - val_accuracy: 0.2135\n",
            "Epoch 476/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0790 - accuracy: 0.2041 - val_loss: 0.0944 - val_accuracy: 0.2135\n",
            "Epoch 477/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0783 - accuracy: 0.2108 - val_loss: 0.0971 - val_accuracy: 0.2120\n",
            "Epoch 478/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0789 - accuracy: 0.2034 - val_loss: 0.0926 - val_accuracy: 0.2150\n",
            "Epoch 479/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0790 - accuracy: 0.2073 - val_loss: 0.0938 - val_accuracy: 0.2120\n",
            "Epoch 480/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0790 - accuracy: 0.2029 - val_loss: 0.0935 - val_accuracy: 0.2165\n",
            "Epoch 481/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0799 - accuracy: 0.2081 - val_loss: 0.1001 - val_accuracy: 0.2090\n",
            "Epoch 482/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0788 - accuracy: 0.2066 - val_loss: 0.0920 - val_accuracy: 0.2120\n",
            "Epoch 483/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0794 - accuracy: 0.2081 - val_loss: 0.0925 - val_accuracy: 0.2135\n",
            "Epoch 484/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0779 - accuracy: 0.2048 - val_loss: 0.0926 - val_accuracy: 0.2075\n",
            "Epoch 485/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0776 - accuracy: 0.2081 - val_loss: 0.0939 - val_accuracy: 0.2150\n",
            "Epoch 486/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0779 - accuracy: 0.2046 - val_loss: 0.0928 - val_accuracy: 0.2120\n",
            "Epoch 487/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0782 - accuracy: 0.2046 - val_loss: 0.0937 - val_accuracy: 0.2105\n",
            "Epoch 488/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0785 - accuracy: 0.2033 - val_loss: 0.0913 - val_accuracy: 0.2165\n",
            "Epoch 489/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0782 - accuracy: 0.2055 - val_loss: 0.0930 - val_accuracy: 0.2180\n",
            "Epoch 490/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0784 - accuracy: 0.2056 - val_loss: 0.0915 - val_accuracy: 0.2150\n",
            "Epoch 491/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0777 - accuracy: 0.2045 - val_loss: 0.0959 - val_accuracy: 0.2150\n",
            "Epoch 492/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0782 - accuracy: 0.2065 - val_loss: 0.1051 - val_accuracy: 0.2105\n",
            "Epoch 493/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0776 - accuracy: 0.2058 - val_loss: 0.1068 - val_accuracy: 0.2090\n",
            "Epoch 494/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0780 - accuracy: 0.2036 - val_loss: 0.0931 - val_accuracy: 0.2165\n",
            "Epoch 495/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0784 - accuracy: 0.2033 - val_loss: 0.0920 - val_accuracy: 0.2180\n",
            "Epoch 496/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0798 - accuracy: 0.2055 - val_loss: 0.0977 - val_accuracy: 0.2105\n",
            "Epoch 497/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0776 - accuracy: 0.2065 - val_loss: 0.0988 - val_accuracy: 0.2135\n",
            "Epoch 498/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0778 - accuracy: 0.2078 - val_loss: 0.0900 - val_accuracy: 0.2241\n",
            "Epoch 499/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0767 - accuracy: 0.2056 - val_loss: 0.0922 - val_accuracy: 0.2150\n",
            "Epoch 500/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0777 - accuracy: 0.2071 - val_loss: 0.0917 - val_accuracy: 0.2135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euEvkju2BpWA",
        "outputId": "2f005c96-b272-42d9-ae2d-14513098c865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.epoch, history.history['loss'], label='Train')\n",
        "plt.plot(history.epoch, history.history['val_loss'], label='Test')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbZDKTvtaRRN"
      },
      "source": [
        "## Feature improtance\n",
        "https://stackoverflow.com/questions/44119207/is-there-any-way-to-get-variable-importance-with-keras\n",
        "https://stats.stackexchange.com/questions/191855/variable-importance-in-rnn-or-lstm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKFlVWPutzmF"
      },
      "source": [
        "#pip install eli5"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7LZ7SGAaP2m"
      },
      "source": [
        "#import eli5\n",
        "#from eli5.sklearn import PermutationImportance"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-AdXfm4cA5h"
      },
      "source": [
        "#perm = PermutationImportance(model, random_state=1,scoring=\"accuracy\").fit(X_train,y_train,)\n",
        "#eli5.show_weights(perm, feature_names = X_train.columns.tolist())"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_3Ll_9mJlxS"
      },
      "source": [
        "## Find the threshold for dividing positive samples and neigative samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoHUjMB_CY5j",
        "outputId": "3e2efdfb-92ff-495f-d677-f1e6d89cce69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predict = model.predict(X_test)\n",
        "predict.shape"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(738, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktsucnyTWBjM",
        "outputId": "e1434423-16e9-485a-b5b5-88d5b9bd974d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "predict[1]"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.1582525e-11, 3.4329682e-15, 0.0000000e+00, 3.0463299e-30,\n",
              "       1.2206622e-13, 4.3235389e-13, 8.2957745e-04, 5.5999458e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT6wHCMMGCyI",
        "outputId": "e2b9926e-7a5a-4b3f-c6a9-bd803353ae9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "predict[0]"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8.1531310e-19, 1.4724492e-18, 0.0000000e+00, 1.5184271e-38,\n",
              "       1.0930026e-22, 1.6616576e-24, 1.4088096e-07, 9.6509175e-05],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfhBF8XuGPg_"
      },
      "source": [
        "month=['May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        "Client = used_id[-y_test.shape[0]:]\n",
        "\n",
        "preidct_df = pd.DataFrame(predict,columns=month,index=Client,)\n",
        "True_df=pd.DataFrame(y_test,columns=month,index=Client)"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoavcnEJIsjx",
        "outputId": "961d3621-0ee7-4131-9ee7-27b5ff144dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "preidct_df.describe()"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>May</th>\n",
              "      <th>Jun</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Nov</th>\n",
              "      <th>Dec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7.380000e+02</td>\n",
              "      <td>7.380000e+02</td>\n",
              "      <td>7.380000e+02</td>\n",
              "      <td>7.380000e+02</td>\n",
              "      <td>7.380000e+02</td>\n",
              "      <td>7.380000e+02</td>\n",
              "      <td>7.380000e+02</td>\n",
              "      <td>7.380000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>9.148239e-02</td>\n",
              "      <td>8.664242e-02</td>\n",
              "      <td>9.879821e-02</td>\n",
              "      <td>7.854912e-02</td>\n",
              "      <td>5.593656e-02</td>\n",
              "      <td>5.411663e-02</td>\n",
              "      <td>6.901874e-02</td>\n",
              "      <td>2.407418e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.518165e-01</td>\n",
              "      <td>2.357512e-01</td>\n",
              "      <td>2.489720e-01</td>\n",
              "      <td>2.122931e-01</td>\n",
              "      <td>1.759565e-01</td>\n",
              "      <td>1.794086e-01</td>\n",
              "      <td>1.712968e-01</td>\n",
              "      <td>5.712353e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.819680e-26</td>\n",
              "      <td>2.835864e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.028367e-29</td>\n",
              "      <td>1.011998e-24</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.166600e-33</td>\n",
              "      <td>2.947986e-37</td>\n",
              "      <td>9.863891e-12</td>\n",
              "      <td>1.313229e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.260103e-21</td>\n",
              "      <td>1.518884e-20</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.794129e-25</td>\n",
              "      <td>7.918147e-27</td>\n",
              "      <td>2.483166e-08</td>\n",
              "      <td>3.462157e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.700700e-10</td>\n",
              "      <td>2.904645e-12</td>\n",
              "      <td>1.936573e-19</td>\n",
              "      <td>8.002005e-14</td>\n",
              "      <td>3.347506e-10</td>\n",
              "      <td>1.465224e-10</td>\n",
              "      <td>1.244314e-03</td>\n",
              "      <td>7.416651e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.589660e-01</td>\n",
              "      <td>9.686996e-01</td>\n",
              "      <td>9.572104e-01</td>\n",
              "      <td>9.952730e-01</td>\n",
              "      <td>9.697754e-01</td>\n",
              "      <td>9.712965e-01</td>\n",
              "      <td>7.319231e-01</td>\n",
              "      <td>2.337033e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                May           Jun  ...           Nov           Dec\n",
              "count  7.380000e+02  7.380000e+02  ...  7.380000e+02  7.380000e+02\n",
              "mean   9.148239e-02  8.664242e-02  ...  6.901874e-02  2.407418e-02\n",
              "std    2.518165e-01  2.357512e-01  ...  1.712968e-01  5.712353e-02\n",
              "min    0.000000e+00  0.000000e+00  ...  2.819680e-26  2.835864e-12\n",
              "25%    1.028367e-29  1.011998e-24  ...  9.863891e-12  1.313229e-06\n",
              "50%    4.260103e-21  1.518884e-20  ...  2.483166e-08  3.462157e-05\n",
              "75%    4.700700e-10  2.904645e-12  ...  1.244314e-03  7.416651e-03\n",
              "max    9.589660e-01  9.686996e-01  ...  7.319231e-01  2.337033e-01\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxCTQs7LMhZh",
        "outputId": "9151d58b-2093-44da-c880-ffe83d14885a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "preidct_df.head()"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>May</th>\n",
              "      <th>Jun</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Nov</th>\n",
              "      <th>Dec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DB10AF3E-0F92-E011-A5C6-B6A03279A8B3</th>\n",
              "      <td>8.153131e-19</td>\n",
              "      <td>1.472449e-18</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.518427e-38</td>\n",
              "      <td>1.093003e-22</td>\n",
              "      <td>1.661658e-24</td>\n",
              "      <td>1.408810e-07</td>\n",
              "      <td>0.000097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DB1CE471-B20F-434C-B4D4-9F6D00D10976</th>\n",
              "      <td>3.158252e-11</td>\n",
              "      <td>3.432968e-15</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.046330e-30</td>\n",
              "      <td>1.220662e-13</td>\n",
              "      <td>4.323539e-13</td>\n",
              "      <td>8.295774e-04</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F771E77B-341D-4672-B6AD-A43500AB411B</th>\n",
              "      <td>6.922687e-36</td>\n",
              "      <td>1.689509e-21</td>\n",
              "      <td>2.613664e-04</td>\n",
              "      <td>9.916862e-01</td>\n",
              "      <td>6.052732e-01</td>\n",
              "      <td>1.369843e-02</td>\n",
              "      <td>6.573859e-02</td>\n",
              "      <td>0.019985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F77DFB42-B83B-47FD-BBA9-A88D00E983C1</th>\n",
              "      <td>3.467755e-23</td>\n",
              "      <td>4.885792e-21</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.313094e-28</td>\n",
              "      <td>8.425087e-31</td>\n",
              "      <td>1.573985e-09</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>E9D0885E-57E7-4EE6-A384-A61200D8ABF1</th>\n",
              "      <td>3.375984e-14</td>\n",
              "      <td>1.439499e-13</td>\n",
              "      <td>1.586240e-35</td>\n",
              "      <td>3.311717e-25</td>\n",
              "      <td>1.028942e-14</td>\n",
              "      <td>1.832767e-16</td>\n",
              "      <td>2.399702e-05</td>\n",
              "      <td>0.001307</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               May  ...       Dec\n",
              "DB10AF3E-0F92-E011-A5C6-B6A03279A8B3  8.153131e-19  ...  0.000097\n",
              "DB1CE471-B20F-434C-B4D4-9F6D00D10976  3.158252e-11  ...  0.005600\n",
              "F771E77B-341D-4672-B6AD-A43500AB411B  6.922687e-36  ...  0.019985\n",
              "F77DFB42-B83B-47FD-BBA9-A88D00E983C1  3.467755e-23  ...  0.000012\n",
              "E9D0885E-57E7-4EE6-A384-A61200D8ABF1  3.375984e-14  ...  0.001307\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFEWbwOUiIug",
        "outputId": "1c4231d5-aebe-41d0-cf9c-5505e0f3f549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "True_df.head()"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>May</th>\n",
              "      <th>Jun</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Nov</th>\n",
              "      <th>Dec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DB10AF3E-0F92-E011-A5C6-B6A03279A8B3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DB1CE471-B20F-434C-B4D4-9F6D00D10976</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F771E77B-341D-4672-B6AD-A43500AB411B</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F77DFB42-B83B-47FD-BBA9-A88D00E983C1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>E9D0885E-57E7-4EE6-A384-A61200D8ABF1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      May  Jun  Jul  Aug  Sep  Oct  Nov  Dec\n",
              "DB10AF3E-0F92-E011-A5C6-B6A03279A8B3    0    0    0    0    0    0    0    0\n",
              "DB1CE471-B20F-434C-B4D4-9F6D00D10976    0    0    0    0    0    0    0    0\n",
              "F771E77B-341D-4672-B6AD-A43500AB411B    0    0    0    1    1    0    0    0\n",
              "F77DFB42-B83B-47FD-BBA9-A88D00E983C1    0    0    0    0    0    0    0    0\n",
              "E9D0885E-57E7-4EE6-A384-A61200D8ABF1    0    0    0    0    0    0    0    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EkBsx03gi_Q"
      },
      "source": [
        "## Build a dataframe which contains two columns: Predited_value and True_Value for modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdr7LEypW-70"
      },
      "source": [
        "# Combine dataframe to a single column\n",
        "len=preidct_df.shape[0]\n",
        "name_all=[] # predicted values\n",
        "value_all=[] # months\n",
        "true_all=[]\n",
        "for elem in month:\n",
        "  value_all+=(list(preidct_df[str(elem)]))\n",
        "  true_all += (list(True_df[str(elem)]))\n",
        "  name_all += [elem]*len"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpMyxhU2dzki"
      },
      "source": [
        "# build the client column\n",
        "client=[]\n",
        "for i in range(preidct_df.shape[1]):\n",
        "  client+=Client"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8JfJLmZZ3bo",
        "outputId": "b95436b6-4daf-4c59-b88c-7a2f826118aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "# Build the datafame\n",
        "dataset=pd.DataFrame(zip(value_all,name_all,true_all),columns=['Predict','Month','Label'])\n",
        "dataset['Client_id']=client\n",
        "dataset.set_index(['Month','Client_id'],inplace=True)\n",
        "dataset.head()"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Predict</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Month</th>\n",
              "      <th>Client_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">May</th>\n",
              "      <th>DB10AF3E-0F92-E011-A5C6-B6A03279A8B3</th>\n",
              "      <td>8.153131e-19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DB1CE471-B20F-434C-B4D4-9F6D00D10976</th>\n",
              "      <td>3.158252e-11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F771E77B-341D-4672-B6AD-A43500AB411B</th>\n",
              "      <td>6.922687e-36</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F77DFB42-B83B-47FD-BBA9-A88D00E983C1</th>\n",
              "      <td>3.467755e-23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>E9D0885E-57E7-4EE6-A384-A61200D8ABF1</th>\n",
              "      <td>3.375984e-14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Predict  Label\n",
              "Month Client_id                                                \n",
              "May   DB10AF3E-0F92-E011-A5C6-B6A03279A8B3  8.153131e-19      0\n",
              "      DB1CE471-B20F-434C-B4D4-9F6D00D10976  3.158252e-11      0\n",
              "      F771E77B-341D-4672-B6AD-A43500AB411B  6.922687e-36      0\n",
              "      F77DFB42-B83B-47FD-BBA9-A88D00E983C1  3.467755e-23      0\n",
              "      E9D0885E-57E7-4EE6-A384-A61200D8ABF1  3.375984e-14      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XHDWWzSQ1wb"
      },
      "source": [
        "## Spliting the predicted value to Test and Train sets for finding the threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZGZYVOGi8sq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvEJ88GVSAG7"
      },
      "source": [
        "rate=0.2\n",
        "train, test = train_test_split(dataset, test_size=rate, random_state=5)"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlJARs70Q0Nx",
        "outputId": "a579f7d6-3622-4501-8cca-b30ff71d16e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "'''splitting the dataset to X and Y'''\n",
        "# X\n",
        "train_xth = train.Predict\n",
        "test_xth = test.Predict\n",
        "\n",
        "# Y\n",
        "train_yth = train.Label\n",
        "test_yth = test.Label\n",
        "\n",
        "print('The sizes for training dataset and test dataset:\\n',train_xth.shape,test_xth.shape)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sizes for training dataset and test dataset:\n",
            " (4723,) (1181,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrYIzBOHwEZS"
      },
      "source": [
        "### Plotting the Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHYBqPc7Gb-m",
        "outputId": "a6f922d8-7e9a-40e3-c032-f953fed7be0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "import seaborn as sns\n",
        "fig, ax = plt.subplots(figsize=(5, 4))\n",
        "for i in [0,1]:\n",
        "  sns.distplot(train_xth.loc[train.Label==i], bins=50,kde=True)\n",
        "ax.set_ylabel('Total Count')\n",
        "ax.set_title('Loss')\n",
        "ax.legend('01')\n",
        "#plt.savefig('loss'.png')"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f3c16f81ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjAjFXXllOYE"
      },
      "source": [
        "### Finding the best threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A6m-n_svXse"
      },
      "source": [
        "# from the above plot we can choose the threshold to be 0.2 or greater\n",
        "'''Generate the list for thresholds'''\n",
        "threshold = []\n",
        "num = 4000\n",
        "start=0.2\n",
        "for i in range(num):\n",
        "  val= start+0.0001*i\n",
        "  threshold.append(val)\n"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I4ibi3C24vR"
      },
      "source": [
        "# generate the list of f1_scores \n",
        "from sklearn.metrics import f1_score\n",
        "f1_scores=[]\n",
        "for thres in threshold:\n",
        "  Predited_label = []\n",
        "  for elem in test_xth:\n",
        "    if elem < thres:\n",
        "      Predited_label.append(0)\n",
        "    else:\n",
        "      Predited_label.append(1)\n",
        "  f1s=f1_score(test_yth, Predited_label, zero_division=0)\n",
        "  f1_scores.append(f1s)"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IUevWtx4a8s"
      },
      "source": [
        "# get the corrodinate of the largest f1_score\n",
        "y=max(f1_scores)\n",
        "max_index = f1_scores.index(max(f1_scores))\n",
        "x=threshold[max_index]"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dkXY410xIPr",
        "outputId": "1ceda5e1-94f1-4c3f-ff8f-0ee5890922de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(threshold,f1_scores)\n",
        "plt.title('threshold VS f1_scores')\n",
        "plt.scatter(x, y, c='red')\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('f1_scores')\n",
        "plt.text(x, y, '({:5.3f}, {:5.3f})'.format(x, y))\n",
        "plt.savefig('threshold_choose.png')\n",
        "plt.show()"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6i6qzYs-ng1",
        "outputId": "0c5c6a74-4363-47c1-d8d1-7d6ea960658b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(f'The best f1_scores is{y: 5.4f} for threshold is{x: 5.4f}.')"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best f1_scores is 0.7713 for threshold is 0.2583.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM0FTJZyfbYx"
      },
      "source": [
        "### Show the performance of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP5r6A5bla4k"
      },
      "source": [
        "# label the prediction with the choosen threshold\n",
        "predited_label=[]\n",
        "incident_index=[]# incident list\n",
        "for elem in test_xth:\n",
        "  if elem < x:\n",
        "    predited_label.append(0)\n",
        "  else:\n",
        "    predited_label.append(1)\n",
        "    indx = test_xth.loc[(test_xth.loc[:]==elem),:].index.values.tolist()\n",
        "    incident_index+=indx"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIWJziKWfCuU",
        "outputId": "b18baa56-067f-4f84-938a-00d91bc78611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(test_yth, predited_label,labels=[1,0])\n",
        "print(report)"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.73      0.82      0.77       105\n",
            "           0       0.98      0.97      0.98      1076\n",
            "\n",
            "    accuracy                           0.96      1181\n",
            "   macro avg       0.86      0.89      0.87      1181\n",
            "weighted avg       0.96      0.96      0.96      1181\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C17VdpEkdqaT",
        "outputId": "d0e39641-834d-417b-c15d-74f558dbe262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(test_yth, predited_label)\n",
        "recal = cm[1][1]/sum(cm[1])\n",
        "\n",
        "sns.heatmap(cm, annot=True,cmap='Blues')\n",
        "plt.ylabel('True')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title(f'Recall is {recal:0.3f}',y=1.05, fontsize=16)\n",
        "plt.suptitle('Confusion Matrix',y=1.06)\n",
        "\n",
        "plt.savefig('Confusion_matrix.png')\n",
        "plt.show()"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LET2Xa3bYUNk"
      },
      "source": [
        "The best result is when epcho is 500, threshold is 0.258, and f1_score is 0.771  and recall is 0.81. (drop out rate 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayBHfJ7i_o-j"
      },
      "source": [
        "## The clients who should pay attention to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YjucVZpDO3Q",
        "outputId": "e97d76bd-2719-4ad5-ab6f-0335a6ccf2c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "print('The risky clients in each month:')\n",
        "df=pd.DataFrame(incident_index,columns=['Month', 'Client_id'])\n",
        "df.sort_values(by=['Month'])"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The risky clients in each month:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month</th>\n",
              "      <th>Client_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Aug</td>\n",
              "      <td>E0CE67F9-2476-40D2-94B9-9F6C00A0001D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>Aug</td>\n",
              "      <td>F0BB6E45-C18C-46DD-8417-A07F00C9EE89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Aug</td>\n",
              "      <td>F9820D32-26C4-4CE9-959C-A60400B41C28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Aug</td>\n",
              "      <td>F8A15B65-EC5D-4540-88C6-E25F8EB44974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Aug</td>\n",
              "      <td>F3A41837-8652-48B1-A74E-A89300E7E965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Sep</td>\n",
              "      <td>DF97393F-9427-409D-B221-A44800E853C7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Sep</td>\n",
              "      <td>F5A7C654-DE9F-4E73-BBE3-A8CC00BC3179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>Sep</td>\n",
              "      <td>DF97393F-9427-409D-B221-A44800E853C7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sep</td>\n",
              "      <td>DCB47745-C27B-46F3-B02C-5ADBA189D1A0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Sep</td>\n",
              "      <td>ECE19E12-DEB8-4FE1-AD67-A7C400F15BC8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Month                             Client_id\n",
              "28   Aug  E0CE67F9-2476-40D2-94B9-9F6C00A0001D\n",
              "82   Aug  F0BB6E45-C18C-46DD-8417-A07F00C9EE89\n",
              "29   Aug  F9820D32-26C4-4CE9-959C-A60400B41C28\n",
              "55   Aug  F8A15B65-EC5D-4540-88C6-E25F8EB44974\n",
              "22   Aug  F3A41837-8652-48B1-A74E-A89300E7E965\n",
              "..   ...                                   ...\n",
              "12   Sep  DF97393F-9427-409D-B221-A44800E853C7\n",
              "13   Sep  F5A7C654-DE9F-4E73-BBE3-A8CC00BC3179\n",
              "78   Sep  DF97393F-9427-409D-B221-A44800E853C7\n",
              "7    Sep  DCB47745-C27B-46F3-B02C-5ADBA189D1A0\n",
              "26   Sep  ECE19E12-DEB8-4FE1-AD67-A7C400F15BC8\n",
              "\n",
              "[132 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    }
  ]
}