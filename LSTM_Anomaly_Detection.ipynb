{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "LSTM_Anomaly_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE32-2_1q9QC"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1q3GKyFq9QG"
      },
      "source": [
        "# df_1 = pd.read_csv('dc_part.csv')\n",
        "# df_2 = pd.read_csv('chenqin5%.csv')\n",
        "# df_3 = pd.read_csv('miaoqin_partN.csv')\n",
        "# df_4 = pd.read_csv('yunDataN.csv')\n",
        "# print(df_1.shape,df_2.shape,df_3.shape,df_4.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8T-hqDj4qSB"
      },
      "source": [
        "#df.isin([0]).sum()/df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mnvnt-EuCrC"
      },
      "source": [
        "df=pd.read_csv('LWB_Monthly_data.csv',low_memory = False)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd3c-Zf4z0m8"
      },
      "source": [
        "#df.isin([0]).sum()/df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL3lOeQCyMsB"
      },
      "source": [
        "#df.loc[:,df[df.isin([0]).sum()/df.shape[0]>0.95]]\n",
        "use=[]\n",
        "unuse=[]\n",
        "for col in df.columns:\n",
        "  if df[col].isin([0]).sum()/df.shape[0]<0.95:\n",
        "    use.append(col)\n",
        "  else:\n",
        "    unuse.append(col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEVfipExzhd5"
      },
      "source": [
        "data = df.loc[:,use]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-fDmQXidApD"
      },
      "source": [
        "# Mergeing the 4 parts of the datasets with the zero-rate less than 95%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m6MHarYYWEU"
      },
      "source": [
        "# data_parts=[df_1,df_2,df_3,df_4]\n",
        "# useful=[] # the column names for each parts that have less than 95% zeros\n",
        "# for ele in data_parts:\n",
        "#   useful_sub=[]\n",
        "#   for col in ele.columns:\n",
        "#     if ele[col].isin([0]).sum()/ele.shape[0]<0.95:\n",
        "#       useful_sub.append(col)\n",
        "#   useful.append(useful_sub)\n",
        "# useful[2]=useful[2][1:]  # drop unuseful column_name in the 4th parts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5ZNKlpHNrhA"
      },
      "source": [
        "# df_1 = df_1.loc[:,useful[0]]\n",
        "# df_2 = df_2.loc[:,useful[1]]\n",
        "# df_3 = df_3.loc[:,useful[2]]\n",
        "# df_4 = df_4.loc[:,useful[3]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucd5-0LZlEvW"
      },
      "source": [
        "#result = pd.concat([df_1,df_2,df_3,df_4], axis=1, sort=False) # combine the dateset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glIvV3rinX1N"
      },
      "source": [
        "#result.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfjmd39toDbO"
      },
      "source": [
        "### Parse 'Dates' and indexs it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI6eJ4P5bOR5"
      },
      "source": [
        "df.to_csv('Dataconcate.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-a32wgnbOKa"
      },
      "source": [
        "Dataset=pd.read_csv('Dataconcate.csv',parse_dates=['_key_occurreddate_month'],index_col=['_key_client_id','_key_occurreddate_month'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLRU4RuNuPgd"
      },
      "source": [
        "Dataset.drop(['Unnamed: 0','response_variable'],axis=1).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb8hnscXfaLu",
        "outputId": "c3e86c8d-3e91-4a17-ce52-1c7da98c832f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "#Dataset.drop(['response_variable'],axis=1).head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>incident_catgry_care_concern_piv</th>\n",
              "      <th>incident_catgry_medication_piv</th>\n",
              "      <th>incident_catgry_medical_piv</th>\n",
              "      <th>incident_catgry__piv</th>\n",
              "      <th>incident_catgry_death_piv</th>\n",
              "      <th>incident_catgry_property_and_vehicles_piv</th>\n",
              "      <th>incident_catgry_physical_and_sexual_assault_piv</th>\n",
              "      <th>incident_catgry_client_missing_piv</th>\n",
              "      <th>incident_catgry_standard_of_care_soc_piv</th>\n",
              "      <th>incident_catgry_absconding_minor_significant_qld_jurisdi_piv</th>\n",
              "      <th>incident_catgry_emergency_situation_piv</th>\n",
              "      <th>incident_catgry_restrictive_practices_piv</th>\n",
              "      <th>incident_catgry_media_piv</th>\n",
              "      <th>incident_catgry_drugs_alcohol_piv</th>\n",
              "      <th>incident_catgry_behaviour_piv</th>\n",
              "      <th>incident_catgry_client_wellbeing_piv</th>\n",
              "      <th>minor_event_total</th>\n",
              "      <th>significant_event_total</th>\n",
              "      <th>critical_event_total</th>\n",
              "      <th>Total_incident_count</th>\n",
              "      <th>response_variable</th>\n",
              "      <th>incident_subcatgry_verbal_abuse____nsw__piv</th>\n",
              "      <th>incident_subcatgry_breach_of_legislatio_piv</th>\n",
              "      <th>incident_subcatgry_ill_treatment_piv</th>\n",
              "      <th>incident_subcatgry_public_health_risk_piv</th>\n",
              "      <th>incident_subcatgry_prn_administered_piv</th>\n",
              "      <th>incident_subcatgry_family_and_domestic__piv</th>\n",
              "      <th>incident_subcatgry_reaction_to_medicati_piv</th>\n",
              "      <th>incident_subcatgry_behaviour_of_concern_piv</th>\n",
              "      <th>incident_subcatgry_possession_of_weapon_piv</th>\n",
              "      <th>incident_subcatgry_unknown_piv</th>\n",
              "      <th>incident_subcatgry_restricted_practice_piv</th>\n",
              "      <th>incident_subcatgry_physical_aggression_piv</th>\n",
              "      <th>incident_subcatgry_visitor_refused_acce_piv</th>\n",
              "      <th>incident_subcatgry_restrictive_practice_piv</th>\n",
              "      <th>incident_subcatgry_adverse_piv</th>\n",
              "      <th>incident_subcatgry_client_piv</th>\n",
              "      <th>incident_subcatgry_personal_finances_piv</th>\n",
              "      <th>incident_subcatgry_sexual_exploitation_piv</th>\n",
              "      <th>incident_subcatgry_negative_experience__piv</th>\n",
              "      <th>...</th>\n",
              "      <th>rowtype_reference_piv</th>\n",
              "      <th>rowtype_plcment_end_piv</th>\n",
              "      <th>rowtype_incident_piv</th>\n",
              "      <th>rowtype_plcment_start_piv</th>\n",
              "      <th>rowtype_program_primary_service_type_start_piv</th>\n",
              "      <th>medc_acqtyp</th>\n",
              "      <th>medc_admintype</th>\n",
              "      <th>medc_levelofindependencetype</th>\n",
              "      <th>medc_adminfreqid</th>\n",
              "      <th>status_placement</th>\n",
              "      <th>status_client_plan</th>\n",
              "      <th>status_rp_mechanical_restraint</th>\n",
              "      <th>status_rp_restricted_access</th>\n",
              "      <th>status_rp_chemical_restraint</th>\n",
              "      <th>status_rp_other</th>\n",
              "      <th>Incident</th>\n",
              "      <th>rp_environmental_restraint_piv</th>\n",
              "      <th>rp_restricted_access_piv</th>\n",
              "      <th>rp_mechanical_restraint_piv</th>\n",
              "      <th>rp_exclusionary_time_out_not_including_seclusion_piv</th>\n",
              "      <th>rp_physical_restraint_prohibited_in_cyf_piv</th>\n",
              "      <th>rp_seclusion_over_18yrs_prohibited_in_cyf_piv</th>\n",
              "      <th>rp_other_piv</th>\n",
              "      <th>rp_chemical_restraint_psychotropic_medication_piv</th>\n",
              "      <th>rp_type_detail_rp_start_mechanical_restraint_piv</th>\n",
              "      <th>rp_type_detail_rp_end_physical_restraint_prohibited_in_cyf_piv</th>\n",
              "      <th>rp_type_detail_rp_start_other_piv</th>\n",
              "      <th>rp_type_detail_rp_end_other_piv</th>\n",
              "      <th>rp_type_detail_rp_start_physical_restraint_prohibited_in_cyf_piv</th>\n",
              "      <th>rp_type_detail_rp_start_seclusion_over_18yrs_prohibited_in_cyf_piv</th>\n",
              "      <th>rp_type_detail_rp_end_environmental_restraint_piv</th>\n",
              "      <th>rp_type_detail_rp_end_chemical_restraint_psychotropic_medication_piv</th>\n",
              "      <th>rp_type_detail_rp_end_restricted_access_piv</th>\n",
              "      <th>rp_type_detail_rp_start_restricted_access_piv</th>\n",
              "      <th>rp_type_detail_rp_end_mechanical_restraint_piv</th>\n",
              "      <th>rp_type_detail_rp_start_chemical_restraint_psychotropic_medication_piv</th>\n",
              "      <th>rp_type_detail_rp_start_environmental_restraint_piv</th>\n",
              "      <th>rp_type_detail_rp_end_exclusionary_time_out_not_including_seclusion_piv</th>\n",
              "      <th>restrictivepractice_isemergency_false_piv</th>\n",
              "      <th>restrictivepractice_isemergency_true_piv</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>_key_client_id</th>\n",
              "      <th>_key_occurreddate_month</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">0000D172-EA88-432F-8235-9FAA00D29072</th>\n",
              "      <th>2019-04-01</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-05-01</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-06-01</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-01</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-01</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 339 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                              incident_catgry_care_concern_piv  ...  restrictivepractice_isemergency_true_piv\n",
              "_key_client_id                       _key_occurreddate_month                                    ...                                          \n",
              "0000D172-EA88-432F-8235-9FAA00D29072 2019-04-01                                              0  ...                                         0\n",
              "                                     2019-05-01                                              0  ...                                         0\n",
              "                                     2019-06-01                                              0  ...                                         0\n",
              "                                     2019-07-01                                              0  ...                                         0\n",
              "                                     2019-08-01                                              0  ...                                         0\n",
              "\n",
              "[5 rows x 339 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IA3ZX1Q3J0j"
      },
      "source": [
        "client_id=list(Dataset.index.get_level_values(0)) # the value of '_key_client_id' index"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OuahIt2UWF2"
      },
      "source": [
        "### Remove the Useless records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvzX1ELmMAfw"
      },
      "source": [
        "from collections import Counter\n",
        "occurrences = Counter(client_id)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZxg9_39N7FR"
      },
      "source": [
        "used_id=[]\n",
        "usedless_id=[]\n",
        "for key, value in occurrences.items():\n",
        "  if value==12:  # number can be changed\n",
        "    used_id.append(key)\n",
        "  else:\n",
        "    usedless_id.append(key)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74FXgqe1lzb_",
        "outputId": "5f87c833-2f70-412e-a3c6-6f09236827d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(f'Useful client:  {len(used_id):d}\\nUseless client: {len(usedless_id):d}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Useful client:  7380\n",
            "Useless client: 6025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIqnQ5eWQ8Oy",
        "outputId": "bbd0880c-1da9-4059-d55f-3cb460a76638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# remove the rows that the record of client is less than 12 month \n",
        "Dataset=Dataset.drop(usedless_id,level=0) \n",
        "Dataset.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88560, 340)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d38tzpQ6UBkf"
      },
      "source": [
        "Dataset.drop(['Incident'],axis=1,inplace=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obJNduOArMIa"
      },
      "source": [
        "## Perparing Dateset for Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6T0_1bqg3J-"
      },
      "source": [
        "### Spliting to Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDdZl8hahLXe",
        "outputId": "faadd269-4029-43be-bb04-91b0031b1095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "split=int(0.9*len(used_id))\n",
        "train_index=used_id[:split] # the clients who will in trainset\n",
        "test_index=used_id[split:] # the clients who will in testset\n",
        "\n",
        "# Train dataset\n",
        "train=Dataset.loc[train_index]\n",
        "train_x = train.drop('response_variable',axis=1)\n",
        "train_y = train.response_variable\n",
        "\n",
        "# Test Dataset\n",
        "test=Dataset.loc[test_index]\n",
        "test_x = test.drop('response_variable',axis=1)\n",
        "test_y = test.response_variable\n",
        "\n",
        "print(train.shape,test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(79704, 339) (8856, 339)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVBhIWD6oqke"
      },
      "source": [
        "### Normalize the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjwqksZ3oJVi"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler()\n",
        "\n",
        "train_x = scaler.fit_transform(train_x)\n",
        "\n",
        "test_x = scaler.transform(test_x)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aim_l66xgSI"
      },
      "source": [
        "###Serializing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOhbC83Kq9QL"
      },
      "source": [
        "# 4D output\n",
        "import numpy as np\n",
        "\n",
        "def create_dataset(X, y, time_steps, window, number):\n",
        "  xs, ys,channel = [],[],0\n",
        "  while channel < number: # Ensure all client data have changed to time series type\n",
        "    xs_sub, ys_sub =[],[]\n",
        "    for i in range(window - time_steps):\n",
        "      shifft= window * channel\n",
        "      v = X[i+shifft:(i + shifft + time_steps)]\n",
        "      xs_sub.append(v)\n",
        "      ys_sub.append(y[i + shifft + time_steps])\n",
        "\n",
        "    channel+=1\n",
        "    xs.append(xs_sub)\n",
        "    ys.append(ys_sub)\n",
        "\n",
        "  return np.array(xs),np.array(ys)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ9H29Sdq9QO"
      },
      "source": [
        "TIME_STEPS = 4\n",
        "WINDOW = 12 # control client change\n",
        "NUM_TRAIN = len(train_index)\n",
        "NUM_TEST = len(test_index)\n",
        "\n",
        "X_train, y_train = create_dataset(train_x,train_y, TIME_STEPS, WINDOW, NUM_TRAIN)\n",
        "X_test, y_test = create_dataset(test_x, test_y, TIME_STEPS, WINDOW,NUM_TEST)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_1HVVXRq9QQ",
        "outputId": "cc84764c-5161-464c-892f-906d6ce0724f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# [n_samples, (n_sub_sequence),TIME_STEPS, n_features]\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6642, 8, 4, 338) (6642, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07IahzPhcNX9"
      },
      "source": [
        "#y_train.counts(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nonWCISJrpa7"
      },
      "source": [
        "## LSTM AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx4xhtWAkXXW"
      },
      "source": [
        "# https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/\n",
        "''' 4D input [n_samples, n_sub_sequence,TIME_STEPS, n_features]'''\n",
        "def ConvLSMT_autoencoder(X):\n",
        "  model = Sequential()\n",
        "  model.add(layers.TimeDistributed(layers.Conv1D(filters=16, kernel_size=1, activation='relu'), input_shape=(None, X.shape[2], X.shape[3])))\n",
        "  model.add(layers.TimeDistributed(layers.MaxPooling1D(pool_size=2)))\n",
        "  model.add(layers.TimeDistributed(layers.Flatten()))\n",
        "  model.add(layers.LSTM(32, activation='relu'))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.RepeatVector(X.shape[2]))\n",
        "  model.add(layers.LSTM(4, activation='relu', return_sequences=True))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(X.shape[1],activation='sigmoid'))\n",
        "  return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OluqSOE2fRNx",
        "outputId": "cf24d743-4f77-4d0b-dbd7-7aafae346f40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "model = ConvLSMT_autoencoder(X_train)\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed (TimeDistri (None, None, 4, 16)       5424      \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, None, 2, 16)       0         \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, None, 32)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 4, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 4, 4)              592       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 136       \n",
            "=================================================================\n",
            "Total params: 14,472\n",
            "Trainable params: 14,472\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVvbWAb4dXUu"
      },
      "source": [
        "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "              optimizer=keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgSPpteoeOLD",
        "outputId": "4cba3696-51c7-4a99-c8e3-200a0150c8dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(\n",
        "    X_train,y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 48,\n",
        "    validation_split = 0.1,\n",
        "    shuffle = False)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6908 - accuracy: 0.4388 - val_loss: 0.6806 - val_accuracy: 0.6316\n",
            "Epoch 2/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6535 - accuracy: 0.4695 - val_loss: 0.5934 - val_accuracy: 0.8211\n",
            "Epoch 3/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5732 - accuracy: 0.5093 - val_loss: 0.4991 - val_accuracy: 0.7970\n",
            "Epoch 4/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.4954 - accuracy: 0.4440 - val_loss: 0.3984 - val_accuracy: 0.6707\n",
            "Epoch 5/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.4116 - accuracy: 0.3425 - val_loss: 0.2863 - val_accuracy: 0.2045\n",
            "Epoch 6/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.3356 - accuracy: 0.2749 - val_loss: 0.2312 - val_accuracy: 0.0902\n",
            "Epoch 7/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2949 - accuracy: 0.2490 - val_loss: 0.2132 - val_accuracy: 0.0902\n",
            "Epoch 8/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.2697 - accuracy: 0.2255 - val_loss: 0.2036 - val_accuracy: 0.0571\n",
            "Epoch 9/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2441 - accuracy: 0.2096 - val_loss: 0.1929 - val_accuracy: 0.0241\n",
            "Epoch 10/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2269 - accuracy: 0.1847 - val_loss: 0.1836 - val_accuracy: 0.0241\n",
            "Epoch 11/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2139 - accuracy: 0.1740 - val_loss: 0.1778 - val_accuracy: 0.0271\n",
            "Epoch 12/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2026 - accuracy: 0.1758 - val_loss: 0.1737 - val_accuracy: 0.0361\n",
            "Epoch 13/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1966 - accuracy: 0.1812 - val_loss: 0.1708 - val_accuracy: 0.0391\n",
            "Epoch 14/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1873 - accuracy: 0.1907 - val_loss: 0.1685 - val_accuracy: 0.0391\n",
            "Epoch 15/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1850 - accuracy: 0.1829 - val_loss: 0.1666 - val_accuracy: 0.0376\n",
            "Epoch 16/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1800 - accuracy: 0.1855 - val_loss: 0.1651 - val_accuracy: 0.0376\n",
            "Epoch 17/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1770 - accuracy: 0.1812 - val_loss: 0.1642 - val_accuracy: 0.0376\n",
            "Epoch 18/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1745 - accuracy: 0.1947 - val_loss: 0.1629 - val_accuracy: 0.0376\n",
            "Epoch 19/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1716 - accuracy: 0.1911 - val_loss: 0.1615 - val_accuracy: 0.0391\n",
            "Epoch 20/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1694 - accuracy: 0.1979 - val_loss: 0.1605 - val_accuracy: 0.0391\n",
            "Epoch 21/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1685 - accuracy: 0.1999 - val_loss: 0.1596 - val_accuracy: 0.0406\n",
            "Epoch 22/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1666 - accuracy: 0.2024 - val_loss: 0.1586 - val_accuracy: 0.0391\n",
            "Epoch 23/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1641 - accuracy: 0.1941 - val_loss: 0.1571 - val_accuracy: 0.0436\n",
            "Epoch 24/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1623 - accuracy: 0.1942 - val_loss: 0.1566 - val_accuracy: 0.0391\n",
            "Epoch 25/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1623 - accuracy: 0.1860 - val_loss: 0.1554 - val_accuracy: 0.0451\n",
            "Epoch 26/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1614 - accuracy: 0.1849 - val_loss: 0.1555 - val_accuracy: 0.0391\n",
            "Epoch 27/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1606 - accuracy: 0.1847 - val_loss: 0.1542 - val_accuracy: 0.0451\n",
            "Epoch 28/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1592 - accuracy: 0.1891 - val_loss: 0.1531 - val_accuracy: 0.0496\n",
            "Epoch 29/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1567 - accuracy: 0.1894 - val_loss: 0.1524 - val_accuracy: 0.0481\n",
            "Epoch 30/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1556 - accuracy: 0.2028 - val_loss: 0.1532 - val_accuracy: 0.0496\n",
            "Epoch 31/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1562 - accuracy: 0.1968 - val_loss: 0.1512 - val_accuracy: 0.0526\n",
            "Epoch 32/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1530 - accuracy: 0.2088 - val_loss: 0.1504 - val_accuracy: 0.0647\n",
            "Epoch 33/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1526 - accuracy: 0.2016 - val_loss: 0.1499 - val_accuracy: 0.0692\n",
            "Epoch 34/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1522 - accuracy: 0.2162 - val_loss: 0.1497 - val_accuracy: 0.0767\n",
            "Epoch 35/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1501 - accuracy: 0.2110 - val_loss: 0.1489 - val_accuracy: 0.0827\n",
            "Epoch 36/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1502 - accuracy: 0.2177 - val_loss: 0.1482 - val_accuracy: 0.0902\n",
            "Epoch 37/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1501 - accuracy: 0.2183 - val_loss: 0.1478 - val_accuracy: 0.0947\n",
            "Epoch 38/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1487 - accuracy: 0.2297 - val_loss: 0.1479 - val_accuracy: 0.0932\n",
            "Epoch 39/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1474 - accuracy: 0.2284 - val_loss: 0.1475 - val_accuracy: 0.1038\n",
            "Epoch 40/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1483 - accuracy: 0.2213 - val_loss: 0.1471 - val_accuracy: 0.1098\n",
            "Epoch 41/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1466 - accuracy: 0.2317 - val_loss: 0.1466 - val_accuracy: 0.1128\n",
            "Epoch 42/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1467 - accuracy: 0.2265 - val_loss: 0.1466 - val_accuracy: 0.1173\n",
            "Epoch 43/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1453 - accuracy: 0.2314 - val_loss: 0.1452 - val_accuracy: 0.1188\n",
            "Epoch 44/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1446 - accuracy: 0.2304 - val_loss: 0.1452 - val_accuracy: 0.1278\n",
            "Epoch 45/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1441 - accuracy: 0.2438 - val_loss: 0.1450 - val_accuracy: 0.1308\n",
            "Epoch 46/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1433 - accuracy: 0.2213 - val_loss: 0.1444 - val_accuracy: 0.1323\n",
            "Epoch 47/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1429 - accuracy: 0.2302 - val_loss: 0.1439 - val_accuracy: 0.1353\n",
            "Epoch 48/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1424 - accuracy: 0.2321 - val_loss: 0.1436 - val_accuracy: 0.1549\n",
            "Epoch 49/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1418 - accuracy: 0.2185 - val_loss: 0.1435 - val_accuracy: 0.1444\n",
            "Epoch 50/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1414 - accuracy: 0.2232 - val_loss: 0.1432 - val_accuracy: 0.1398\n",
            "Epoch 51/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1410 - accuracy: 0.2160 - val_loss: 0.1422 - val_accuracy: 0.1534\n",
            "Epoch 52/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1400 - accuracy: 0.2349 - val_loss: 0.1427 - val_accuracy: 0.1669\n",
            "Epoch 53/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1400 - accuracy: 0.2168 - val_loss: 0.1425 - val_accuracy: 0.1444\n",
            "Epoch 54/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1389 - accuracy: 0.2309 - val_loss: 0.1412 - val_accuracy: 0.1654\n",
            "Epoch 55/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1401 - accuracy: 0.2113 - val_loss: 0.1407 - val_accuracy: 0.1579\n",
            "Epoch 56/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1383 - accuracy: 0.2080 - val_loss: 0.1411 - val_accuracy: 0.1414\n",
            "Epoch 57/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1380 - accuracy: 0.2105 - val_loss: 0.1405 - val_accuracy: 0.1609\n",
            "Epoch 58/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1380 - accuracy: 0.2130 - val_loss: 0.1394 - val_accuracy: 0.1639\n",
            "Epoch 59/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1365 - accuracy: 0.2160 - val_loss: 0.1395 - val_accuracy: 0.1519\n",
            "Epoch 60/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1368 - accuracy: 0.2034 - val_loss: 0.1382 - val_accuracy: 0.1714\n",
            "Epoch 61/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1363 - accuracy: 0.1961 - val_loss: 0.1379 - val_accuracy: 0.1474\n",
            "Epoch 62/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1354 - accuracy: 0.2028 - val_loss: 0.1375 - val_accuracy: 0.1564\n",
            "Epoch 63/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1351 - accuracy: 0.1968 - val_loss: 0.1373 - val_accuracy: 0.1459\n",
            "Epoch 64/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1347 - accuracy: 0.1844 - val_loss: 0.1366 - val_accuracy: 0.1459\n",
            "Epoch 65/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1343 - accuracy: 0.1999 - val_loss: 0.1363 - val_accuracy: 0.1489\n",
            "Epoch 66/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1334 - accuracy: 0.1865 - val_loss: 0.1358 - val_accuracy: 0.1549\n",
            "Epoch 67/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1330 - accuracy: 0.1881 - val_loss: 0.1353 - val_accuracy: 0.1459\n",
            "Epoch 68/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1329 - accuracy: 0.1738 - val_loss: 0.1352 - val_accuracy: 0.1474\n",
            "Epoch 69/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1309 - accuracy: 0.1768 - val_loss: 0.1340 - val_accuracy: 0.1474\n",
            "Epoch 70/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1318 - accuracy: 0.1797 - val_loss: 0.1342 - val_accuracy: 0.1398\n",
            "Epoch 71/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1304 - accuracy: 0.1690 - val_loss: 0.1340 - val_accuracy: 0.1398\n",
            "Epoch 72/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1302 - accuracy: 0.1676 - val_loss: 0.1329 - val_accuracy: 0.1398\n",
            "Epoch 73/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1295 - accuracy: 0.1640 - val_loss: 0.1332 - val_accuracy: 0.1338\n",
            "Epoch 74/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1303 - accuracy: 0.1660 - val_loss: 0.1321 - val_accuracy: 0.1353\n",
            "Epoch 75/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1296 - accuracy: 0.1615 - val_loss: 0.1319 - val_accuracy: 0.1323\n",
            "Epoch 76/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1290 - accuracy: 0.1544 - val_loss: 0.1325 - val_accuracy: 0.1323\n",
            "Epoch 77/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1283 - accuracy: 0.1606 - val_loss: 0.1309 - val_accuracy: 0.1368\n",
            "Epoch 78/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1287 - accuracy: 0.1523 - val_loss: 0.1306 - val_accuracy: 0.1308\n",
            "Epoch 79/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1288 - accuracy: 0.1519 - val_loss: 0.1302 - val_accuracy: 0.1338\n",
            "Epoch 80/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1263 - accuracy: 0.1506 - val_loss: 0.1300 - val_accuracy: 0.1429\n",
            "Epoch 81/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1264 - accuracy: 0.1539 - val_loss: 0.1296 - val_accuracy: 0.1368\n",
            "Epoch 82/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1264 - accuracy: 0.1594 - val_loss: 0.1294 - val_accuracy: 0.1398\n",
            "Epoch 83/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1255 - accuracy: 0.1486 - val_loss: 0.1290 - val_accuracy: 0.1368\n",
            "Epoch 84/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1258 - accuracy: 0.1405 - val_loss: 0.1290 - val_accuracy: 0.1383\n",
            "Epoch 85/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1250 - accuracy: 0.1424 - val_loss: 0.1281 - val_accuracy: 0.1398\n",
            "Epoch 86/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1251 - accuracy: 0.1484 - val_loss: 0.1274 - val_accuracy: 0.1414\n",
            "Epoch 87/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1239 - accuracy: 0.1436 - val_loss: 0.1274 - val_accuracy: 0.1414\n",
            "Epoch 88/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1246 - accuracy: 0.1469 - val_loss: 0.1264 - val_accuracy: 0.1414\n",
            "Epoch 89/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1246 - accuracy: 0.1419 - val_loss: 0.1272 - val_accuracy: 0.1414\n",
            "Epoch 90/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.1231 - accuracy: 0.1471 - val_loss: 0.1265 - val_accuracy: 0.1459\n",
            "Epoch 91/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1217 - accuracy: 0.1400 - val_loss: 0.1256 - val_accuracy: 0.1489\n",
            "Epoch 92/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1221 - accuracy: 0.1436 - val_loss: 0.1255 - val_accuracy: 0.1519\n",
            "Epoch 93/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1215 - accuracy: 0.1437 - val_loss: 0.1240 - val_accuracy: 0.1429\n",
            "Epoch 94/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.1208 - accuracy: 0.1449 - val_loss: 0.1252 - val_accuracy: 0.1459\n",
            "Epoch 95/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1214 - accuracy: 0.1444 - val_loss: 0.1243 - val_accuracy: 0.1429\n",
            "Epoch 96/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1201 - accuracy: 0.1481 - val_loss: 0.1249 - val_accuracy: 0.1474\n",
            "Epoch 97/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1205 - accuracy: 0.1464 - val_loss: 0.1237 - val_accuracy: 0.1489\n",
            "Epoch 98/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1204 - accuracy: 0.1439 - val_loss: 0.1240 - val_accuracy: 0.1489\n",
            "Epoch 99/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1204 - accuracy: 0.1469 - val_loss: 0.1229 - val_accuracy: 0.1459\n",
            "Epoch 100/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1185 - accuracy: 0.1441 - val_loss: 0.1237 - val_accuracy: 0.1534\n",
            "Epoch 101/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1178 - accuracy: 0.1541 - val_loss: 0.1215 - val_accuracy: 0.1519\n",
            "Epoch 102/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1178 - accuracy: 0.1427 - val_loss: 0.1224 - val_accuracy: 0.1549\n",
            "Epoch 103/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1188 - accuracy: 0.1350 - val_loss: 0.1216 - val_accuracy: 0.1534\n",
            "Epoch 104/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1178 - accuracy: 0.1504 - val_loss: 0.1224 - val_accuracy: 0.1489\n",
            "Epoch 105/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1173 - accuracy: 0.1437 - val_loss: 0.1205 - val_accuracy: 0.1594\n",
            "Epoch 106/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1166 - accuracy: 0.1419 - val_loss: 0.1204 - val_accuracy: 0.1534\n",
            "Epoch 107/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1164 - accuracy: 0.1402 - val_loss: 0.1208 - val_accuracy: 0.1639\n",
            "Epoch 108/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1156 - accuracy: 0.1479 - val_loss: 0.1218 - val_accuracy: 0.1564\n",
            "Epoch 109/500\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.1163 - accuracy: 0.1504 - val_loss: 0.1211 - val_accuracy: 0.1609\n",
            "Epoch 110/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1159 - accuracy: 0.1434 - val_loss: 0.1189 - val_accuracy: 0.1579\n",
            "Epoch 111/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1150 - accuracy: 0.1519 - val_loss: 0.1186 - val_accuracy: 0.1609\n",
            "Epoch 112/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1149 - accuracy: 0.1489 - val_loss: 0.1197 - val_accuracy: 0.1579\n",
            "Epoch 113/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1143 - accuracy: 0.1499 - val_loss: 0.1184 - val_accuracy: 0.1639\n",
            "Epoch 114/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1140 - accuracy: 0.1514 - val_loss: 0.1178 - val_accuracy: 0.1654\n",
            "Epoch 115/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1139 - accuracy: 0.1616 - val_loss: 0.1180 - val_accuracy: 0.1684\n",
            "Epoch 116/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1122 - accuracy: 0.1543 - val_loss: 0.1190 - val_accuracy: 0.1624\n",
            "Epoch 117/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1130 - accuracy: 0.1528 - val_loss: 0.1166 - val_accuracy: 0.1669\n",
            "Epoch 118/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1130 - accuracy: 0.1623 - val_loss: 0.1178 - val_accuracy: 0.1699\n",
            "Epoch 119/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1119 - accuracy: 0.1517 - val_loss: 0.1162 - val_accuracy: 0.1699\n",
            "Epoch 120/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.1109 - accuracy: 0.1593 - val_loss: 0.1167 - val_accuracy: 0.1744\n",
            "Epoch 121/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1114 - accuracy: 0.1625 - val_loss: 0.1167 - val_accuracy: 0.1729\n",
            "Epoch 122/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1118 - accuracy: 0.1591 - val_loss: 0.1144 - val_accuracy: 0.1789\n",
            "Epoch 123/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1110 - accuracy: 0.1658 - val_loss: 0.1148 - val_accuracy: 0.1729\n",
            "Epoch 124/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1102 - accuracy: 0.1712 - val_loss: 0.1126 - val_accuracy: 0.1759\n",
            "Epoch 125/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1094 - accuracy: 0.1615 - val_loss: 0.1129 - val_accuracy: 0.1729\n",
            "Epoch 126/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1098 - accuracy: 0.1564 - val_loss: 0.1138 - val_accuracy: 0.1789\n",
            "Epoch 127/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1086 - accuracy: 0.1581 - val_loss: 0.1148 - val_accuracy: 0.1729\n",
            "Epoch 128/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1072 - accuracy: 0.1678 - val_loss: 0.1123 - val_accuracy: 0.1820\n",
            "Epoch 129/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1087 - accuracy: 0.1715 - val_loss: 0.1114 - val_accuracy: 0.1774\n",
            "Epoch 130/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1089 - accuracy: 0.1615 - val_loss: 0.1119 - val_accuracy: 0.1805\n",
            "Epoch 131/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1069 - accuracy: 0.1599 - val_loss: 0.1116 - val_accuracy: 0.1774\n",
            "Epoch 132/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1073 - accuracy: 0.1623 - val_loss: 0.1122 - val_accuracy: 0.1774\n",
            "Epoch 133/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1067 - accuracy: 0.1615 - val_loss: 0.1129 - val_accuracy: 0.1835\n",
            "Epoch 134/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1068 - accuracy: 0.1613 - val_loss: 0.1108 - val_accuracy: 0.1820\n",
            "Epoch 135/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1058 - accuracy: 0.1636 - val_loss: 0.1106 - val_accuracy: 0.1850\n",
            "Epoch 136/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1060 - accuracy: 0.1663 - val_loss: 0.1114 - val_accuracy: 0.1865\n",
            "Epoch 137/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1051 - accuracy: 0.1633 - val_loss: 0.1099 - val_accuracy: 0.1865\n",
            "Epoch 138/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1059 - accuracy: 0.1606 - val_loss: 0.1099 - val_accuracy: 0.1865\n",
            "Epoch 139/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1048 - accuracy: 0.1727 - val_loss: 0.1101 - val_accuracy: 0.1865\n",
            "Epoch 140/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1049 - accuracy: 0.1717 - val_loss: 0.1086 - val_accuracy: 0.1880\n",
            "Epoch 141/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1040 - accuracy: 0.1670 - val_loss: 0.1076 - val_accuracy: 0.1880\n",
            "Epoch 142/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1040 - accuracy: 0.1680 - val_loss: 0.1077 - val_accuracy: 0.1925\n",
            "Epoch 143/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1033 - accuracy: 0.1670 - val_loss: 0.1076 - val_accuracy: 0.1880\n",
            "Epoch 144/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1027 - accuracy: 0.1693 - val_loss: 0.1065 - val_accuracy: 0.1925\n",
            "Epoch 145/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1031 - accuracy: 0.1681 - val_loss: 0.1052 - val_accuracy: 0.1910\n",
            "Epoch 146/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1020 - accuracy: 0.1665 - val_loss: 0.1096 - val_accuracy: 0.1850\n",
            "Epoch 147/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1022 - accuracy: 0.1698 - val_loss: 0.1059 - val_accuracy: 0.1865\n",
            "Epoch 148/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1022 - accuracy: 0.1676 - val_loss: 0.1047 - val_accuracy: 0.1895\n",
            "Epoch 149/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1023 - accuracy: 0.1668 - val_loss: 0.1062 - val_accuracy: 0.1910\n",
            "Epoch 150/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1012 - accuracy: 0.1608 - val_loss: 0.1041 - val_accuracy: 0.1880\n",
            "Epoch 151/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1007 - accuracy: 0.1651 - val_loss: 0.1060 - val_accuracy: 0.1895\n",
            "Epoch 152/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1008 - accuracy: 0.1645 - val_loss: 0.1052 - val_accuracy: 0.1880\n",
            "Epoch 153/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1012 - accuracy: 0.1665 - val_loss: 0.1077 - val_accuracy: 0.1865\n",
            "Epoch 154/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0996 - accuracy: 0.1686 - val_loss: 0.1037 - val_accuracy: 0.1895\n",
            "Epoch 155/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1000 - accuracy: 0.1748 - val_loss: 0.1038 - val_accuracy: 0.1850\n",
            "Epoch 156/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0995 - accuracy: 0.1703 - val_loss: 0.1053 - val_accuracy: 0.1910\n",
            "Epoch 157/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0994 - accuracy: 0.1718 - val_loss: 0.1037 - val_accuracy: 0.1880\n",
            "Epoch 158/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0982 - accuracy: 0.1681 - val_loss: 0.1067 - val_accuracy: 0.1895\n",
            "Epoch 159/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0995 - accuracy: 0.1606 - val_loss: 0.1030 - val_accuracy: 0.1910\n",
            "Epoch 160/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0979 - accuracy: 0.1728 - val_loss: 0.1036 - val_accuracy: 0.1910\n",
            "Epoch 161/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0989 - accuracy: 0.1650 - val_loss: 0.1046 - val_accuracy: 0.1910\n",
            "Epoch 162/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0984 - accuracy: 0.1698 - val_loss: 0.1035 - val_accuracy: 0.1925\n",
            "Epoch 163/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0971 - accuracy: 0.1723 - val_loss: 0.1073 - val_accuracy: 0.1910\n",
            "Epoch 164/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0979 - accuracy: 0.1675 - val_loss: 0.1062 - val_accuracy: 0.1925\n",
            "Epoch 165/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0974 - accuracy: 0.1750 - val_loss: 0.1035 - val_accuracy: 0.1925\n",
            "Epoch 166/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0959 - accuracy: 0.1670 - val_loss: 0.1040 - val_accuracy: 0.1940\n",
            "Epoch 167/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0969 - accuracy: 0.1681 - val_loss: 0.1019 - val_accuracy: 0.1985\n",
            "Epoch 168/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0965 - accuracy: 0.1688 - val_loss: 0.1017 - val_accuracy: 0.1970\n",
            "Epoch 169/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0967 - accuracy: 0.1668 - val_loss: 0.1013 - val_accuracy: 0.1910\n",
            "Epoch 170/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0977 - accuracy: 0.1745 - val_loss: 0.0988 - val_accuracy: 0.1925\n",
            "Epoch 171/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0963 - accuracy: 0.1715 - val_loss: 0.1003 - val_accuracy: 0.1925\n",
            "Epoch 172/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0953 - accuracy: 0.1666 - val_loss: 0.1017 - val_accuracy: 0.1985\n",
            "Epoch 173/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0953 - accuracy: 0.1767 - val_loss: 0.1014 - val_accuracy: 0.1940\n",
            "Epoch 174/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0957 - accuracy: 0.1785 - val_loss: 0.1001 - val_accuracy: 0.1910\n",
            "Epoch 175/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0947 - accuracy: 0.1703 - val_loss: 0.1007 - val_accuracy: 0.1985\n",
            "Epoch 176/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0943 - accuracy: 0.1748 - val_loss: 0.1010 - val_accuracy: 0.1940\n",
            "Epoch 177/500\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0945 - accuracy: 0.1718 - val_loss: 0.0985 - val_accuracy: 0.1925\n",
            "Epoch 178/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0945 - accuracy: 0.1763 - val_loss: 0.0974 - val_accuracy: 0.1925\n",
            "Epoch 179/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0953 - accuracy: 0.1787 - val_loss: 0.0984 - val_accuracy: 0.1955\n",
            "Epoch 180/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0937 - accuracy: 0.1753 - val_loss: 0.1003 - val_accuracy: 0.1985\n",
            "Epoch 181/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0940 - accuracy: 0.1747 - val_loss: 0.0996 - val_accuracy: 0.1970\n",
            "Epoch 182/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0935 - accuracy: 0.1789 - val_loss: 0.0991 - val_accuracy: 0.1925\n",
            "Epoch 183/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0934 - accuracy: 0.1698 - val_loss: 0.0981 - val_accuracy: 0.1940\n",
            "Epoch 184/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0935 - accuracy: 0.1722 - val_loss: 0.0975 - val_accuracy: 0.1910\n",
            "Epoch 185/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0922 - accuracy: 0.1737 - val_loss: 0.1004 - val_accuracy: 0.1895\n",
            "Epoch 186/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0930 - accuracy: 0.1797 - val_loss: 0.0991 - val_accuracy: 0.1925\n",
            "Epoch 187/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0934 - accuracy: 0.1708 - val_loss: 0.0983 - val_accuracy: 0.1910\n",
            "Epoch 188/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0923 - accuracy: 0.1643 - val_loss: 0.0990 - val_accuracy: 0.1925\n",
            "Epoch 189/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0911 - accuracy: 0.1780 - val_loss: 0.1007 - val_accuracy: 0.1910\n",
            "Epoch 190/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0921 - accuracy: 0.1784 - val_loss: 0.0989 - val_accuracy: 0.1910\n",
            "Epoch 191/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0917 - accuracy: 0.1807 - val_loss: 0.0966 - val_accuracy: 0.1895\n",
            "Epoch 192/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0908 - accuracy: 0.1685 - val_loss: 0.0963 - val_accuracy: 0.1895\n",
            "Epoch 193/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0919 - accuracy: 0.1702 - val_loss: 0.0978 - val_accuracy: 0.1865\n",
            "Epoch 194/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0901 - accuracy: 0.1720 - val_loss: 0.1002 - val_accuracy: 0.1850\n",
            "Epoch 195/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0908 - accuracy: 0.1814 - val_loss: 0.0984 - val_accuracy: 0.1835\n",
            "Epoch 196/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0915 - accuracy: 0.1720 - val_loss: 0.0948 - val_accuracy: 0.1850\n",
            "Epoch 197/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0914 - accuracy: 0.1707 - val_loss: 0.0964 - val_accuracy: 0.1835\n",
            "Epoch 198/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0906 - accuracy: 0.1750 - val_loss: 0.0961 - val_accuracy: 0.1850\n",
            "Epoch 199/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0908 - accuracy: 0.1666 - val_loss: 0.0965 - val_accuracy: 0.1850\n",
            "Epoch 200/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0900 - accuracy: 0.1715 - val_loss: 0.0946 - val_accuracy: 0.1805\n",
            "Epoch 201/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0894 - accuracy: 0.1660 - val_loss: 0.0961 - val_accuracy: 0.1789\n",
            "Epoch 202/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0898 - accuracy: 0.1695 - val_loss: 0.0928 - val_accuracy: 0.1820\n",
            "Epoch 203/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0899 - accuracy: 0.1722 - val_loss: 0.0942 - val_accuracy: 0.1835\n",
            "Epoch 204/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0888 - accuracy: 0.1740 - val_loss: 0.0965 - val_accuracy: 0.1774\n",
            "Epoch 205/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0893 - accuracy: 0.1655 - val_loss: 0.0963 - val_accuracy: 0.1820\n",
            "Epoch 206/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0886 - accuracy: 0.1710 - val_loss: 0.0931 - val_accuracy: 0.1759\n",
            "Epoch 207/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0891 - accuracy: 0.1717 - val_loss: 0.0929 - val_accuracy: 0.1835\n",
            "Epoch 208/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0886 - accuracy: 0.1707 - val_loss: 0.0967 - val_accuracy: 0.1774\n",
            "Epoch 209/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0896 - accuracy: 0.1680 - val_loss: 0.0948 - val_accuracy: 0.1789\n",
            "Epoch 210/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0877 - accuracy: 0.1697 - val_loss: 0.0931 - val_accuracy: 0.1805\n",
            "Epoch 211/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0872 - accuracy: 0.1630 - val_loss: 0.0931 - val_accuracy: 0.1820\n",
            "Epoch 212/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0883 - accuracy: 0.1715 - val_loss: 0.0942 - val_accuracy: 0.1835\n",
            "Epoch 213/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0882 - accuracy: 0.1680 - val_loss: 0.0943 - val_accuracy: 0.1835\n",
            "Epoch 214/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0876 - accuracy: 0.1693 - val_loss: 0.0947 - val_accuracy: 0.1774\n",
            "Epoch 215/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0876 - accuracy: 0.1737 - val_loss: 0.0923 - val_accuracy: 0.1805\n",
            "Epoch 216/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0866 - accuracy: 0.1671 - val_loss: 0.0921 - val_accuracy: 0.1820\n",
            "Epoch 217/500\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0866 - accuracy: 0.1676 - val_loss: 0.0935 - val_accuracy: 0.1789\n",
            "Epoch 218/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0863 - accuracy: 0.1697 - val_loss: 0.0920 - val_accuracy: 0.1789\n",
            "Epoch 219/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0869 - accuracy: 0.1655 - val_loss: 0.0918 - val_accuracy: 0.1820\n",
            "Epoch 220/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0871 - accuracy: 0.1616 - val_loss: 0.0935 - val_accuracy: 0.1774\n",
            "Epoch 221/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0872 - accuracy: 0.1641 - val_loss: 0.0932 - val_accuracy: 0.1759\n",
            "Epoch 222/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0874 - accuracy: 0.1616 - val_loss: 0.0920 - val_accuracy: 0.1759\n",
            "Epoch 223/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0869 - accuracy: 0.1668 - val_loss: 0.0885 - val_accuracy: 0.1759\n",
            "Epoch 224/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0861 - accuracy: 0.1678 - val_loss: 0.0909 - val_accuracy: 0.1744\n",
            "Epoch 225/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0856 - accuracy: 0.1705 - val_loss: 0.0893 - val_accuracy: 0.1789\n",
            "Epoch 226/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0862 - accuracy: 0.1717 - val_loss: 0.0864 - val_accuracy: 0.1820\n",
            "Epoch 227/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0859 - accuracy: 0.1702 - val_loss: 0.0918 - val_accuracy: 0.1820\n",
            "Epoch 228/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0853 - accuracy: 0.1683 - val_loss: 0.0914 - val_accuracy: 0.1789\n",
            "Epoch 229/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0846 - accuracy: 0.1681 - val_loss: 0.0910 - val_accuracy: 0.1805\n",
            "Epoch 230/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0850 - accuracy: 0.1686 - val_loss: 0.0928 - val_accuracy: 0.1805\n",
            "Epoch 231/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0847 - accuracy: 0.1666 - val_loss: 0.0921 - val_accuracy: 0.1805\n",
            "Epoch 232/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0845 - accuracy: 0.1676 - val_loss: 0.0902 - val_accuracy: 0.1835\n",
            "Epoch 233/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0844 - accuracy: 0.1676 - val_loss: 0.0883 - val_accuracy: 0.1820\n",
            "Epoch 234/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0842 - accuracy: 0.1661 - val_loss: 0.0920 - val_accuracy: 0.1835\n",
            "Epoch 235/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0841 - accuracy: 0.1656 - val_loss: 0.0884 - val_accuracy: 0.1835\n",
            "Epoch 236/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0846 - accuracy: 0.1673 - val_loss: 0.0873 - val_accuracy: 0.1805\n",
            "Epoch 237/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0839 - accuracy: 0.1675 - val_loss: 0.0879 - val_accuracy: 0.1835\n",
            "Epoch 238/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0828 - accuracy: 0.1668 - val_loss: 0.0889 - val_accuracy: 0.1850\n",
            "Epoch 239/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0828 - accuracy: 0.1762 - val_loss: 0.0886 - val_accuracy: 0.1850\n",
            "Epoch 240/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0835 - accuracy: 0.1666 - val_loss: 0.0876 - val_accuracy: 0.1820\n",
            "Epoch 241/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0837 - accuracy: 0.1660 - val_loss: 0.0881 - val_accuracy: 0.1865\n",
            "Epoch 242/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0830 - accuracy: 0.1708 - val_loss: 0.0923 - val_accuracy: 0.1820\n",
            "Epoch 243/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0830 - accuracy: 0.1645 - val_loss: 0.0935 - val_accuracy: 0.1805\n",
            "Epoch 244/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0833 - accuracy: 0.1673 - val_loss: 0.0871 - val_accuracy: 0.1835\n",
            "Epoch 245/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0836 - accuracy: 0.1653 - val_loss: 0.0918 - val_accuracy: 0.1835\n",
            "Epoch 246/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0833 - accuracy: 0.1651 - val_loss: 0.0880 - val_accuracy: 0.1835\n",
            "Epoch 247/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0830 - accuracy: 0.1708 - val_loss: 0.0827 - val_accuracy: 0.1820\n",
            "Epoch 248/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0828 - accuracy: 0.1681 - val_loss: 0.0864 - val_accuracy: 0.1865\n",
            "Epoch 249/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0816 - accuracy: 0.1666 - val_loss: 0.0872 - val_accuracy: 0.1865\n",
            "Epoch 250/500\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0815 - accuracy: 0.1653 - val_loss: 0.0916 - val_accuracy: 0.1850\n",
            "Epoch 251/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0810 - accuracy: 0.1626 - val_loss: 0.0901 - val_accuracy: 0.1865\n",
            "Epoch 252/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0812 - accuracy: 0.1651 - val_loss: 0.0844 - val_accuracy: 0.1850\n",
            "Epoch 253/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0816 - accuracy: 0.1648 - val_loss: 0.0867 - val_accuracy: 0.1835\n",
            "Epoch 254/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0813 - accuracy: 0.1623 - val_loss: 0.0885 - val_accuracy: 0.1880\n",
            "Epoch 255/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0810 - accuracy: 0.1666 - val_loss: 0.0887 - val_accuracy: 0.1850\n",
            "Epoch 256/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0810 - accuracy: 0.1678 - val_loss: 0.0875 - val_accuracy: 0.1850\n",
            "Epoch 257/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0810 - accuracy: 0.1695 - val_loss: 0.0866 - val_accuracy: 0.1865\n",
            "Epoch 258/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0808 - accuracy: 0.1643 - val_loss: 0.0893 - val_accuracy: 0.1820\n",
            "Epoch 259/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0802 - accuracy: 0.1616 - val_loss: 0.0871 - val_accuracy: 0.1835\n",
            "Epoch 260/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0805 - accuracy: 0.1673 - val_loss: 0.0840 - val_accuracy: 0.1880\n",
            "Epoch 261/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0808 - accuracy: 0.1651 - val_loss: 0.0899 - val_accuracy: 0.1850\n",
            "Epoch 262/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0804 - accuracy: 0.1628 - val_loss: 0.0828 - val_accuracy: 0.1895\n",
            "Epoch 263/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0805 - accuracy: 0.1666 - val_loss: 0.0878 - val_accuracy: 0.1850\n",
            "Epoch 264/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0799 - accuracy: 0.1656 - val_loss: 0.0816 - val_accuracy: 0.1865\n",
            "Epoch 265/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0804 - accuracy: 0.1631 - val_loss: 0.0868 - val_accuracy: 0.1865\n",
            "Epoch 266/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0796 - accuracy: 0.1625 - val_loss: 0.0871 - val_accuracy: 0.1865\n",
            "Epoch 267/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0801 - accuracy: 0.1653 - val_loss: 0.0874 - val_accuracy: 0.1865\n",
            "Epoch 268/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0796 - accuracy: 0.1681 - val_loss: 0.0843 - val_accuracy: 0.1865\n",
            "Epoch 269/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0802 - accuracy: 0.1618 - val_loss: 0.0865 - val_accuracy: 0.1850\n",
            "Epoch 270/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0789 - accuracy: 0.1604 - val_loss: 0.0860 - val_accuracy: 0.1850\n",
            "Epoch 271/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0793 - accuracy: 0.1593 - val_loss: 0.0836 - val_accuracy: 0.1910\n",
            "Epoch 272/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0797 - accuracy: 0.1658 - val_loss: 0.0895 - val_accuracy: 0.1865\n",
            "Epoch 273/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0786 - accuracy: 0.1650 - val_loss: 0.0890 - val_accuracy: 0.1865\n",
            "Epoch 274/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0791 - accuracy: 0.1618 - val_loss: 0.0874 - val_accuracy: 0.1865\n",
            "Epoch 275/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0784 - accuracy: 0.1620 - val_loss: 0.0831 - val_accuracy: 0.1895\n",
            "Epoch 276/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0792 - accuracy: 0.1666 - val_loss: 0.0834 - val_accuracy: 0.1880\n",
            "Epoch 277/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0789 - accuracy: 0.1643 - val_loss: 0.0839 - val_accuracy: 0.1880\n",
            "Epoch 278/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0777 - accuracy: 0.1608 - val_loss: 0.0858 - val_accuracy: 0.1895\n",
            "Epoch 279/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0779 - accuracy: 0.1566 - val_loss: 0.0841 - val_accuracy: 0.1910\n",
            "Epoch 280/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0783 - accuracy: 0.1630 - val_loss: 0.0881 - val_accuracy: 0.1910\n",
            "Epoch 281/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0784 - accuracy: 0.1653 - val_loss: 0.0836 - val_accuracy: 0.1865\n",
            "Epoch 282/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0781 - accuracy: 0.1554 - val_loss: 0.0851 - val_accuracy: 0.1865\n",
            "Epoch 283/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0778 - accuracy: 0.1656 - val_loss: 0.0843 - val_accuracy: 0.1940\n",
            "Epoch 284/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0791 - accuracy: 0.1655 - val_loss: 0.0809 - val_accuracy: 0.1865\n",
            "Epoch 285/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0767 - accuracy: 0.1615 - val_loss: 0.0819 - val_accuracy: 0.1940\n",
            "Epoch 286/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0778 - accuracy: 0.1599 - val_loss: 0.0850 - val_accuracy: 0.1895\n",
            "Epoch 287/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0774 - accuracy: 0.1630 - val_loss: 0.0859 - val_accuracy: 0.1910\n",
            "Epoch 288/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0772 - accuracy: 0.1601 - val_loss: 0.0831 - val_accuracy: 0.1880\n",
            "Epoch 289/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0781 - accuracy: 0.1626 - val_loss: 0.0828 - val_accuracy: 0.1895\n",
            "Epoch 290/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0773 - accuracy: 0.1593 - val_loss: 0.0808 - val_accuracy: 0.1895\n",
            "Epoch 291/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0768 - accuracy: 0.1655 - val_loss: 0.0840 - val_accuracy: 0.1895\n",
            "Epoch 292/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0775 - accuracy: 0.1625 - val_loss: 0.0814 - val_accuracy: 0.1910\n",
            "Epoch 293/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0768 - accuracy: 0.1599 - val_loss: 0.0862 - val_accuracy: 0.1880\n",
            "Epoch 294/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0764 - accuracy: 0.1615 - val_loss: 0.0811 - val_accuracy: 0.1925\n",
            "Epoch 295/500\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0766 - accuracy: 0.1628 - val_loss: 0.0830 - val_accuracy: 0.1940\n",
            "Epoch 296/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0766 - accuracy: 0.1608 - val_loss: 0.0867 - val_accuracy: 0.1925\n",
            "Epoch 297/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0763 - accuracy: 0.1638 - val_loss: 0.0838 - val_accuracy: 0.1910\n",
            "Epoch 298/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0761 - accuracy: 0.1665 - val_loss: 0.0809 - val_accuracy: 0.1925\n",
            "Epoch 299/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0757 - accuracy: 0.1661 - val_loss: 0.0812 - val_accuracy: 0.1925\n",
            "Epoch 300/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0753 - accuracy: 0.1665 - val_loss: 0.0840 - val_accuracy: 0.1895\n",
            "Epoch 301/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0751 - accuracy: 0.1635 - val_loss: 0.0823 - val_accuracy: 0.1925\n",
            "Epoch 302/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0759 - accuracy: 0.1645 - val_loss: 0.0819 - val_accuracy: 0.1925\n",
            "Epoch 303/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0755 - accuracy: 0.1631 - val_loss: 0.0801 - val_accuracy: 0.1970\n",
            "Epoch 304/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0762 - accuracy: 0.1604 - val_loss: 0.0856 - val_accuracy: 0.1895\n",
            "Epoch 305/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0752 - accuracy: 0.1651 - val_loss: 0.0773 - val_accuracy: 0.1940\n",
            "Epoch 306/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0765 - accuracy: 0.1626 - val_loss: 0.0795 - val_accuracy: 0.1940\n",
            "Epoch 307/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0745 - accuracy: 0.1615 - val_loss: 0.0806 - val_accuracy: 0.1925\n",
            "Epoch 308/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0757 - accuracy: 0.1606 - val_loss: 0.0789 - val_accuracy: 0.1985\n",
            "Epoch 309/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0762 - accuracy: 0.1641 - val_loss: 0.0817 - val_accuracy: 0.1940\n",
            "Epoch 310/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0753 - accuracy: 0.1611 - val_loss: 0.0814 - val_accuracy: 0.1940\n",
            "Epoch 311/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0745 - accuracy: 0.1625 - val_loss: 0.0796 - val_accuracy: 0.1955\n",
            "Epoch 312/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0754 - accuracy: 0.1623 - val_loss: 0.0804 - val_accuracy: 0.1940\n",
            "Epoch 313/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0755 - accuracy: 0.1636 - val_loss: 0.0818 - val_accuracy: 0.1910\n",
            "Epoch 314/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0746 - accuracy: 0.1586 - val_loss: 0.0843 - val_accuracy: 0.1940\n",
            "Epoch 315/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0734 - accuracy: 0.1660 - val_loss: 0.0803 - val_accuracy: 0.2000\n",
            "Epoch 316/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0749 - accuracy: 0.1631 - val_loss: 0.0862 - val_accuracy: 0.1940\n",
            "Epoch 317/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0751 - accuracy: 0.1648 - val_loss: 0.0757 - val_accuracy: 0.1970\n",
            "Epoch 318/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0746 - accuracy: 0.1615 - val_loss: 0.0790 - val_accuracy: 0.1955\n",
            "Epoch 319/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0741 - accuracy: 0.1621 - val_loss: 0.0835 - val_accuracy: 0.1955\n",
            "Epoch 320/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0740 - accuracy: 0.1635 - val_loss: 0.0815 - val_accuracy: 0.1955\n",
            "Epoch 321/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0743 - accuracy: 0.1621 - val_loss: 0.0762 - val_accuracy: 0.1985\n",
            "Epoch 322/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0749 - accuracy: 0.1583 - val_loss: 0.0822 - val_accuracy: 0.1970\n",
            "Epoch 323/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0737 - accuracy: 0.1653 - val_loss: 0.0778 - val_accuracy: 0.1985\n",
            "Epoch 324/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0743 - accuracy: 0.1626 - val_loss: 0.0771 - val_accuracy: 0.1955\n",
            "Epoch 325/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0749 - accuracy: 0.1594 - val_loss: 0.0767 - val_accuracy: 0.2000\n",
            "Epoch 326/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0735 - accuracy: 0.1638 - val_loss: 0.0788 - val_accuracy: 0.2015\n",
            "Epoch 327/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0741 - accuracy: 0.1631 - val_loss: 0.0755 - val_accuracy: 0.1955\n",
            "Epoch 328/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0727 - accuracy: 0.1611 - val_loss: 0.0757 - val_accuracy: 0.2015\n",
            "Epoch 329/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0738 - accuracy: 0.1633 - val_loss: 0.0814 - val_accuracy: 0.1985\n",
            "Epoch 330/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0735 - accuracy: 0.1625 - val_loss: 0.0773 - val_accuracy: 0.1940\n",
            "Epoch 331/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0734 - accuracy: 0.1630 - val_loss: 0.0800 - val_accuracy: 0.1970\n",
            "Epoch 332/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0735 - accuracy: 0.1621 - val_loss: 0.0791 - val_accuracy: 0.1955\n",
            "Epoch 333/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0727 - accuracy: 0.1636 - val_loss: 0.0779 - val_accuracy: 0.2030\n",
            "Epoch 334/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0727 - accuracy: 0.1650 - val_loss: 0.0801 - val_accuracy: 0.1985\n",
            "Epoch 335/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0726 - accuracy: 0.1643 - val_loss: 0.0842 - val_accuracy: 0.1985\n",
            "Epoch 336/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0724 - accuracy: 0.1625 - val_loss: 0.0780 - val_accuracy: 0.2000\n",
            "Epoch 337/500\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0733 - accuracy: 0.1633 - val_loss: 0.0766 - val_accuracy: 0.1985\n",
            "Epoch 338/500\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0724 - accuracy: 0.1611 - val_loss: 0.0798 - val_accuracy: 0.1985\n",
            "Epoch 339/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0724 - accuracy: 0.1656 - val_loss: 0.0764 - val_accuracy: 0.2000\n",
            "Epoch 340/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0737 - accuracy: 0.1653 - val_loss: 0.0771 - val_accuracy: 0.1955\n",
            "Epoch 341/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0736 - accuracy: 0.1593 - val_loss: 0.0812 - val_accuracy: 0.1955\n",
            "Epoch 342/500\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0718 - accuracy: 0.1656 - val_loss: 0.0813 - val_accuracy: 0.1970\n",
            "Epoch 343/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0729 - accuracy: 0.1635 - val_loss: 0.0828 - val_accuracy: 0.1955\n",
            "Epoch 344/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0722 - accuracy: 0.1626 - val_loss: 0.0787 - val_accuracy: 0.2000\n",
            "Epoch 345/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0730 - accuracy: 0.1615 - val_loss: 0.0787 - val_accuracy: 0.1970\n",
            "Epoch 346/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0719 - accuracy: 0.1678 - val_loss: 0.0748 - val_accuracy: 0.1955\n",
            "Epoch 347/500\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0720 - accuracy: 0.1594 - val_loss: 0.0828 - val_accuracy: 0.1955\n",
            "Epoch 348/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0728 - accuracy: 0.1630 - val_loss: 0.0800 - val_accuracy: 0.1970\n",
            "Epoch 349/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0718 - accuracy: 0.1655 - val_loss: 0.0772 - val_accuracy: 0.2015\n",
            "Epoch 350/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0717 - accuracy: 0.1636 - val_loss: 0.0755 - val_accuracy: 0.1985\n",
            "Epoch 351/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0714 - accuracy: 0.1635 - val_loss: 0.0783 - val_accuracy: 0.1985\n",
            "Epoch 352/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0708 - accuracy: 0.1643 - val_loss: 0.0735 - val_accuracy: 0.2000\n",
            "Epoch 353/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0718 - accuracy: 0.1630 - val_loss: 0.0769 - val_accuracy: 0.2015\n",
            "Epoch 354/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0716 - accuracy: 0.1646 - val_loss: 0.0747 - val_accuracy: 0.1955\n",
            "Epoch 355/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0703 - accuracy: 0.1650 - val_loss: 0.0767 - val_accuracy: 0.1940\n",
            "Epoch 356/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0717 - accuracy: 0.1641 - val_loss: 0.0731 - val_accuracy: 0.1940\n",
            "Epoch 357/500\n",
            "125/125 [==============================] - 2s 17ms/step - loss: 0.0714 - accuracy: 0.1636 - val_loss: 0.0768 - val_accuracy: 0.1970\n",
            "Epoch 358/500\n",
            "125/125 [==============================] - 3s 21ms/step - loss: 0.0713 - accuracy: 0.1640 - val_loss: 0.0740 - val_accuracy: 0.2000\n",
            "Epoch 359/500\n",
            "125/125 [==============================] - 2s 20ms/step - loss: 0.0704 - accuracy: 0.1640 - val_loss: 0.0773 - val_accuracy: 0.1970\n",
            "Epoch 360/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0710 - accuracy: 0.1643 - val_loss: 0.0741 - val_accuracy: 0.2015\n",
            "Epoch 361/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0716 - accuracy: 0.1643 - val_loss: 0.0774 - val_accuracy: 0.1955\n",
            "Epoch 362/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0705 - accuracy: 0.1641 - val_loss: 0.0774 - val_accuracy: 0.1895\n",
            "Epoch 363/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0704 - accuracy: 0.1598 - val_loss: 0.0765 - val_accuracy: 0.1955\n",
            "Epoch 364/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0704 - accuracy: 0.1646 - val_loss: 0.0754 - val_accuracy: 0.1940\n",
            "Epoch 365/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0711 - accuracy: 0.1638 - val_loss: 0.0783 - val_accuracy: 0.1985\n",
            "Epoch 366/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0707 - accuracy: 0.1640 - val_loss: 0.0733 - val_accuracy: 0.1940\n",
            "Epoch 367/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0709 - accuracy: 0.1616 - val_loss: 0.0740 - val_accuracy: 0.1895\n",
            "Epoch 368/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0708 - accuracy: 0.1643 - val_loss: 0.0753 - val_accuracy: 0.1895\n",
            "Epoch 369/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0704 - accuracy: 0.1611 - val_loss: 0.0783 - val_accuracy: 0.1955\n",
            "Epoch 370/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0705 - accuracy: 0.1631 - val_loss: 0.0746 - val_accuracy: 0.1940\n",
            "Epoch 371/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0698 - accuracy: 0.1650 - val_loss: 0.0721 - val_accuracy: 0.1895\n",
            "Epoch 372/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0709 - accuracy: 0.1625 - val_loss: 0.0772 - val_accuracy: 0.1955\n",
            "Epoch 373/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0706 - accuracy: 0.1621 - val_loss: 0.0769 - val_accuracy: 0.1970\n",
            "Epoch 374/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0696 - accuracy: 0.1651 - val_loss: 0.0765 - val_accuracy: 0.1970\n",
            "Epoch 375/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0699 - accuracy: 0.1636 - val_loss: 0.0764 - val_accuracy: 0.2000\n",
            "Epoch 376/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0700 - accuracy: 0.1626 - val_loss: 0.0770 - val_accuracy: 0.1955\n",
            "Epoch 377/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0699 - accuracy: 0.1640 - val_loss: 0.0749 - val_accuracy: 0.1940\n",
            "Epoch 378/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0699 - accuracy: 0.1615 - val_loss: 0.0731 - val_accuracy: 0.1970\n",
            "Epoch 379/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0697 - accuracy: 0.1636 - val_loss: 0.0739 - val_accuracy: 0.1955\n",
            "Epoch 380/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0718 - accuracy: 0.1628 - val_loss: 0.0755 - val_accuracy: 0.1955\n",
            "Epoch 381/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0699 - accuracy: 0.1631 - val_loss: 0.0778 - val_accuracy: 0.1955\n",
            "Epoch 382/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0690 - accuracy: 0.1618 - val_loss: 0.0761 - val_accuracy: 0.1955\n",
            "Epoch 383/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0692 - accuracy: 0.1604 - val_loss: 0.0767 - val_accuracy: 0.1940\n",
            "Epoch 384/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0703 - accuracy: 0.1643 - val_loss: 0.0783 - val_accuracy: 0.1985\n",
            "Epoch 385/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0700 - accuracy: 0.1650 - val_loss: 0.0756 - val_accuracy: 0.1955\n",
            "Epoch 386/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0698 - accuracy: 0.1625 - val_loss: 0.0766 - val_accuracy: 0.1940\n",
            "Epoch 387/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0688 - accuracy: 0.1661 - val_loss: 0.0737 - val_accuracy: 0.1955\n",
            "Epoch 388/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0684 - accuracy: 0.1631 - val_loss: 0.0727 - val_accuracy: 0.1970\n",
            "Epoch 389/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0701 - accuracy: 0.1650 - val_loss: 0.0741 - val_accuracy: 0.1955\n",
            "Epoch 390/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0699 - accuracy: 0.1621 - val_loss: 0.0764 - val_accuracy: 0.1985\n",
            "Epoch 391/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0689 - accuracy: 0.1610 - val_loss: 0.0745 - val_accuracy: 0.1985\n",
            "Epoch 392/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0696 - accuracy: 0.1610 - val_loss: 0.0746 - val_accuracy: 0.1955\n",
            "Epoch 393/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0693 - accuracy: 0.1645 - val_loss: 0.0805 - val_accuracy: 0.1940\n",
            "Epoch 394/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0686 - accuracy: 0.1650 - val_loss: 0.0735 - val_accuracy: 0.2000\n",
            "Epoch 395/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0693 - accuracy: 0.1635 - val_loss: 0.0744 - val_accuracy: 0.1955\n",
            "Epoch 396/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0689 - accuracy: 0.1633 - val_loss: 0.0744 - val_accuracy: 0.1940\n",
            "Epoch 397/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0694 - accuracy: 0.1611 - val_loss: 0.0737 - val_accuracy: 0.1955\n",
            "Epoch 398/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0680 - accuracy: 0.1631 - val_loss: 0.0727 - val_accuracy: 0.1955\n",
            "Epoch 399/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0696 - accuracy: 0.1646 - val_loss: 0.0736 - val_accuracy: 0.1955\n",
            "Epoch 400/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0681 - accuracy: 0.1640 - val_loss: 0.0746 - val_accuracy: 0.1955\n",
            "Epoch 401/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0692 - accuracy: 0.1620 - val_loss: 0.0735 - val_accuracy: 0.2000\n",
            "Epoch 402/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0688 - accuracy: 0.1658 - val_loss: 0.0751 - val_accuracy: 0.1970\n",
            "Epoch 403/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0678 - accuracy: 0.1646 - val_loss: 0.0740 - val_accuracy: 0.1940\n",
            "Epoch 404/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0688 - accuracy: 0.1671 - val_loss: 0.0765 - val_accuracy: 0.1940\n",
            "Epoch 405/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0685 - accuracy: 0.1638 - val_loss: 0.0763 - val_accuracy: 0.1970\n",
            "Epoch 406/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0680 - accuracy: 0.1645 - val_loss: 0.0747 - val_accuracy: 0.1970\n",
            "Epoch 407/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0677 - accuracy: 0.1645 - val_loss: 0.0764 - val_accuracy: 0.1955\n",
            "Epoch 408/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0681 - accuracy: 0.1640 - val_loss: 0.0725 - val_accuracy: 0.1955\n",
            "Epoch 409/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0683 - accuracy: 0.1661 - val_loss: 0.0741 - val_accuracy: 0.1985\n",
            "Epoch 410/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0681 - accuracy: 0.1640 - val_loss: 0.0717 - val_accuracy: 0.1955\n",
            "Epoch 411/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0687 - accuracy: 0.1678 - val_loss: 0.0726 - val_accuracy: 0.1955\n",
            "Epoch 412/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0686 - accuracy: 0.1633 - val_loss: 0.0708 - val_accuracy: 0.1985\n",
            "Epoch 413/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0672 - accuracy: 0.1665 - val_loss: 0.0705 - val_accuracy: 0.1940\n",
            "Epoch 414/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0678 - accuracy: 0.1680 - val_loss: 0.0727 - val_accuracy: 0.2000\n",
            "Epoch 415/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0682 - accuracy: 0.1638 - val_loss: 0.0742 - val_accuracy: 0.1985\n",
            "Epoch 416/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0689 - accuracy: 0.1658 - val_loss: 0.0726 - val_accuracy: 0.1955\n",
            "Epoch 417/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0679 - accuracy: 0.1635 - val_loss: 0.0729 - val_accuracy: 0.1985\n",
            "Epoch 418/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0676 - accuracy: 0.1656 - val_loss: 0.0720 - val_accuracy: 0.1970\n",
            "Epoch 419/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0674 - accuracy: 0.1643 - val_loss: 0.0713 - val_accuracy: 0.1985\n",
            "Epoch 420/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0664 - accuracy: 0.1655 - val_loss: 0.0795 - val_accuracy: 0.1970\n",
            "Epoch 421/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0677 - accuracy: 0.1643 - val_loss: 0.0768 - val_accuracy: 0.1940\n",
            "Epoch 422/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0666 - accuracy: 0.1685 - val_loss: 0.0747 - val_accuracy: 0.1985\n",
            "Epoch 423/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0683 - accuracy: 0.1628 - val_loss: 0.0733 - val_accuracy: 0.2000\n",
            "Epoch 424/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0668 - accuracy: 0.1645 - val_loss: 0.0799 - val_accuracy: 0.1940\n",
            "Epoch 425/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0675 - accuracy: 0.1670 - val_loss: 0.0762 - val_accuracy: 0.2000\n",
            "Epoch 426/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0681 - accuracy: 0.1635 - val_loss: 0.0750 - val_accuracy: 0.2015\n",
            "Epoch 427/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0672 - accuracy: 0.1673 - val_loss: 0.0732 - val_accuracy: 0.2015\n",
            "Epoch 428/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0675 - accuracy: 0.1645 - val_loss: 0.0726 - val_accuracy: 0.2000\n",
            "Epoch 429/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0670 - accuracy: 0.1646 - val_loss: 0.0740 - val_accuracy: 0.2015\n",
            "Epoch 430/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0664 - accuracy: 0.1651 - val_loss: 0.0752 - val_accuracy: 0.1985\n",
            "Epoch 431/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0666 - accuracy: 0.1620 - val_loss: 0.0739 - val_accuracy: 0.1970\n",
            "Epoch 432/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0679 - accuracy: 0.1640 - val_loss: 0.0747 - val_accuracy: 0.1940\n",
            "Epoch 433/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0674 - accuracy: 0.1660 - val_loss: 0.0710 - val_accuracy: 0.2000\n",
            "Epoch 434/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0669 - accuracy: 0.1651 - val_loss: 0.0729 - val_accuracy: 0.1985\n",
            "Epoch 435/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0674 - accuracy: 0.1660 - val_loss: 0.0743 - val_accuracy: 0.1985\n",
            "Epoch 436/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0672 - accuracy: 0.1640 - val_loss: 0.0743 - val_accuracy: 0.1970\n",
            "Epoch 437/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0662 - accuracy: 0.1670 - val_loss: 0.0732 - val_accuracy: 0.1970\n",
            "Epoch 438/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0671 - accuracy: 0.1630 - val_loss: 0.0757 - val_accuracy: 0.1970\n",
            "Epoch 439/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0672 - accuracy: 0.1663 - val_loss: 0.0723 - val_accuracy: 0.2000\n",
            "Epoch 440/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0679 - accuracy: 0.1660 - val_loss: 0.0727 - val_accuracy: 0.1985\n",
            "Epoch 441/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0663 - accuracy: 0.1666 - val_loss: 0.0733 - val_accuracy: 0.1985\n",
            "Epoch 442/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0662 - accuracy: 0.1655 - val_loss: 0.0757 - val_accuracy: 0.1985\n",
            "Epoch 443/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0669 - accuracy: 0.1633 - val_loss: 0.0738 - val_accuracy: 0.2045\n",
            "Epoch 444/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0659 - accuracy: 0.1635 - val_loss: 0.0710 - val_accuracy: 0.2045\n",
            "Epoch 445/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0671 - accuracy: 0.1656 - val_loss: 0.0741 - val_accuracy: 0.2000\n",
            "Epoch 446/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0663 - accuracy: 0.1656 - val_loss: 0.0731 - val_accuracy: 0.2015\n",
            "Epoch 447/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0659 - accuracy: 0.1690 - val_loss: 0.0781 - val_accuracy: 0.1985\n",
            "Epoch 448/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0663 - accuracy: 0.1675 - val_loss: 0.0694 - val_accuracy: 0.2045\n",
            "Epoch 449/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0655 - accuracy: 0.1663 - val_loss: 0.0762 - val_accuracy: 0.2000\n",
            "Epoch 450/500\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0658 - accuracy: 0.1668 - val_loss: 0.0737 - val_accuracy: 0.2015\n",
            "Epoch 451/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0654 - accuracy: 0.1686 - val_loss: 0.0730 - val_accuracy: 0.2045\n",
            "Epoch 452/500\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0661 - accuracy: 0.1691 - val_loss: 0.0727 - val_accuracy: 0.2015\n",
            "Epoch 453/500\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0661 - accuracy: 0.1678 - val_loss: 0.0755 - val_accuracy: 0.2030\n",
            "Epoch 454/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0647 - accuracy: 0.1675 - val_loss: 0.0775 - val_accuracy: 0.2015\n",
            "Epoch 455/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0653 - accuracy: 0.1675 - val_loss: 0.0755 - val_accuracy: 0.2000\n",
            "Epoch 456/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0657 - accuracy: 0.1695 - val_loss: 0.0735 - val_accuracy: 0.2045\n",
            "Epoch 457/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0649 - accuracy: 0.1660 - val_loss: 0.0697 - val_accuracy: 0.2060\n",
            "Epoch 458/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0668 - accuracy: 0.1650 - val_loss: 0.0720 - val_accuracy: 0.2015\n",
            "Epoch 459/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0668 - accuracy: 0.1635 - val_loss: 0.0728 - val_accuracy: 0.2030\n",
            "Epoch 460/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0653 - accuracy: 0.1668 - val_loss: 0.0733 - val_accuracy: 0.1985\n",
            "Epoch 461/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0654 - accuracy: 0.1690 - val_loss: 0.0774 - val_accuracy: 0.1970\n",
            "Epoch 462/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0667 - accuracy: 0.1651 - val_loss: 0.0746 - val_accuracy: 0.1985\n",
            "Epoch 463/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0650 - accuracy: 0.1663 - val_loss: 0.0699 - val_accuracy: 0.1985\n",
            "Epoch 464/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0642 - accuracy: 0.1640 - val_loss: 0.0766 - val_accuracy: 0.1970\n",
            "Epoch 465/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0649 - accuracy: 0.1668 - val_loss: 0.0712 - val_accuracy: 0.2030\n",
            "Epoch 466/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0669 - accuracy: 0.1636 - val_loss: 0.0719 - val_accuracy: 0.2015\n",
            "Epoch 467/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0649 - accuracy: 0.1663 - val_loss: 0.0750 - val_accuracy: 0.1970\n",
            "Epoch 468/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0656 - accuracy: 0.1645 - val_loss: 0.0760 - val_accuracy: 0.1955\n",
            "Epoch 469/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0652 - accuracy: 0.1641 - val_loss: 0.0707 - val_accuracy: 0.2015\n",
            "Epoch 470/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0656 - accuracy: 0.1660 - val_loss: 0.0742 - val_accuracy: 0.2015\n",
            "Epoch 471/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0642 - accuracy: 0.1646 - val_loss: 0.0714 - val_accuracy: 0.2000\n",
            "Epoch 472/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0657 - accuracy: 0.1697 - val_loss: 0.0745 - val_accuracy: 0.2015\n",
            "Epoch 473/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0647 - accuracy: 0.1666 - val_loss: 0.0711 - val_accuracy: 0.2030\n",
            "Epoch 474/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0660 - accuracy: 0.1638 - val_loss: 0.0708 - val_accuracy: 0.2015\n",
            "Epoch 475/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0652 - accuracy: 0.1660 - val_loss: 0.0708 - val_accuracy: 0.2060\n",
            "Epoch 476/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0648 - accuracy: 0.1671 - val_loss: 0.0748 - val_accuracy: 0.1985\n",
            "Epoch 477/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0645 - accuracy: 0.1660 - val_loss: 0.0752 - val_accuracy: 0.1985\n",
            "Epoch 478/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0645 - accuracy: 0.1621 - val_loss: 0.0772 - val_accuracy: 0.1985\n",
            "Epoch 479/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0645 - accuracy: 0.1660 - val_loss: 0.0710 - val_accuracy: 0.2030\n",
            "Epoch 480/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0655 - accuracy: 0.1675 - val_loss: 0.0771 - val_accuracy: 0.1985\n",
            "Epoch 481/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0657 - accuracy: 0.1638 - val_loss: 0.0706 - val_accuracy: 0.2030\n",
            "Epoch 482/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0654 - accuracy: 0.1665 - val_loss: 0.0719 - val_accuracy: 0.2015\n",
            "Epoch 483/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0658 - accuracy: 0.1643 - val_loss: 0.0687 - val_accuracy: 0.2060\n",
            "Epoch 484/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0648 - accuracy: 0.1658 - val_loss: 0.0722 - val_accuracy: 0.2060\n",
            "Epoch 485/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0645 - accuracy: 0.1636 - val_loss: 0.0730 - val_accuracy: 0.2000\n",
            "Epoch 486/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0649 - accuracy: 0.1655 - val_loss: 0.0754 - val_accuracy: 0.2000\n",
            "Epoch 487/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0652 - accuracy: 0.1660 - val_loss: 0.0714 - val_accuracy: 0.2030\n",
            "Epoch 488/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0645 - accuracy: 0.1648 - val_loss: 0.0690 - val_accuracy: 0.2060\n",
            "Epoch 489/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0642 - accuracy: 0.1663 - val_loss: 0.0685 - val_accuracy: 0.2075\n",
            "Epoch 490/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0646 - accuracy: 0.1688 - val_loss: 0.0722 - val_accuracy: 0.2000\n",
            "Epoch 491/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0647 - accuracy: 0.1670 - val_loss: 0.0720 - val_accuracy: 0.2045\n",
            "Epoch 492/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0654 - accuracy: 0.1658 - val_loss: 0.0731 - val_accuracy: 0.2030\n",
            "Epoch 493/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0645 - accuracy: 0.1650 - val_loss: 0.0761 - val_accuracy: 0.1985\n",
            "Epoch 494/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0644 - accuracy: 0.1673 - val_loss: 0.0713 - val_accuracy: 0.2030\n",
            "Epoch 495/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0642 - accuracy: 0.1653 - val_loss: 0.0766 - val_accuracy: 0.1985\n",
            "Epoch 496/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0638 - accuracy: 0.1648 - val_loss: 0.0710 - val_accuracy: 0.2030\n",
            "Epoch 497/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0637 - accuracy: 0.1643 - val_loss: 0.0702 - val_accuracy: 0.2060\n",
            "Epoch 498/500\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0642 - accuracy: 0.1641 - val_loss: 0.0710 - val_accuracy: 0.2045\n",
            "Epoch 499/500\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0632 - accuracy: 0.1656 - val_loss: 0.0722 - val_accuracy: 0.2030\n",
            "Epoch 500/500\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0644 - accuracy: 0.1683 - val_loss: 0.0730 - val_accuracy: 0.2015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euEvkju2BpWA",
        "outputId": "e09c3c38-b1ee-4b8b-e513-b77af069e4ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.epoch, history.history['loss'], label='Train')\n",
        "plt.plot(history.epoch, history.history['val_loss'], label='Test')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbZDKTvtaRRN"
      },
      "source": [
        "## Feature improtance\n",
        "https://machinelearningmastery.com/calculate-feature-importance-with-python/\n",
        "\n",
        "Permutation feature importance is a technique for calculating **relative** importance scores that is independent of the model used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z52ru-BTopsY"
      },
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idRZZA0Wotap"
      },
      "source": [
        "results = permutation_importance(model, X_train, y_train, scoring='neg_mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVULvCaIouA0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKFlVWPutzmF"
      },
      "source": [
        "#pip install eli5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7LZ7SGAaP2m"
      },
      "source": [
        "#import eli5\n",
        "#from eli5.sklearn import PermutationImportance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-AdXfm4cA5h"
      },
      "source": [
        "#perm = PermutationImportance(model, random_state=1,scoring=\"accuracy\").fit(X_train,y_train,)\n",
        "#eli5.show_weights(perm, feature_names = X_train.columns.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_3Ll_9mJlxS"
      },
      "source": [
        "## Find the threshold for dividing positive samples and neigative samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoHUjMB_CY5j"
      },
      "source": [
        "predict = model.predict(X_test)\n",
        "#predict.shape"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktsucnyTWBjM"
      },
      "source": [
        "#predict[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT6wHCMMGCyI"
      },
      "source": [
        "#predict[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfhBF8XuGPg_"
      },
      "source": [
        "month=['May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        "Client = used_id[-y_test.shape[0]:]\n",
        "\n",
        "preidct_df = pd.DataFrame(predict,columns=month,index=Client,)\n",
        "True_df=pd.DataFrame(y_test,columns=month,index=Client)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoavcnEJIsjx"
      },
      "source": [
        "preidct_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxCTQs7LMhZh"
      },
      "source": [
        "preidct_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFEWbwOUiIug"
      },
      "source": [
        "True_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EkBsx03gi_Q"
      },
      "source": [
        "## Build a dataframe which contains two columns: Predited_value and True_Value for modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdr7LEypW-70"
      },
      "source": [
        "# Combine dataframe to a single column\n",
        "len=preidct_df.shape[0]\n",
        "name_all=[] # predicted values\n",
        "value_all=[] # months\n",
        "true_all=[]\n",
        "for elem in month:\n",
        "  value_all+=(list(preidct_df[str(elem)]))\n",
        "  true_all += (list(True_df[str(elem)]))\n",
        "  name_all += [elem]*len"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpMyxhU2dzki"
      },
      "source": [
        "# build the client column\n",
        "client=[]\n",
        "for i in range(preidct_df.shape[1]):\n",
        "  client+=Client"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8JfJLmZZ3bo",
        "outputId": "e5558760-4a54-435e-ecdc-8187237eaf37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "# Build the datafame\n",
        "dataset=pd.DataFrame(zip(value_all,name_all,true_all),columns=['Predict','Month','Label'])\n",
        "dataset['Client_id']=client\n",
        "dataset.set_index(['Month','Client_id'],inplace=True)\n",
        "dataset.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Predict</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Month</th>\n",
              "      <th>Client_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">May</th>\n",
              "      <th>DB10AF3E-0F92-E011-A5C6-B6A03279A8B3</th>\n",
              "      <td>3.209441e-36</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DB1CE471-B20F-434C-B4D4-9F6D00D10976</th>\n",
              "      <td>1.339487e-29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F771E77B-341D-4672-B6AD-A43500AB411B</th>\n",
              "      <td>8.857987e-24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F77DFB42-B83B-47FD-BBA9-A88D00E983C1</th>\n",
              "      <td>1.588169e-38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>E9D0885E-57E7-4EE6-A384-A61200D8ABF1</th>\n",
              "      <td>1.705792e-33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Predict  Label\n",
              "Month Client_id                                                \n",
              "May   DB10AF3E-0F92-E011-A5C6-B6A03279A8B3  3.209441e-36      0\n",
              "      DB1CE471-B20F-434C-B4D4-9F6D00D10976  1.339487e-29      0\n",
              "      F771E77B-341D-4672-B6AD-A43500AB411B  8.857987e-24      0\n",
              "      F77DFB42-B83B-47FD-BBA9-A88D00E983C1  1.588169e-38      0\n",
              "      E9D0885E-57E7-4EE6-A384-A61200D8ABF1  1.705792e-33      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XHDWWzSQ1wb"
      },
      "source": [
        "## Spliting the predicted value to Test and Train sets for finding the threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZGZYVOGi8sq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvEJ88GVSAG7"
      },
      "source": [
        "rate=0.2\n",
        "train, test = train_test_split(dataset, test_size=rate, random_state=5)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlJARs70Q0Nx",
        "outputId": "f91051cb-5c95-452d-fb82-90b2247a6305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "'''splitting the dataset to X and Y'''\n",
        "# X\n",
        "train_xth = train.Predict\n",
        "test_xth = test.Predict\n",
        "\n",
        "# Y\n",
        "train_yth = train.Label\n",
        "test_yth = test.Label\n",
        "\n",
        "print('The sizes for training dataset and test dataset:\\n',train_xth.shape,test_xth.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sizes for training dataset and test dataset:\n",
            " (4723,) (1181,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrYIzBOHwEZS"
      },
      "source": [
        "### Plotting the Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHYBqPc7Gb-m",
        "outputId": "e2c7f373-af3e-42bc-bd30-27d20dd0f93b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "source": [
        "import seaborn as sns\n",
        "fig, ax = plt.subplots(figsize=(5, 4))\n",
        "for i in [0,1]:\n",
        "  sns.distplot(train_xth.loc[train.Label==i], bins=50,kde=True)\n",
        "ax.set_ylabel('Total Count')\n",
        "ax.set_title('Loss')\n",
        "ax.legend('01')\n",
        "plt.savefig('lossPlot.png')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAEWCAYAAAD1m1U5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZzcdZ3n8denjq7qdHeOTndCSBOSEEADKrIdBQ9UDoWo0Zl1Z8DjwbXD6KiLq7PKqDujjrsLus7ojjOjKCq6KzBeCzKCcoQVBQIBOQQmhCvSkKNzdyd9Vn32j9+vuiudX1VXuqvqV528n49HPep31e/36erOO9/f9f2ZuyMiIgdKxF2AiEgjUjiKiERQOIqIRFA4iohEUDiKiERQOIqIRFA4iohEUDhKQzOz583s7LjrkCOPwlFEJILCUWYcM8uY2VfN7KXw9VUzy4TzOszsZjPbbWY7zexuM0uE8z5lZi+aWZ+ZbTCzs+L9SaSRpeIuQGQKPgOcBpwCOHAj8FngvwKfAHqAznDZ0wA3sxOBjwCr3P0lM1sKJOtbtswkajnKTPQ+4Avuvs3de4HPAx8I540Ai4Bj3X3E3e/2oAOBHJABVppZ2t2fd/dnYqleZgSFo8xERwObisY3hdMAvgw8DfzKzJ41sysA3P1p4GPA54BtZna9mR2NSAkKR5mJXgKOLRpfEk7D3fvc/RPuvhxYA3y8cGzR3X/o7m8IP+vAVfUtW2YShaPMBGkzyxZewHXAZ82s08w6gL8G/jeAmb3DzFaYmQF7CHan82Z2opmdGZ64GQQGgHw8P47MBApHmQl+QRBmhVcWWA88CjwGPAR8MVz2eOB2oB+4F/gnd19LcLzxSmA7sAVYAPxV/X4EmWlMnd2KiBxMLUcRkQgKRxGRCApHEZEICkcRkQgz4vbBjo4OX7p0adxliMhh5sEHH9zu7p1R82ZEOC5dupT169fHXYaIHGbMbFOpedqtFhGJoHAUEYmgcBQRiTAjjjmKSGMaGRmhp6eHwcHBuEspK5vN0tXVRTqdrvgzCkcRmbKenh7a2tpYunQpQV8fjcfd2bFjBz09PSxbtqziz2m3WkSmbHBwkPnz5zdsMAKYGfPnzz/k1q3CUUSmpZGDsWAqNSocRUQiKBxFZMa79dZbOfHEE1mxYgVXXnllVdapEzIN4ofr/jA2/N7XLomxEpGZJZfL8eEPf5jbbruNrq4uVq1axZo1a1i5cuW01quWo4jMaPfffz8rVqxg+fLlNDU1cf7553PjjTdOe71qOYpIVXz+54/zxEt7q7rOlUfP5m/eeVLZZV588UWOOeaYsfGuri7WrVs37W2r5SgiEkEtRxGpislaeLWyePFiXnjhhbHxnp4eFi9ePO31quUoIjPaqlWr2LhxI8899xzDw8Ncf/31rFmzZtrrVctRRGa0VCrF17/+dd72treRy+W45JJLOOmk6bdiFY4iMuOtXr2a1atXV3Wd2q0WEYmgcBQRiaBwFBGJoHAUEYmgcBQRiaBwFBGJoHAUkRnvkksuYcGCBZx88slVW6fCUURmvIsuuohbb721qutUOIrIjHfGGWfQ3t5e1XXqDhkRqY5broAtj1V3nUe9As6rTs/eh0otRxGRCGo5ikh1xNTCqxW1HEVEIigcRWTGu+CCCzj99NPZsGEDXV1dXHPNNdNep3arRWTGu+6666q+TrUcRUQiKBxFRCLUPBzNLGlmvzOzm8PxZWa2zsyeNrMbzKyp1jWISO24e9wlTGoqNdaj5Xg58GTR+FXA37v7CmAXcGkdahCRGshms+zYsaOhA9Ld2bFjB9ls9pA+V9MTMmbWBbwd+G/Ax83MgDOB94aLXAt8DvjnWtYhIrXR1dVFT08Pvb29cZdSVjabpaur65A+U+uz1V8FPgm0hePzgd3uPhqO9wCRD5g1s8uAywCWLFlS4zJFZCrS6TTLli2Lu4yaqNlutZm9A9jm7g9O5fPufrW7d7t7d2dnZ5WrExEpr5Ytx9cDa8xsNZAFZgNfA+aaWSpsPXYBL9awBhGRKalZy9Hd/8rdu9x9KXA+cKe7vw9YC7wnXOxC4MZa1SAiMlVxXOf4KYKTM08THIOc/n0+IiJVVpfbB939LuCucPhZ4DX12K6IyFTpDhkRkQgKRxGRCApHEZEICkcRkQgKRxGRCApHEZEICkcRkQgKRxGRCApHEZEICkcRkQgKRxGRCApHEZEICkcRkQgKRxGRCApHEZEICkcRkQgKRxGRCApHEZEICkcRkQgKRxGRCApHEZEICkcRkQgKRxGRCApHEZEICkcRkQgKRxGRCApHEZEICkcRkQgKRxGRCApHEZEICkcRkQgKRxGRCApHEZEICkcRkQgKRxGRCDULRzPLmtn9ZvaImT1uZp8Ppy8zs3Vm9rSZ3WBmTbWqQURkqmrZchwCznT3VwGnAOea2WnAVcDfu/sKYBdwaQ1rEBGZkpqFowf6w9F0+HLgTODH4fRrgXfXqgYRkamaNBzN7PJKppX4bNLMHga2AbcBzwC73X00XKQHWFx5uSIi9VFJy/HCiGkXVbJyd8+5+ylAF/Aa4GWVFmZml5nZejNb39vbW+nHRESqIlVqhpldALwXWGZmNxXNagN2HspG3H23ma0FTgfmmlkqbD12AS+W+MzVwNUA3d3dfijbExGZrpLhCNwDbAY6gK8UTe8DHp1sxWbWCYyEwdgMnENwMmYt8B7geoJW6Y1TK11EpHZKhqO7bwI2EbT2pmIRcK2ZJQl23//F3W82syeA683si8DvgGumuH4RkZop13IEwMz+mKDFtwCw8OXuPrvc59z9UeDVEdOfJTj+KCLSsCYNR+BLwDvd/claFyMi0igqOVu9VcEoIkeaSlqO683sBuD/Etz1AoC7/7RmVYmIxKyScJwN7AfeWjTNAYWjiBy2Jg1Hd7+4HoWIiDSSSs5Wf5egpXgAd7+kJhWJiDSASnarby4azgJ/BLxUm3JERBpDJbvVPykeN7PrgN/UrCIRkQYwlS7Ljie4IFxE5LBVyTHHPoJjjha+bwE+VeO6RERiVcludVs9ChERaSSVnJDBzNYAZ4Sjd7n7zeWWFxGZ6SrpCfxK4HLgifB1uZn991oXJiISp0pajquBU9w9D2Bm1xJ0NfbpWhYmIhKnSs9Wzy0anlOLQkREGkklLcf/AfwufMyBERx7vKKmVYmIxKySs9XXmdldwKpw0qfcfUtNqxIRiVm5B2y9DWhz9x+7+2bgpnD6e8xsj7vfVq8iRUTqrdwxx78G/l/E9LuAL9SkGhGRBlEuHDPuftADo919O9BSu5JEROJXLhxnm9lBu91mlgaaa1eSiEj8yoXjT4FvmdlYK9HMWoFvoF7AReQwVy4cPwtsBTaZ2YNm9iDwHNAbzhMROWyVPFvt7qPAFWb2eWBFOPlpdx+oS2UiIjGq5DrHAeCxOtQiItIwptLZrYjIYU/hKCISodwdMqeW+6C7P1T9ckREGkO5Y45fKTPPgTOrXIuISMMod7b6LfUsRESkkVT6mISTgZUEz60GwN2/X6uiRETiVsnTB/8GeDNBOP4COI/gudUKRxE5bFVytvo9wFnAFne/GHgV6g1cRA5zlYTjQPj8mFEzmw1sA46pbVkiIvGq5JjjejObC3wLeBDoB+6taVUiIjGr5PbBvwgHv2FmtwKz3f3R2pZ15BkezdOU0jX5Io2ikudW31EYdvfn3f3R4mllPneMma01syfM7HEzuzyc3m5mt5nZxvB93vR+hJnvh+v+wOd+/jjb+4fiLkVEQiXD0cyyZtYOdJjZvDDU2s1sKbC4gnWPAp9w95XAacCHzWwlwZML73D344E7OMKfZDg4kuPTPwv69di8ZzDmakSkoNxu9Z8DHwOOBopvFdwLfH2yFYcP5docDveZ2ZMEofougkuDAK4leCbNpw6x7sPGYy/uGRvetW84xkpEpFi5O2S+BnzNzD7q7v8wnY2Erc1XA+uAhWFwAmwBFpb4zGXAZQBLliyZzuYbWm/f+K70zv0KR5FGUckZgG+a2X8ysx+Hr4+Ez5GpSPhohZ8AH3P3vcXz3N0J7tM+iLtf7e7d7t7d2dlZ6eZmnEI4zp2VVstRpIFUEo7/BPy78L0w/M+VrDwM0Z8A/8fdC8+d2Wpmi8L5iwiumzxi9fYNkUwYXXOb2alwFGkY5bosS4WPSljl7q8qmnWnmT0y2YrNzIBrgCfd/e+KZt0EXAhcGb7fOKXKDxO9fUN0tDYxvzXDk5v7yHtkQ1pE6qxcy/H+8D1nZscVJprZciBXwbpfD3wAONPMHg5fqwlC8Rwz2wicHY4fsXr7h+hsyzB3VpqcO32Do3GXJCKUP1tt4ftfAmvN7NlwfClw8WQrdvffFK1jorMqLfBw19s3RGdrhpam4Fexf1jhKNIIyoVjp5l9PBz+JpAMh3MEZ57X1rKwI0Vv3xAvX9RGc1Pw9Q4MV9IoF5FaKxeOSaCVg1t/KaCtZhUdQfJ5Z3u4W23h1zwwonAUaQTlwnGzu3+hbpUcgXYPjDCadzpaM+wPW4xqOYo0hkqOOUqN7Aov+p43qwn3YFgtR5HGUO5stU6a1Fh/eGa6LZsik0qQMLUcRRpFyXB09531LORI1DcWjmnMjGw6qZajSINQB4Ix6h8aAaA1ExzdaE4nx449iki8FI4x6ivarQZobkoyqJajSENQOMbooHDUbrVIw1A4xqh/KAjHlsx4y1G71SKNQeEYo77BEZrTSdLJ4NfQnE7qbLVIg1A4xqh/aJTW7PilpoVjjvm8euYRiZvCMUZ9g6O0ZYrCMZ3Egf067igSO4VjjPoGR8dOxgBkUslw+khcJYlISOEYo4m71Zl08OvoV5+OIrFTOMaof3B07AJwgGwq+HX0DSkcReKmcIxR3+AIbdnxZ5UVdqvVchSJn8IxRn1DB7Ycx3ar1XIUiZ3CMSb5vNM/NMrsomOO2bRajiKNQuEYk/0jOdw54IRMtnC2Wi1HkdgpHGNSaB22ZsaPOTaldLZapFEoHGNSuJax+DrHZMJIJ22sKzMRiY/CMSaFXefi3WoIdq11QkYkfgrHmIw9IiFzYDhm0omxrsxEJD4Kx5gUPyKhWEYtR5GGoHCMydgjErIHtxx1QkYkfgrHmEzsBbxAxxxFGkO551ZLDRXCsaVpQssxlWBb31AcJcmRbv13DxzvvjieOhqEWo4x6R8apaUpSTJhB0zPpNVyFGkECseYTOx0oiCbStA/NIq7egMXiZPCMSYT+3IsyKST5PKupxCKxEzhGJOJvYAXZHQLoUhDUDjGpG9CR7cF2bQ6vBVpBArHmPQPlWo5qtsykUagcIxJ3+AIbZmDT8iow1uRxqBwjEn/YPQJmbE+HdVyFIlVzcLRzL5jZtvM7PdF09rN7DYz2xi+z6vV9htZLu/sG86VOOYY7lar5SgSq1q2HL8HnDth2hXAHe5+PHBHOH7EKQRf+bPV6tNRJE41C0d3/zWwc8LkdwHXhsPXAu+u1fYbWUXhqJajSKzqfcxxobtvDoe3AAtLLWhml5nZejNb39vbW5/q6qS/RHdlAKlkgqZUQpfyiMQsthMyHtwfV/IeOXe/2t273b27s7OzjpXVXuERCVHHHCHoAFeX8ojEq97huNXMFgGE79vqvP2GUOoRCQWt2ZR2q0ViVu9wvAm4MBy+ELixzttvCIXLdGaXCke1HEViV8tLea4D7gVONLMeM7sUuBI4x8w2AmeH40ecqMeyFmvNpHTMUSRmNevs1t0vKDHrrFptc6Yo9YiEgrZsipd2D9azJBGZQHfIxKBvcBQzaGlKRs5vy6bZq+scRWKlcIxBoUceM4ucP6c5zZ4BhaNInBSOMegfGmV2xDWOBbOb0/QNjpLLqzdwkbgoHGPQNzhS8hpHCFqOheVEJB4KxxiUekRCQSEctWstEh+FYwxKPSKhQOEoEj+FYwxKPSKhQOEoEj+FYwz2DIwwd1bpEzIKR5H4KRzrLJ93du8fZm5zU8llFI4i8VM41lnf0Ch5Ry1HkQancKyzPfuDwJs7q3TLMZtO0JRMKBxFYqRwrLNd+4cBmNtcuuVoZsxuTrNX4SgSG4Vjne0OA29eS+lwBJjTnFLLUSRGCsc62x22HOeUOSETzNf91SJxUjjW2e6xY47lW47tLRl29A/XoyQRiaBwrLOxcCxzzBGgs62J7f1D9ShJRCIoHOts1/5h2jIpUsnyX31Ha4ad+4bVM49ITBSOdbZnYIQ5k+xSA3S2Zcg77NynXWuROCgc62zX/mHmlbnGsaCjNQNAb592rUXioHCss137hic9GQPj4ajjjiLxUDjW2Za9gxw1Ozvpcp1tCkeROCkc62g0l6e3b4iFFYRjR2uw661wFImHwrGOduwbJu+wcM7k4diaSZFJJXTMUSQmNXtutRxsy57gWdSV7FabGR2tGYWj1Nb678ZdQcNSy7GOtu4NwnHh7ExFyy+e10zProFaliQiJSgc66gQjpW0HAGWzW/h+R37a1mSiJSgcKyjrXuHSCaM+a2VtRyP7ZjF9v4h+odGa1yZiEykcKyjLXsH6WzNkExYRcsvnd8CwKYd+2pZlohEUDjW0aYd++ia11zx8sfOnwXA89u1ay1SbzpbXSfuzlNb+3n7KxdV/JlCy/F5tRzlUO3fCds3wvYNsP0p6H0K+l6CoX4Y7g/eCTs1SaahqRUybdA8D1oXQutRsG8HtMyP9ceIk8KxTnr7htgzMMIJC1or/kxLJsXRc7I8uXlvDSuTGSufh7094+G3vei1r3d8uWQGOo6HOV1BADa1QqYVMNj8MORGYKgveG19HF5YF3zugauh4wRYchoseR2sOBtaO2P5UeOgcKyTDVv7ADjhqLZD+lz30nbWPbcDd8essmOVMgNNvN6w++Lx4aF+2Pks7HwmbA0+Bb0bYMfTMFJ0yCU9K2j1tR8Hr78cOk4MQnHuEkgkK9suwPA+6NsCs9qDoHziJnjo+4BBVzec8DY4cTUsWAmH8d+kwrFOntraD8AJC6PD8bg//Gh85LWfGBt8zbJ2bnrkJTbt2M/Sjpaa1ig1UC70CkYGgpbe4B4Y2A2Du+HF9bAjDMT+rQcuP2cJdJ4AS98A+7aHu8ELoallPKyKt3OoF3o3tcD848bXkc/D1sfgqV/Chlvgzi8Gr3nL4OXvgJevgcXdkDi8TmEoHOvk0Z7ddLRmxnrbqdRpy9sBuPfZHQrHaioOjKjAmsr63CE/Aq/4DzC0Nzjut+3JoCU2sg+G9we7rQM7g3n924LjgAO7Dl5fy4IgoFacA/OXQ/vyoEU4/7ggvKJ+jlpJJGDRq4LXmz4ZtCo33AL/djPc9w245x+CY5Qvezu8/J1BaCcn73mq0Skc62Akl2ftv23jrScddcifPa6zlWUdLfxw3R84f9Ux2rWeqtGhIKSG+oKW2u4XIDccvJ78OYwMBruoIwMwOhC8F8aL543sh9FwvG9LcLwuNxKsJx8+EO2WT5YowqB5LjS3B7us846FY0+HtkWw45lgXnYOZOfCaR8c/9j67wYtyhcfhEWvrPlXNam2o4L/ULovDura+KvgO3zkOlh/TVD/iefBy94Bx50JTbPirnhKFI51cP9zO9k7OMo5KxdW9oGi1oABf/bGs/j0zx7jl49v5dyTDz1gZ5zcSHBGdThsbY0N7wuH++GZO4PAGx2G3GDwPjoIs+aPLz/UH7TSRofAc6W3d/83o6enmiHdHBzLSzdDOjs+PGs+JFJBCynRBMmmYDiZhmVnBCc9ZrXDpnuDcGhqCT676tLobU1sAZZqEVbaUqzXPdPNc+GVfxK8hvfDs2uDoNxwSxCWqSwc81pY+kZY9kY4+lRITd7ZcyMw9/o/o8TMzgW+BiSBb7v7leWW7+7u9vXr19eltmpzdy787gM8tGkXD3zmbJpTNv6Pd6wVMsCTt3+PRH6ERH6UhI+QyI9gnsM8z9Fzm/nBM1l2D8Hpy9vpmptlbjZBJmmkEyWOiW9+dHy4XGuj0uUO5TP53HhrKjc8yfBQGICFXc99wbxKJdKQygSvZPieaoJkNnhPZYPgSoXjycL8puCzY6E24T2RPviLnbj7fbh32jCdww25EXj+N8Fxyufvhq2/D6YnM7DwpPHd9IUnBccuWzpiObljZg+6e3fkvHqHo5klgaeAc4Ae4AHgAnd/otRnqhaO7uD5otfE8aLp+dEguHJhi6TQMskNhS2WwrSBomvH+savIQvfd+/eyc5dOzkqO8osHwgCoEpybjjBa+LfVck/s+IZlfzqrfBW9EHPF81LFM3Jh6tN4IkUnmrGE2nyyTQ+OoxbCk8kD3y3JPlkhnyiKXhfcBKebiGfnkW+qQVPzcLTLXjTLLypFdItkGnFnr6TfDLDKElGHUbzRs45YDjvQYlm4+UWf0/Ff/pmkDRImofvRcOJYDyBh993+KdTwdcHkAg/W9hGMA5mPjacsAl1HlC3H1R7YdwmGZ+WahyLLdi/MwjLF9bB5keC/2CH9ozPb2qD9qUwezHM6gjCsqUzeGXnHNhqL7ynskWt91TwOsQfulw4xrFb/RrgaXd/FsDMrgfeBZQMx0Oy6R74wR8fGHb4+D/oWkrPGr+GrCl4peYcRb8tIrtscXCN2di8lnBXqxlSzTxxz8/JW5p8Ik0+kQqGLfhlO4nw3dg5kuaFwQzbhpromXMqgyN5hkZzDI3kSe3dxEA+wUAuyUAuwUAuwf5cguF84oBQTOBj/2CDf6xOgiAMCtNzGAO5BIO5BLnSUVt9z5eakQf2hi+AY+pRzWGjOGDLBWjxqN14S9H0YE7x8ld/oJs3HN9RWQGz2mHlmuAFwf8uu54PLkva+VxwqdKu52Dvi0Fw7usdP4Zbqdaj4C83HNpnyogjHBcDLxSN9wCvnbiQmV0GXBaO9ptZ9X7qg3UA26e/mmldrF2lGqZFNaiGimt449/Gu/2D7YX/csj/kR9bakbDnpBx96uBq+uxLTNbX6ppXS+qQTWohsbafhxXbb7IgftEXeE0EZGGEUc4PgAcb2bLzKwJOB+4KYY6RERKqvtutbuPmtlHgF8SXMrzHXd/vN51TFCX3fdJqIaAagiohpi3H8t1jiIije7wulNcRKRKFI4iIhGOyHA0s3Yzu83MNobv8yKWOcXM7jWzx83sUTP70ypt+1wz22BmT5vZFRHzM2Z2Qzh/nZktrcZ2D7GGj5vZE+HPfYeZlbwWrFY1FC33783Mzayql3RUsn0z+5Pwe3jczH5Yze1XUoOZLTGztWb2u/B3sboGNXzHzLaZ2e9LzDcz+19hjY+a2akx1PC+cNuPmdk9ZvaqatcQyd2PuBfwJeCKcPgK4KqIZU4Ajg+HjwY2A3Onud0k8AywHGgCHgFWTljmL4BvhMPnAzdU+WevpIa3ALPC4Q/FUUO4XBvwa+A+oLvO38HxwO+AeeH4ghh+D1cDHwqHVwLPV7OGcL1nAKcCvy8xfzVwC8HNM6cB62Ko4XVFv4fzalFD1OuIbDkS3K54bTh8LfDuiQu4+1PuvjEcfgnYBky3j/ixWyfdfRgo3DpZqrYfA2dZdfspm7QGd1/r7oUupu8juBa1mir5HgD+FrgKGIxh+38G/KO77wJw920x1ODA7HB4DvBSlWvA3X8N7CyzyLuA73vgPmCumVX+IKQq1ODu9xR+D9Tm7zHSkRqOC919czi8BSjbl5iZvYbgf/dnprndqFsnF5daxt1HgT1ANZ9yVEkNxS4laDlU06Q1hLtvx7j7v1Z52xVtn2DP4QQz+62Z3Rf2JFXvGj4HvN/MeoBfAB+tcg2VONS/l1qrxd9jpIa9fXC6zOx2IKrzw88Uj7i7m1nJ65nC/yV/AFzoXo/eKxqHmb0f6AbeVOftJoC/Ay6q53YnSBHsWr+ZoKXyazN7hbvvrmMNFwDfc/evmNnpwA/M7OQj7e+wwMzeQhCOb6jH9g7bcHT3s0vNM7OtZrbI3TeH4Re5y2Rms4F/BT4T7lJMVyW3ThaW6TGzFMHu1I4qbPtQasDMzib4j+RN7j5Uxe1XUkMbcDJwV3hE4SjgJjNb4+7V6Nizku+gh+DY1gjwnJk9RRCWD1Rh+5XWcClwLoC732tmWYLOGKq9i19OQ9zua2avBL4NnOfu1fz3UFo9Dmw22gv4MgeekPlSxDJNwB3Ax6q43RTwLLCM8YPwJ01Y5sMceELmX6r8s1dSw6sJDiEcX6Pvf9IaJix/F9U9IVPJd3AucG043EGwazm/zjXcAlwUDr+c4Jij1eD3sZTSJ0PezoEnZO6v0d9EuRqWAE8Dr6vFtkvWVM+NNcqL4BjeHcBG4HagPZzeTdAzOcD7gRHg4aLXKVXY9mqCzn6fIWiRAnwBWBMOZ4EfhX8M9wPLa/DzT1bD7cDWop/7pnrXMGHZqoZjhd+BEezaPwE8Bpwfw+9hJfDbMDgfBt5agxquI7gSY4SgtXwp8EHgg0Xfwz+GNT5W7d9DhTV8G9hV9Pe4vto1RL10+6CISIQj9Wy1iEhZCkcRkQgKRxGRCApHEZEICkcRkQgKR2koZpYzs4fN7Pdm9iMzmzWNdX3PzN4TDn/bzFaWWfbNZva6qW5LDj8KR2k0A+5+irufDAwTXO82Jrxr6JC5+39093LPRn8zQe8vIoDCURrb3cCKsFV3t5ndBDxhZkkz+7KZPRD28/fnMNb34NfDPhJvBxYUVmRmdxX6hAz7UXzIzB4J+6tcShDC/zlstb6x7j+pNJzD9t5qmdnCFuJ5wK3hpFOBk939OTO7DNjj7qvMLAP81sx+RXDb44kEd5YsJLi75TsT1tsJfAs4I1xXu7vvNLNvAP3u/j/r8gNKw1M4SqNpNrOHw+G7gWsIdnfvd/fnwulvBV5ZOJ5I0DnH8QSdpl7n7jngJTO7M2L9pwG/LqzL3cv1ZShHMIWjNJoBdz+leELYM8++4knAR939lxOWq/pjBOTIpWOOMhP9EviQmaUBzOwEM2sheKTCn4bHJBcRPO5hovuAM8xsWfjZ9nB6H0FXaSKAwlFmpm8THE98KHwo0zcJ9oJ+RtDT0hPA94F7J37Q3XuBy4CfmtkjwA3hrJ8Df6QTMlKgXnlERCKo5SgiEkHhKCISQeEoIhJB4SgiEkHhKKnkUYIAAAATSURBVCISQeEoIhJB4SgiEuH/AwIAKtJ1q9zZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjAjFXXllOYE"
      },
      "source": [
        "### Finding the best threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A6m-n_svXse"
      },
      "source": [
        "# from the above plot we can choose the threshold to be 0.2 or greater\n",
        "'''Generate the list for thresholds'''\n",
        "threshold = []\n",
        "num = 4000\n",
        "start=0.2\n",
        "for i in range(num):\n",
        "  val= start+0.0001*i\n",
        "  threshold.append(val)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I4ibi3C24vR"
      },
      "source": [
        "# generate the list of f1_scores \n",
        "from sklearn.metrics import f1_score\n",
        "f1_scores=[]\n",
        "for thres in threshold:\n",
        "  Predited_label = []\n",
        "  for elem in test_xth:\n",
        "    if elem < thres:\n",
        "      Predited_label.append(0)\n",
        "    else:\n",
        "      Predited_label.append(1)\n",
        "  f1s=f1_score(test_yth, Predited_label, zero_division=0)\n",
        "  f1_scores.append(f1s)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IUevWtx4a8s"
      },
      "source": [
        "# get the corrodinate of the largest f1_score\n",
        "y=max(f1_scores)\n",
        "max_index = f1_scores.index(max(f1_scores))\n",
        "x=threshold[max_index]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dkXY410xIPr",
        "outputId": "b79cefbd-bb0e-482e-e071-6e4d4eaf93f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(threshold,f1_scores)\n",
        "plt.title('threshold VS f1_scores')\n",
        "plt.scatter(x, y, c='red')\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('f1_scores')\n",
        "plt.text(x, y, '({:5.3f}, {:5.3f})'.format(x, y))\n",
        "plt.savefig('threshold_choose.png')\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6i6qzYs-ng1",
        "outputId": "51d7c947-c8ad-4e46-c376-e9f8286bb9ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(f'The best f1_scores is{y: 5.4f} for threshold is{x: 5.4f}.')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best f1_scores is 0.7961 for threshold is 0.4827.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM0FTJZyfbYx"
      },
      "source": [
        "### Show the performance of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP5r6A5bla4k"
      },
      "source": [
        "# label the prediction with the choosen threshold\n",
        "predited_label=[]\n",
        "incident_index=[]# incident list\n",
        "for elem in test_xth:\n",
        "  if elem < x:\n",
        "    predited_label.append(0)\n",
        "  else:\n",
        "    predited_label.append(1)\n",
        "    indx = test_xth.loc[(test_xth.loc[:]==elem),:].index.values.tolist()\n",
        "    incident_index+=indx"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIWJziKWfCuU",
        "outputId": "9eefd7c6-efe6-4f77-e002-29ecec146ec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(test_yth, predited_label,labels=[1,0])\n",
        "print(report)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.81      0.78      0.80       105\n",
            "           0       0.98      0.98      0.98      1076\n",
            "\n",
            "    accuracy                           0.96      1181\n",
            "   macro avg       0.90      0.88      0.89      1181\n",
            "weighted avg       0.96      0.96      0.96      1181\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C17VdpEkdqaT",
        "outputId": "56243a3a-7181-446c-8905-8c3da3892aaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(test_yth, predited_label)\n",
        "recal = cm[1][1]/sum(cm[1])\n",
        "\n",
        "sns.heatmap(cm, annot=True,cmap='Blues')\n",
        "plt.ylabel('True')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title(f'Recall is {recal:0.3f}',y=1.05, fontsize=16)\n",
        "plt.suptitle('Confusion Matrix',y=1.06)\n",
        "\n",
        "plt.savefig('Confusion_matrix.png')\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LET2Xa3bYUNk"
      },
      "source": [
        "The best result is when epcho is 500, threshold is 0.258, and f1_score is 0.771  and recall is 0.81. (drop out rate 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayBHfJ7i_o-j"
      },
      "source": [
        "## The clients who should pay attention to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YjucVZpDO3Q",
        "outputId": "37a6d9a6-b579-4d45-9a64-52b3d9d82f01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "print('The risky clients in each month:')\n",
        "df=pd.DataFrame(incident_index,columns=['Month', 'Client_id'])\n",
        "df.sort_values(by=['Month'])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The risky clients in each month:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month</th>\n",
              "      <th>Client_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Aug</td>\n",
              "      <td>F9820D32-26C4-4CE9-959C-A60400B41C28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Aug</td>\n",
              "      <td>E714D2C2-0D31-40CC-BA86-A462014699B8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aug</td>\n",
              "      <td>F83448CE-AD2E-412C-B7EB-A8D000D9E91F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Aug</td>\n",
              "      <td>EEA15CAA-1BCC-4B77-858D-6411976138F9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>Aug</td>\n",
              "      <td>F3FB6D6E-F935-4D13-8482-A2EA00AACFA0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Sep</td>\n",
              "      <td>FC3769A9-E075-E011-97F0-B6A03279A8B3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Sep</td>\n",
              "      <td>FA381413-9F46-4093-8E71-192D86BDB089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Sep</td>\n",
              "      <td>EF1E6180-A15F-4A21-BE0D-A86400FD634E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Sep</td>\n",
              "      <td>DF97393F-9427-409D-B221-A44800E853C7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Sep</td>\n",
              "      <td>F5A7C654-DE9F-4E73-BBE3-A8CC00BC3179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Month                             Client_id\n",
              "24   Aug  F9820D32-26C4-4CE9-959C-A60400B41C28\n",
              "39   Aug  E714D2C2-0D31-40CC-BA86-A462014699B8\n",
              "3    Aug  F83448CE-AD2E-412C-B7EB-A8D000D9E91F\n",
              "6    Aug  EEA15CAA-1BCC-4B77-858D-6411976138F9\n",
              "92   Aug  F3FB6D6E-F935-4D13-8482-A2EA00AACFA0\n",
              "..   ...                                   ...\n",
              "36   Sep  FC3769A9-E075-E011-97F0-B6A03279A8B3\n",
              "16   Sep  FA381413-9F46-4093-8E71-192D86BDB089\n",
              "48   Sep  EF1E6180-A15F-4A21-BE0D-A86400FD634E\n",
              "12   Sep  DF97393F-9427-409D-B221-A44800E853C7\n",
              "57   Sep  F5A7C654-DE9F-4E73-BBE3-A8CC00BC3179\n",
              "\n",
              "[101 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    }
  ]
}